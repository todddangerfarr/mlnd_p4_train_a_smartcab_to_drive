Gamma: 0.95, Epsilon: 0.6, Epsilon_Decay: 0.97
Simulator.run(): Trial 0
Environment.reset(): Trial set up with start = (8, 5), destination = (4, 2), deadline = 35
RoutePlanner.route_to(): destination = (4, 2)
{'forward': 0.0, None: 0.0, 'right': 0.4, 'left': 0.0}
LearningAgent.update(): deadline = 35, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': -0.2, None: 0.0, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 34, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1
{'forward': -0.2, None: 1.0, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 33, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.12500000000000003, None: 1.0, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 32, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1
{'forward': 0.9833333333333334, None: 0.0, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 31, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.12500000000000003, None: 1.0, 'right': 0.0, 'left': -0.012500000000000011}
LearningAgent.update(): deadline = 30, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1
{'forward': 1.3735, None: 0.0, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 29, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 1.4779166666666665, None: 0.0, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 28, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 0.0, None: 0.0, 'right': 0.4862886904761904, 'left': 0.0}
LearningAgent.update(): deadline = 27, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': 1.7186796874999999, None: 0.0, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 26, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 1
Environment.reset(): Trial set up with start = (2, 3), destination = (6, 3), deadline = 20
RoutePlanner.route_to(): destination = (6, 3)
{'forward': 0.0, None: 0.0, 'right': 0.6291082506613757, 'left': 0.0}
LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': 0.0, None: 0.0, 'right': 0.4862886904761904, 'left': -0.059780638227513234}
LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1
{'forward': 0.0, None: 0.0, 'right': 3.632745703125, 'left': -0.059780638227513234}
LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': -0.12500000000000003, None: 1.475, 'right': 0.0, 'left': -0.012500000000000011}
LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.12500000000000003, None: 1.7837500000000002, 'right': 0.0, 'left': -0.012500000000000011}
LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.12500000000000003, None: 1.7837500000000002, 'right': 0.125, 'left': -0.012500000000000011}
LearningAgent.update(): deadline = 15, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 0.5
{'forward': 0.1, None: 0.0, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 14, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 0.5
{'forward': -0.16666666666666666, None: 0.0, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 13, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1
{'forward': -0.16666666666666666, None: 0.0, 'right': 0.15680754830404384, 'left': 0.0}
LearningAgent.update(): deadline = 12, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 0.5
{'forward': 0.0, None: 0.0, 'right': 1.2318582715747974, 'left': 0.0}
LearningAgent.update(): deadline = 11, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': 0.0, None: 0.0, 'right': 3.6327457031249994, 'left': -0.059780638227513234}
LearningAgent.update(): deadline = 10, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': 1.91626796875, None: 0.0, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 9, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 1.91626796875, None: 0.25640496093750004, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 8, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 2.074950185546875, None: 0.25640496093750004, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 7, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 2
Environment.reset(): Trial set up with start = (5, 1), destination = (8, 2), deadline = 20
RoutePlanner.route_to(): destination = (8, 2)
{'forward': 2.2208157617563105, None: 0.25640496093750004, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 2.2208157617563105, None: 0.47589496191680736, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 19, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 2.2208157617563105, None: 0.47589496191680736, 'right': 0.5, 'left': 0.0}
LearningAgent.update(): deadline = 18, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 0.5
{'forward': 0.3244835854444208, None: 0.0, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 17, inputs = {'light': 'green', 'oncoming': None, 'right': 'left', 'left': None}, action = forward, reward = 0.5
{'forward': -0.16666666666666666, None: 0.38298905696294716, 'right': 0.15680754830404384, 'left': 0.0}
LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16666666666666666, None: 0.6282016937509103, 'right': 0.15680754830404384, 'left': 0.0}
LearningAgent.update(): deadline = 15, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 0.1, None: 0.0, 'right': 0.0, 'left': 0.821954994733699}
LearningAgent.update(): deadline = 14, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2
{'forward': 2.3141560089630944, None: 0.47589496191680736, 'right': 0.5, 'left': 0.0}
LearningAgent.update(): deadline = 13, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 3
Environment.reset(): Trial set up with start = (5, 5), destination = (7, 3), deadline = 20
RoutePlanner.route_to(): destination = (7, 3)
{'forward': -0.12500000000000003, None: 1.9138660714285716, 'right': 0.125, 'left': -0.012500000000000011}
LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.12500000000000003, None: 2.043052742346939, 'right': 0.125, 'left': -0.012500000000000011}
LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.12500000000000003, None: 2.9409001052295918, 'right': 0.125, 'left': -0.012500000000000011}
LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 3.2563021087390167, None: 0.47589496191680736, 'right': 0.5, 'left': 0.0}
LearningAgent.update(): deadline = 17, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 3.0364652755137995, None: 0.47589496191680736, 'right': 0.5, 'left': 0.0}
LearningAgent.update(): deadline = 16, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.16666666666666666, None: 0.8703491725790239, 'right': 0.15680754830404384, 'left': 0.0}
LearningAgent.update(): deadline = 15, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16666666666666666, None: 0.8703491725790239, 'right': 0.15680754830404384, 'left': -0.03463365720998546}
LearningAgent.update(): deadline = 14, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1
{'forward': -0.16666666666666666, None: 1.0297629294741988, 'right': 0.15680754830404384, 'left': -0.03463365720998546}
LearningAgent.update(): deadline = 13, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 0.1, None: 0.0, 'right': 0.0, 'left': 1.3893692954814725}
LearningAgent.update(): deadline = 12, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 4
Environment.reset(): Trial set up with start = (6, 2), destination = (4, 6), deadline = 30
RoutePlanner.route_to(): destination = (4, 6)
{'forward': 0.1, None: 0.0, 'right': 0.0, 'left': 1.8149300210423025}
LearningAgent.update(): deadline = 30, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2
{'forward': -0.125, None: 0.0, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 29, inputs = {'light': 'red', 'oncoming': None, 'right': 'left', 'left': None}, action = forward, reward = -1
{'forward': -0.12500000000000003, None: 3.793855099968112, 'right': 0.125, 'left': -0.012500000000000011}
LearningAgent.update(): deadline = 28, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 3.3803243977519934, None: 0.47589496191680736, 'right': 0.5, 'left': 0.0}
LearningAgent.update(): deadline = 27, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 0.1, None: 0.0, 'right': 0.0, 'left': 2.9470560733163333}
LearningAgent.update(): deadline = 26, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2
{'forward': 3.8380703427800937, None: 0.47589496191680736, 'right': 0.5, 'left': 0.0}
LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 4.199689639352293, None: 0.47589496191680736, 'right': 0.5, 'left': 0.0}
LearningAgent.update(): deadline = 24, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
Environment.act(): Primary agent has reached destination!
