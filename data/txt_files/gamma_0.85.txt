Gamma: 0.85
Simulator.run(): Trial 0
Environment.reset(): Trial set up with start = (2, 4), destination = (8, 5), deadline = 35
RoutePlanner.route_to(): destination = (8, 5)
{'forward': -0.2, None: 0.0, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 35, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1
{'forward': -0.2, None: 0.2, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 34, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.2, None: 1.17, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 33, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 1.0, None: 0.0, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 32, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 1.0, None: 0.6166666666666667, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 31, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 1.4625, None: 0.6166666666666667, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 30, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 1.818625, None: 0.6166666666666667, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 29, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 1.818625, None: 0.6166666666666667, 'right': 0.0, 'left': 0.08333333333333333}
LearningAgent.update(): deadline = 28, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 0.5
{'forward': -0.14285714285714285, None: 0.0, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 27, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1
{'forward': 0.0, None: 0.0, 'right': 0.3743125, 'left': 0.0}
LearningAgent.update(): deadline = 26, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': 2.0105368055555553, None: 0.6166666666666667, 'right': 0.0, 'left': 0.08333333333333333}
LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 2.009483125, None: 0.6166666666666667, 'right': 0.0, 'left': 0.08333333333333333}
LearningAgent.update(): deadline = 24, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.14285714285714285, None: 0.0, 'right': 0.33709642329545453, 'left': 0.0}
LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': 2.009483125, None: 0.7909494991319443, 'right': 0.0, 'left': 0.08333333333333333}
LearningAgent.update(): deadline = 22, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 1
Environment.reset(): Trial set up with start = (8, 3), destination = (7, 6), deadline = 20
RoutePlanner.route_to(): destination = (7, 6)
{'forward': 0.0, None: 0.0, 'right': 0.0, 'left': 0.15384615384615385}
LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2
{'forward': 0.0, None: 0.0, 'right': 0.0, 'left': 0.4272472694156805}
LearningAgent.update(): deadline = 19, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2
{'forward': 3.70806065625, None: 0.7909494991319443, 'right': 0.0, 'left': 0.08333333333333333}
LearningAgent.update(): deadline = 18, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 2
Environment.reset(): Trial set up with start = (3, 3), destination = (8, 6), deadline = 40
RoutePlanner.route_to(): destination = (8, 6)
{'forward': -0.2, None: 1.58225, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 40, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.2, None: 1.58225, 'right': 0.25, 'left': 0.0}
LearningAgent.update(): deadline = 39, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 0.5
{'forward': -1.0, None: 0.0, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 38, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1
{'forward': 0.0, None: 0.0, 'right': 0.39326597990056816, 'left': 0.4272472694156805}
LearningAgent.update(): deadline = 37, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 0.5
{'forward': -0.14285714285714285, None: 0.0, 'right': 0.9869082687973485, 'left': 0.0}
LearningAgent.update(): deadline = 36, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': 0.0, None: 0.0, 'right': 1.568697264453125, 'left': 0.0}
LearningAgent.update(): deadline = 35, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': 3.635431025, None: 0.7909494991319443, 'right': 0.0, 'left': 0.08333333333333333}
LearningAgent.update(): deadline = 34, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.2, None: 1.58225, 'right': 0.2916666666666667, 'left': 0.0}
LearningAgent.update(): deadline = 33, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 0.5
{'forward': -1.0, None: 0.0, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 32, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1
{'forward': -1.0, None: 0.0, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 31, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1
{'forward': 0.0, None: 0.0, 'right': 0.39326597990056816, 'left': 0.9453438362861604}
LearningAgent.update(): deadline = 30, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2
{'forward': 3.4718879225, None: 0.7909494991319443, 'right': 0.0, 'left': 0.08333333333333333}
LearningAgent.update(): deadline = 29, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.2, None: 1.6515829545454543, 'right': 0.2916666666666667, 'left': 0.0}
LearningAgent.update(): deadline = 28, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.2, None: 1.7142715009469693, 'right': 0.2916666666666667, 'left': 0.0}
LearningAgent.update(): deadline = 27, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.2, None: 1.7714145220898891, 'right': 0.2916666666666667, 'left': 0.0}
LearningAgent.update(): deadline = 26, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 3.4718879225, None: 0.7909494991319443, 'right': 0.0, 'left': 0.20833757200846353}
LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 0.5
{'forward': 0.0, None: 0.0, 'right': 1.6978309364080102, 'left': 0.0}
LearningAgent.update(): deadline = 24, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': -0.2, None: 1.8173075109452965, 'right': 0.2916666666666667, 'left': 0.0}
LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.2, None: 1.8600959740840144, 'right': 0.2916666666666667, 'left': 0.0}
LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.2, None: 1.9001507298555365, 'right': 0.2916666666666667, 'left': 0.0}
LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 3.4718879225, None: 0.7909494991319443, 'right': 0.0, 'left': 0.2678393855068468}
LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 0.5
{'forward': -0.14285714285714285, None: 0.0, 'right': 0.9869082687973485, 'left': -0.00805639857611269}
LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1
{'forward': -0.1437271823173862, None: 0.0, 'right': 0.9869082687973485, 'left': -0.00805639857611269}
LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1
{'forward': -0.1437271823173862, None: 0.0, 'right': 1.071088439691912, 'left': -0.00805639857611269}
LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': 0.0, None: 0.0, 'right': 1.8392776232652708, 'left': 0.0}
LearningAgent.update(): deadline = 16, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': -0.16603632831761644, None: 1.9001507298555365, 'right': 0.2916666666666667, 'left': 0.0}
LearningAgent.update(): deadline = 15, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1
{'forward': -0.16603632831761644, None: 1.9287498254764033, 'right': 0.2916666666666667, 'left': 0.0}
LearningAgent.update(): deadline = 14, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 1.9560839610986547, 'right': 0.2916666666666667, 'left': 0.0}
LearningAgent.update(): deadline = 13, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 1.9822538650184771, 'right': 0.2916666666666667, 'left': 0.0}
LearningAgent.update(): deadline = 12, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 2.007348933598735, 'right': 0.2916666666666667, 'left': 0.0}
LearningAgent.update(): deadline = 11, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 3.479969255984791, None: 0.7909494991319443, 'right': 0.0, 'left': 0.2678393855068468}
LearningAgent.update(): deadline = 10, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.16603632831761644, None: 2.030645522264075, 'right': 0.2916666666666667, 'left': 0.0}
LearningAgent.update(): deadline = 9, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 2.0530778826402165, 'right': 0.2916666666666667, 'left': 0.0}
LearningAgent.update(): deadline = 8, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 3.479969255984791, None: 0.8899190106461671, 'right': 0.0, 'left': 0.2678393855068468}
LearningAgent.update(): deadline = 7, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 3.524757274518193, None: 0.8899190106461671, 'right': 0.0, 'left': 0.2678393855068468}
LearningAgent.update(): deadline = 6, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 3
Environment.reset(): Trial set up with start = (5, 3), destination = (7, 1), deadline = 20
RoutePlanner.route_to(): destination = (7, 1)
{'forward': 3.531238419392487, None: 0.8899190106461671, 'right': 0.0, 'left': 0.2678393855068468}
LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.16603632831761644, None: 2.073431950805039, 'right': 0.2916666666666667, 'left': 0.0}
LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 2.762417158184283, 'right': 0.2916666666666667, 'left': 0.0}
LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 3.0552358713204617, 'right': 0.2916666666666667, 'left': 0.0}
LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 3.235807411087772, 'right': 0.2916666666666667, 'left': 0.0}
LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 3.3493143797551745, None: 0.8899190106461671, 'right': 0.0, 'left': 0.2678393855068468}
LearningAgent.update(): deadline = 15, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 0.0, None: 0.0, 'right': 0.39326597990056816, 'left': 1.7063623289138499}
LearningAgent.update(): deadline = 14, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2
{'forward': -0.16603632831761644, None: 3.235807411087772, 'right': 0.2916666666666667, 'left': 0.2917393832374343}
LearningAgent.update(): deadline = 13, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1
{'forward': -0.14285714285714285, None: 0.0, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 12, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': 'left'}, action = forward, reward = -1
{'forward': -0.16603632831761644, None: 3.3001360221298763, 'right': 0.2916666666666667, 'left': 0.2917393832374343}
LearningAgent.update(): deadline = 11, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 3.3493143797551745, None: 0.8899190106461671, 'right': 0.22926510886394222, 'left': 0.2678393855068468}
LearningAgent.update(): deadline = 10, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 0.5
{'forward': 0.0, None: 0.0, 'right': 1.9463923783125563, 'left': 0.0}
LearningAgent.update(): deadline = 9, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': -0.1437271823173862, None: 0.0, 'right': 1.2383008700597495, 'left': -0.00805639857611269}
LearningAgent.update(): deadline = 8, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': -0.1437271823173862, None: 0.0, 'right': 1.5390188994540952, 'left': -0.00805639857611269}
LearningAgent.update(): deadline = 7, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 4
Environment.reset(): Trial set up with start = (7, 5), destination = (3, 3), deadline = 30
RoutePlanner.route_to(): destination = (3, 3)
{'forward': -1.0, None: 0.07692307692307693, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 30, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 0.15295857988165681, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 29, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 1.1300147928994082, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 28, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 1.1300147928994082, 'right': 0.0, 'left': -0.01974371301775152}
LearningAgent.update(): deadline = 27, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1
{'forward': 0.0, None: 0.0, 'right': 0.39326597990056816, 'left': 2.7392800922126983}
LearningAgent.update(): deadline = 26, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2
{'forward': -0.16603632831761644, None: 3.3001360221298763, 'right': 0.2916666666666667, 'left': 0.6700834421306744}
LearningAgent.update(): deadline = 25, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1
{'forward': 3.6488349483625195, None: 0.8899190106461671, 'right': 0.22926510886394222, 'left': 0.2678393855068468}
LearningAgent.update(): deadline = 24, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 3.89094740798679, None: 0.8899190106461671, 'right': 0.22926510886394222, 'left': 0.2678393855068468}
LearningAgent.update(): deadline = 23, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 3.85715970992663, None: 0.8899190106461671, 'right': 0.22926510886394222, 'left': 0.2678393855068468}
LearningAgent.update(): deadline = 22, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.1437271823173862, None: 0.0, 'right': 1.9472809893736325, 'left': -0.00805639857611269}
LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': -0.16603632831761644, None: 3.3562448662054893, 'right': 0.2916666666666667, 'left': 0.6700834421306744}
LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 3.405901193212407, 'right': 0.2916666666666667, 'left': 0.6700834421306744}
LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 5
Environment.reset(): Trial set up with start = (4, 1), destination = (2, 3), deadline = 20
RoutePlanner.route_to(): destination = (2, 3)
{'forward': -0.1437271823173862, None: 0.0, 'right': 1.9472809893736325, 'left': 0.05223862320058734}
LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1
{'forward': -0.1437271823173862, None: 0.0, 'right': 2.215256900724261, 'left': 0.05223862320058734}
LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': -0.16603632831761644, None: 3.895016014230546, 'right': 0.2916666666666667, 'left': 0.6700834421306744}
LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 4.102889813163255, 'right': 0.2916666666666667, 'left': 0.6700834421306744}
LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 4.2310786558384255, 'right': 0.2916666666666667, 'left': 0.6700834421306744}
LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 3.6329979259360967, None: 0.8899190106461671, 'right': 0.22926510886394222, 'left': 0.2678393855068468}
LearningAgent.update(): deadline = 15, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -1.0, None: 1.2961143491124258, 'right': 0.0, 'left': -0.01974371301775152}
LearningAgent.update(): deadline = 14, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 1.2961143491124258, 'right': 0.5980080395076137, 'left': -0.01974371301775152}
LearningAgent.update(): deadline = 13, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 0.5
{'forward': 3.840862256094609, None: 0.8899190106461671, 'right': 0.22926510886394222, 'left': 0.2678393855068468}
LearningAgent.update(): deadline = 12, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.16603632831761644, None: 4.2310786558384255, 'right': 0.2916666666666667, 'left': 0.9108751190471728}
LearningAgent.update(): deadline = 11, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1
{'forward': -0.16603632831761644, None: 4.271671789352229, 'right': 0.2916666666666667, 'left': 0.9108751190471728}
LearningAgent.update(): deadline = 10, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 4.307596712511946, 'right': 0.2916666666666667, 'left': 0.9108751190471728}
LearningAgent.update(): deadline = 9, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 3.9703050435115004, None: 0.8899190106461671, 'right': 0.22926510886394222, 'left': 0.2678393855068468}
LearningAgent.update(): deadline = 8, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 6
Environment.reset(): Trial set up with start = (3, 3), destination = (6, 5), deadline = 25
RoutePlanner.route_to(): destination = (6, 5)
{'forward': 0.19858069713463514, None: 0.0, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': 'right', 'left': None}, action = forward, reward = 0.5
{'forward': -0.1437271823173862, None: 0.0, 'right': 2.335188285794379, 'left': 0.05223862320058734}
LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': 0.0, None: 0.0, 'right': 5.661457205635154, 'left': 0.0}
LearningAgent.update(): deadline = 23, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': 4.815881124573327, None: 0.8899190106461671, 'right': 0.22926510886394222, 'left': 0.2678393855068468}
LearningAgent.update(): deadline = 22, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.16603632831761644, None: 4.425550210219682, 'right': 0.2916666666666667, 'left': 0.9108751190471728}
LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 4.5095920773364435, 'right': 0.2916666666666667, 'left': 0.9108751190471728}
LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 5.019335552805857, None: 0.8899190106461671, 'right': 0.22926510886394222, 'left': 0.2678393855068468}
LearningAgent.update(): deadline = 19, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.16603632831761644, None: 4.563518942069699, 'right': 0.2916666666666667, 'left': 0.9108751190471728}
LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 4.608586393311063, 'right': 0.2916666666666667, 'left': 0.9108751190471728}
LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 4.64717539843648, 'right': 0.2916666666666667, 'left': 0.9108751190471728}
LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 4.904399385041342, None: 0.8899190106461671, 'right': 0.22926510886394222, 'left': 0.2678393855068468}
LearningAgent.update(): deadline = 15, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.1437271823173862, None: 0.0, 'right': 2.718543404943455, 'left': 0.05223862320058734}
LearningAgent.update(): deadline = 14, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': 4.99946299446222, None: 0.8899190106461671, 'right': 0.22926510886394222, 'left': 0.2678393855068468}
LearningAgent.update(): deadline = 13, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.16603632831761644, None: 4.64717539843648, 'right': 0.7100476631769346, 'left': 0.9108751190471728}
LearningAgent.update(): deadline = 12, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 0.5
{'forward': 0.0, None: 0.0, 'right': 5.557557566294137, 'left': 0.0}
LearningAgent.update(): deadline = 11, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': 0.0, None: 0.0, 'right': 5.640869449512414, 'left': 0.0}
LearningAgent.update(): deadline = 10, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': 0.0, None: 0.0, 'right': 5.681447722564446, 'left': 0.0}
LearningAgent.update(): deadline = 9, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 7
Environment.reset(): Trial set up with start = (6, 4), destination = (7, 1), deadline = 20
RoutePlanner.route_to(): destination = (7, 1)
{'forward': 0.0, None: 0.0, 'right': 5.520213314700766, 'left': 0.0}
LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': -1.0, None: 1.3464632770894969, 'right': 0.5980080395076137, 'left': -0.01974371301775152}
LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 2.1444937855260724, 'right': 0.5980080395076137, 'left': -0.01974371301775152}
LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 2.1444937855260724, 'right': 1.7043849668547753, 'left': -0.01974371301775152}
LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 0.5
{'forward': 0.0, None: 0.0, 'right': 5.910869315632395, 'left': 0.0}
LearningAgent.update(): deadline = 16, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': 0.0, None: 0.0, 'right': 5.51084246027478, 'left': 0.0}
LearningAgent.update(): deadline = 15, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': 0.0, None: 0.0, 'right': 5.274351583895983, 'left': 0.0}
LearningAgent.update(): deadline = 14, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': 0.0, None: 0.0, 'right': 0.39326597990056816, 'left': 3.3243240010593964}
LearningAgent.update(): deadline = 13, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2
{'forward': 5.178045930295173, None: 0.8899190106461671, 'right': 0.22926510886394222, 'left': 0.2678393855068468}
LearningAgent.update(): deadline = 12, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 5.178045930295173, None: 1.4538465144092583, 'right': 0.22926510886394222, 'left': 0.2678393855068468}
LearningAgent.update(): deadline = 11, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 4.6808335862403165, 'right': 0.7100476631769346, 'left': 0.9108751190471728}
LearningAgent.update(): deadline = 10, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 4.710621082446711, 'right': 0.7100476631769346, 'left': 0.9108751190471728}
LearningAgent.update(): deadline = 9, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 4.737294431322438, 'right': 0.7100476631769346, 'left': 0.9108751190471728}
LearningAgent.update(): deadline = 8, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 4.76141158426424, 'right': 0.7100476631769346, 'left': 0.9108751190471728}
LearningAgent.update(): deadline = 7, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 4.76141158426424, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 6, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 8
Environment.reset(): Trial set up with start = (5, 5), destination = (6, 1), deadline = 25
RoutePlanner.route_to(): destination = (6, 1)
{'forward': 5.152876606766982, None: 1.4538465144092583, 'right': 0.22926510886394222, 'left': 0.2678393855068468}
LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 0.0, None: 0.0, 'right': 0.39326597990056816, 'left': 3.229729429555154}
LearningAgent.update(): deadline = 24, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2
{'forward': -1.0, None: 0.0, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': 'forward', 'right': None, 'left': None}, action = forward, reward = -1
{'forward': 5.766410861259458, None: 1.4538465144092583, 'right': 0.22926510886394222, 'left': 0.2678393855068468}
LearningAgent.update(): deadline = 22, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 6.144756984863152, None: 1.4538465144092583, 'right': 0.22926510886394222, 'left': 0.2678393855068468}
LearningAgent.update(): deadline = 21, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 9
Environment.reset(): Trial set up with start = (8, 1), destination = (8, 5), deadline = 20
RoutePlanner.route_to(): destination = (8, 5)
{'forward': 0.0, None: 0.0, 'right': 5.761524547205408, 'left': 0.0}
LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': 6.1203677003035155, None: 1.4538465144092583, 'right': 0.22926510886394222, 'left': 0.2678393855068468}
LearningAgent.update(): deadline = 19, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.16603632831761644, None: 5.047199846624604, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 5.168659858127759, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 5.243560198554705, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 6.204532317420512, None: 1.4538465144092583, 'right': 0.22926510886394222, 'left': 0.2678393855068468}
LearningAgent.update(): deadline = 15, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.16603632831761644, None: 5.286253392598065, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 14, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 5.32076372444978, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 13, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 5.349604501782999, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 12, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 5.374299417374568, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 11, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 6.244934782681386, None: 1.4538465144092583, 'right': 0.22926510886394222, 'left': 0.2678393855068468}
LearningAgent.update(): deadline = 10, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.16603632831761644, None: 5.39368492611395, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 9, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.09090909090909091, None: 0.0, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 8, inputs = {'light': 'red', 'oncoming': None, 'right': 'forward', 'left': None}, action = forward, reward = -1
{'forward': -0.16603632831761644, None: 5.409597197870859, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 7, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 5.4241018455877335, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 6, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 5.941725155347002, None: 1.4538465144092583, 'right': 0.22926510886394222, 'left': 0.2678393855068468}
LearningAgent.update(): deadline = 5, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.16603632831761644, None: 5.436527493798522, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 4, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 5.448060048544161, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 3, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 5.458812459880535, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 2, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 5.468877911603753, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 1, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 5.978926264268907, None: 1.4538465144092583, 'right': 0.22926510886394222, 'left': 0.2678393855068468}
LearningAgent.update(): deadline = 0, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
Environment.reset(): Primary agent could not reach destination within deadline!
Simulator.run(): Trial 10
Environment.reset(): Trial set up with start = (2, 4), destination = (6, 5), deadline = 25
RoutePlanner.route_to(): destination = (6, 5)
{'forward': 6.03408431728689, None: 1.4538465144092583, 'right': 0.22926510886394222, 'left': 0.2678393855068468}
LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 6.064807412665704, None: 1.4538465144092583, 'right': 0.22926510886394222, 'left': 0.2678393855068468}
LearningAgent.update(): deadline = 24, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.16603632831761644, None: 5.64854622486319, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 5.724905257998451, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 5.771993328431861, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 6.33737713469074, None: 1.4538465144092583, 'right': 0.22926510886394222, 'left': 0.2678393855068468}
LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.16603632831761644, None: 5.798833528578905, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 5.820529357031099, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 5.838660870809004, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 6.4073669759949725, None: 1.4538465144092583, 'right': 0.22926510886394222, 'left': 0.2678393855068468}
LearningAgent.update(): deadline = 16, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 11
Environment.reset(): Trial set up with start = (5, 1), destination = (7, 6), deadline = 35
RoutePlanner.route_to(): destination = (7, 6)
{'forward': 6.469088616460826, None: 1.4538465144092583, 'right': 0.22926510886394222, 'left': 0.2678393855068468}
LearningAgent.update(): deadline = 35, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.16603632831761644, None: 5.852460967406632, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 34, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 5.974591822295637, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 33, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.026497435623464, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 32, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.058505897175625, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 31, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 6.469088616460826, None: 1.4538465144092583, 'right': 0.22926510886394222, 'left': 1.5502035054112842}
LearningAgent.update(): deadline = 30, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 0.5
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 12
Environment.reset(): Trial set up with start = (7, 2), destination = (4, 1), deadline = 20
RoutePlanner.route_to(): destination = (4, 1)
{'forward': 0.0, None: 0.0, 'right': 5.0092196377643265, 'left': 0.0}
LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': 1.4997450647983404, None: 0.0, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 19, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': 'left'}, action = forward, reward = 2
{'forward': 6.257836692099677, None: 1.4538465144092583, 'right': 0.22926510886394222, 'left': 1.5502035054112842}
LearningAgent.update(): deadline = 18, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 13
Environment.reset(): Trial set up with start = (1, 6), destination = (8, 4), deadline = 45
RoutePlanner.route_to(): destination = (8, 4)
{'forward': 6.788498940192202, None: 1.4538465144092583, 'right': 0.22926510886394222, 'left': 1.5502035054112842}
LearningAgent.update(): deadline = 45, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 6.788498940192202, None: 1.4538465144092583, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 44, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 0.5
{'forward': -1.0, None: 0.0, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 43, inputs = {'light': 'red', 'oncoming': 'left', 'right': None, 'left': None}, action = forward, reward = -1
{'forward': 2.3789183460498387, None: 0.0, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 42, inputs = {'light': 'green', 'oncoming': 'left', 'right': None, 'left': None}, action = forward, reward = 0.5
{'forward': 0.0, None: 0.0, 'right': 5.722723096042644, 'left': 0.0}
LearningAgent.update(): deadline = 41, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': -0.25, None: 0.0, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 40, inputs = {'light': 'red', 'oncoming': None, 'right': 'right', 'left': None}, action = forward, reward = -1
{'forward': 0.0, None: 0.0, 'right': 0.0, 'left': 1.0728629263272496}
LearningAgent.update(): deadline = 39, inputs = {'light': 'green', 'oncoming': None, 'right': 'right', 'left': None}, action = left, reward = 0.5
{'forward': 0.0, None: 0.0, 'right': 5.960557582135417, 'left': 0.0}
LearningAgent.update(): deadline = 38, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': -0.16603632831761644, None: 6.071537913664718, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 37, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 6.911214585063599, None: 1.4538465144092583, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 36, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 6.938947100791533, None: 1.4538465144092583, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 35, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.16603632831761644, None: 6.080464844959748, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 34, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.088458506164842, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 33, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.0956861081711144, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 32, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.102274345384525, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 31, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 7.007458381854481, None: 1.4538465144092583, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 30, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 6.827678616010978, None: 1.4538465144092583, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 29, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 14
Environment.reset(): Trial set up with start = (1, 6), destination = (7, 1), deadline = 55
RoutePlanner.route_to(): destination = (7, 1)
{'forward': -0.16603632831761644, None: 6.107565523396545, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 55, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.112807096614702, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 54, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.1958860321224964, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 53, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 7.315602719810155, None: 1.4538465144092583, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 52, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 7.616489250486315, None: 1.4538465144092583, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 51, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 7.528992719690767, None: 1.4538465144092583, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 50, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.16603632831761644, None: 6.210009451158823, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 49, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.221425881546519, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 48, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 7.494595473922735, None: 1.4538465144092583, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 47, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.16603632831761644, None: 6.229774146267522, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 46, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 7.472452423967697, None: 1.4538465144092583, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 45, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.16603632831761644, None: 6.236327534073508, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 44, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 7.472452423967697, None: 1.9900045185877384, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 43, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 7.245187223230546, None: 1.9900045185877384, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 42, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 0.0, None: 0.0, 'right': 0.39326597990056816, 'left': 3.6088586380313705}
LearningAgent.update(): deadline = 41, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2
{'forward': 7.249165164711399, None: 1.9900045185877384, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 40, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.16603632831761644, None: 6.24063092539944, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 39, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.24462501047382, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 38, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.248348907440228, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 37, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.251834888767115, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 36, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 7.252580664224065, None: 1.9900045185877384, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 35, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.16603632831761644, None: 6.254946127101362, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 34, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.257886988098257, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 33, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.260674122270315, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 32, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.26332189973377, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 31, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 7.290585368405999, None: 1.9900045185877384, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 30, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 15
Environment.reset(): Trial set up with start = (3, 3), destination = (7, 4), deadline = 25
RoutePlanner.route_to(): destination = (7, 4)
{'forward': 0.0, None: 0.0, 'right': 5.960557582135417, 'left': 0.1427011936930666}
LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 0.5
{'forward': 0.0, None: 0.0, 'right': 0.39326597990056816, 'left': 3.7923841950359196}
LearningAgent.update(): deadline = 24, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2
{'forward': 8.1969975631451, None: 1.9900045185877384, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 23, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.16603632831761644, None: 6.293572757253736, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.3122274527243825, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.325518923247218, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 8.351087636250748, None: 1.9900045185877384, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 19, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 16
Environment.reset(): Trial set up with start = (8, 2), destination = (3, 1), deadline = 30
RoutePlanner.route_to(): destination = (3, 1)
{'forward': 8.475643778677812, None: 1.9900045185877384, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 30, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 8.5970860175442, None: 1.9900045185877384, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 29, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 7.376691084760135, None: 1.9900045185877384, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 28, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.16603632831761644, None: 6.351105004003676, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 27, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.366883087136826, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 26, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 7.385480969586677, None: 1.9900045185877384, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 6.7705371545097295, None: 1.9900045185877384, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 24, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 17
Environment.reset(): Trial set up with start = (5, 2), destination = (8, 6), deadline = 35
RoutePlanner.route_to(): destination = (8, 6)
{'forward': -1.0, None: 2.2575481075545873, 'right': 1.7043849668547753, 'left': -0.01974371301775152}
LearningAgent.update(): deadline = 35, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 2.3677760715323894, 'right': 1.7043849668547753, 'left': -0.01974371301775152}
LearningAgent.update(): deadline = 34, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 3.012609660802531, 'right': 1.7043849668547753, 'left': -0.01974371301775152}
LearningAgent.update(): deadline = 33, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 3.286663936242341, 'right': 1.7043849668547753, 'left': -0.01974371301775152}
LearningAgent.update(): deadline = 32, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 3.4556640727635575, 'right': 1.7043849668547753, 'left': -0.01974371301775152}
LearningAgent.update(): deadline = 31, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 0.0, None: 0.0, 'right': 0.39326597990056816, 'left': 3.3442881462769396}
LearningAgent.update(): deadline = 30, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2
{'forward': 1.550991316266654, None: 0.0, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 29, inputs = {'light': 'green', 'oncoming': None, 'right': 'left', 'left': 'left'}, action = forward, reward = 2
{'forward': 6.8198599528939585, None: 1.9900045185877384, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 28, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.1437271823173862, None: 0.0, 'right': 3.4440201985172276, 'left': 0.05223862320058734}
LearningAgent.update(): deadline = 27, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': 6.893858786790502, None: 1.9900045185877384, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 26, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.16603632831761644, None: 6.371879480128991, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 25, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.376301287927055, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 6.893858786790502, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 23, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 6.974352218622287, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 22, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 18
Environment.reset(): Trial set up with start = (8, 1), destination = (5, 6), deadline = 40
RoutePlanner.route_to(): destination = (5, 6)
{'forward': 7.047725077638184, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 40, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 7.120251326742358, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 39, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 4.842644924335398, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 38, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 0.0, None: 0.0, 'right': 0.39326597990056816, 'left': 5.382072120507468}
LearningAgent.update(): deadline = 37, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2
{'forward': -0.16603632831761644, None: 6.390819556864036, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 36, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 5.16104573967282, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 35, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.16603632831761644, None: 6.3990949701581155, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 34, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.40578426257083, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 33, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.411374599801455, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 32, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 5.314276132053955, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 31, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 5.447927085408611, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 30, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 19
Environment.reset(): Trial set up with start = (5, 6), destination = (8, 3), deadline = 30
RoutePlanner.route_to(): destination = (8, 3)
{'forward': 0.0, None: 0.0, 'right': 0.39326597990056816, 'left': 5.506938710716454}
LearningAgent.update(): deadline = 30, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2
{'forward': 5.648101217850874, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 29, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.16603632831761644, None: 6.4496684098312365, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 28, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 5.292707839849949, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 27, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 0.0, None: 0.0, 'right': 0.39326597990056816, 'left': 4.7628869088371655}
LearningAgent.update(): deadline = 26, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2
{'forward': 2.7495092145668694, None: 0.0, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': 'left'}, action = forward, reward = 2
{'forward': -0.16603632831761644, None: 6.4561783575363005, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.46144056526456, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.465838267437463, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 20
Environment.reset(): Trial set up with start = (2, 1), destination = (7, 3), deadline = 35
RoutePlanner.route_to(): destination = (7, 3)
{'forward': 0.0, None: 0.0, 'right': 0.39326597990056816, 'left': 4.979876253216577}
LearningAgent.update(): deadline = 35, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2
{'forward': 5.568114675783936, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 34, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.16603632831761644, None: 6.4959625273218435, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 33, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.508765337772705, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 32, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.5166604042174034, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 31, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 6.060876342734151, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 30, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.16603632831761644, None: 6.521160592090881, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 29, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.524798243955276, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 28, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 6.216714706818419, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 27, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 6.322934611568005, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 26, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.1437271823173862, None: 0.0, 'right': 3.899804455055534, 'left': 0.05223862320058734}
LearningAgent.update(): deadline = 25, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': -0.1, None: 0.0, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': 'forward'}, action = forward, reward = -1
{'forward': -0.16603632831761644, None: 6.526732813355886, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.52848198652227, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.530076425139321, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 21
Environment.reset(): Trial set up with start = (4, 4), destination = (8, 5), deadline = 25
RoutePlanner.route_to(): destination = (8, 5)
{'forward': 6.410622493696607, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.16603632831761644, None: 6.5315398920128285, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.551808908210904, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 6.929825806669362, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 22, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 7.250001183002561, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 21, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.16603632831761644, None: 6.556116074152995, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.559432591928406, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.5621134437968625, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.564353870001216, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.566272234938693, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 7.0349825834241875, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 15, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 22
Environment.reset(): Trial set up with start = (1, 2), destination = (5, 6), deadline = 40
RoutePlanner.route_to(): destination = (5, 6)
{'forward': -0.1437271823173862, None: 0.0, 'right': 4.216471404031491, 'left': 0.05223862320058734}
LearningAgent.update(): deadline = 40, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': 0.0, None: 0.0, 'right': 6.162475343512932, 'left': 0.1427011936930666}
LearningAgent.update(): deadline = 39, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': 7.581331399697889, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 38, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.16603632831761644, None: 6.573801817318291, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 37, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.578445059785709, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 36, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 7.583918124977879, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 35, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.16603632831761644, None: 6.581091707992138, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 34, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.583231081959001, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 33, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.5850189873455935, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 32, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.586549881332864, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 31, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 7.3617050770277555, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 30, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.1437271823173862, None: 0.0, 'right': 4.554681003541636, 'left': 0.05223862320058734}
LearningAgent.update(): deadline = 29, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': -0.16603632831761644, None: 6.587642382951053, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 28, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.588630186497498, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 27, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.589530607422526, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 26, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 7.425686808345316, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 7.484763273595195, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 24, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 7.539593617905241, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 23, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.16603632831761644, None: 6.590211219709975, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.590848348434613, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.591446914104866, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 23
Environment.reset(): Trial set up with start = (5, 4), destination = (3, 6), deadline = 20
RoutePlanner.route_to(): destination = (3, 6)
{'forward': -0.1437271823173862, None: 0.0, 'right': 4.688852155463853, 'left': 0.05223862320058734}
LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': 0.0, None: 0.0, 'right': 6.234488070186742, 'left': 0.1427011936930666}
LearningAgent.update(): deadline = 19, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': -0.16603632831761644, None: 6.602729876989136, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.60752513621495, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.610482212737536, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 7.212918917237453, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 15, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -1.0, None: 3.551994150580651, 'right': 1.7043849668547753, 'left': -0.01974371301775152}
LearningAgent.update(): deadline = 14, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 3.6298609634828014, 'right': 1.7043849668547753, 'left': -0.01974371301775152}
LearningAgent.update(): deadline = 13, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 3.69493537140817, 'right': 1.7043849668547753, 'left': -0.01974371301775152}
LearningAgent.update(): deadline = 12, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 24
Environment.reset(): Trial set up with start = (3, 6), destination = (6, 4), deadline = 25
RoutePlanner.route_to(): destination = (6, 4)
{'forward': -0.1437271823173862, None: 0.0, 'right': 5.055109371134234, 'left': 0.05223862320058734}
LearningAgent.update(): deadline = 25, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': -0.16603632831761644, None: 6.611535671248707, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.619805320561401, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.623319921519296, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 7.518939638042248, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 21, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.16603632831761644, None: 6.624945424462322, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.626197061728452, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.627208801851907, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.62805432752651, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.628778308885387, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 7.376045768841341, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 15, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 0.0, None: 0.0, 'right': 0.39326597990056816, 'left': 4.681888627894919}
LearningAgent.update(): deadline = 14, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2
{'forward': -0.09090909090909091, None: 0.0, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 13, inputs = {'light': 'red', 'oncoming': 'left', 'right': None, 'left': None}, action = forward, reward = -1
{'forward': -0.09090909090909091, None: 0.08333333333333333, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 12, inputs = {'light': 'red', 'oncoming': 'left', 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.09090909090909091, None: 0.15929487179487178, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 11, inputs = {'light': 'red', 'oncoming': 'left', 'right': None, 'left': None}, action = None, reward = 1
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 25
Environment.reset(): Trial set up with start = (6, 5), destination = (7, 2), deadline = 20
RoutePlanner.route_to(): destination = (7, 2)
{'forward': 0.0, None: 0.0, 'right': 0.39326597990056816, 'left': 4.77458267831033}
LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2
{'forward': 0.0, None: 0.0, 'right': 0.39326597990056816, 'left': 4.97885974147049}
LearningAgent.update(): deadline = 19, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2
{'forward': -0.16603632831761644, None: 6.634461562552579, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.636876945361135, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.638366431426412, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 7.442687193309119, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 15, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.16603632831761644, None: 6.63921543848362, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 14, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.639901719188196, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 13, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.640475253777021, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 12, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.640966342768702, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 11, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 26
Environment.reset(): Trial set up with start = (4, 4), destination = (7, 2), deadline = 25
RoutePlanner.route_to(): destination = (7, 2)
{'forward': -0.1437271823173862, None: 0.0, 'right': 5.418573231487403, 'left': 0.05223862320058734}
LearningAgent.update(): deadline = 25, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': 7.540864628976189, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 24, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 6.232030780249916, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 23, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 0.0, None: 0.0, 'right': 0.39326597990056816, 'left': 6.1380429523414595}
LearningAgent.update(): deadline = 22, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 27
Environment.reset(): Trial set up with start = (2, 3), destination = (8, 5), deadline = 40
RoutePlanner.route_to(): destination = (8, 5)
{'forward': 0.0, None: 0.0, 'right': 6.588734101195305, 'left': 0.1427011936930666}
LearningAgent.update(): deadline = 40, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': 6.702960983951076, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 39, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.16603632831761644, None: 6.644821391353396, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 38, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 7.200238910154745, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 37, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 7.349525334319959, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 36, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 7.573918134282961, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 35, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 7.380291956779227, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 34, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.1437271823173862, None: 0.0, 'right': 5.790160723347901, 'left': 0.05223862320058734}
LearningAgent.update(): deadline = 33, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': -0.16603632831761644, None: 6.645289504395824, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 32, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 28
Environment.reset(): Trial set up with start = (8, 5), destination = (2, 6), deadline = 35
RoutePlanner.route_to(): destination = (2, 6)
{'forward': -0.16603632831761644, None: 6.645690326188402, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 35, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.64608363257237, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 34, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.649171087686514, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 33, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 7.516043690656382, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 32, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 7.561294268615434, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 31, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.16603632831761644, None: 6.64982717189827, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 30, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 7.734455440556972, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 29, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 7.720771716483064, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 28, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.16603632831761644, None: 6.6501880182147355, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 27, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.650496992873209, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 26, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 7.71323290842297, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.16603632831761644, None: 6.650739537980111, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 7.4793658318115135, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 23, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -1.0, None: 3.732082012598901, 'right': 1.7043849668547753, 'left': -0.01974371301775152}
LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 3.7659426047612214, 'right': 1.7043849668547753, 'left': -0.01974371301775152}
LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 29
Environment.reset(): Trial set up with start = (7, 1), destination = (3, 3), deadline = 30
RoutePlanner.route_to(): destination = (3, 3)
{'forward': -1.0, None: 3.79702179113878, 'right': 1.7043849668547753, 'left': -0.01974371301775152}
LearningAgent.update(): deadline = 30, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 3.8277679862337215, 'right': 1.7043849668547753, 'left': -0.01974371301775152}
LearningAgent.update(): deadline = 29, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 4.253602788298663, 'right': 1.7043849668547753, 'left': -0.01974371301775152}
LearningAgent.update(): deadline = 28, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 4.434582579176263, 'right': 1.7043849668547753, 'left': -0.01974371301775152}
LearningAgent.update(): deadline = 27, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 4.546186783550784, 'right': 1.7043849668547753, 'left': -0.01974371301775152}
LearningAgent.update(): deadline = 26, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 0.0, None: 0.0, 'right': 0.39326597990056816, 'left': 6.5168143660768685}
LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2
{'forward': -0.16603632831761644, None: 6.6512173518407085, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.651603584711357, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.651926365038971, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.65220274569449, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 7.498810998703602, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.16603632831761644, None: 6.652419704509073, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 7.578372666903099, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 18, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 7.435529841829354, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 17, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -1.0, None: 4.570653859125199, 'right': 1.7043849668547753, 'left': -0.01974371301775152}
LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 0.0, None: 0.0, 'right': 0.39326597990056816, 'left': 6.645627651753874}
LearningAgent.update(): deadline = 15, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 30
Environment.reset(): Trial set up with start = (6, 4), destination = (1, 5), deadline = 30
RoutePlanner.route_to(): destination = (1, 5)
{'forward': -1.0, None: 4.591613987200613, 'right': 1.7043849668547753, 'left': -0.01974371301775152}
LearningAgent.update(): deadline = 30, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 4.612364513995274, 'right': 1.7043849668547753, 'left': -0.01974371301775152}
LearningAgent.update(): deadline = 29, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 4.920509836895983, 'right': 1.7043849668547753, 'left': -0.01974371301775152}
LearningAgent.update(): deadline = 28, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 0.0, None: 0.0, 'right': 0.39326597990056816, 'left': 7.150092200293294}
LearningAgent.update(): deadline = 27, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2
{'forward': -0.16603632831761644, None: 6.653132052616954, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 26, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.653639600643817, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 25, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 7.612463946574473, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 24, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 7.619652232236602, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 23, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.16603632831761644, None: 6.653918752058593, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 7.726783752882165, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 21, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 7.555189264935433, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -1.0, None: 4.946702189342544, 'right': 1.7043849668547753, 'left': -0.01974371301775152}
LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 31
Environment.reset(): Trial set up with start = (5, 6), destination = (5, 2), deadline = 20
RoutePlanner.route_to(): destination = (5, 2)
{'forward': 0.0, None: 0.0, 'right': 0.39326597990056816, 'left': 7.19606844928934}
LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2
{'forward': -0.16603632831761644, None: 6.654092587257795, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.655978699169125, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 7.9885500700652745, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 17, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 8.255789233228677, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 16, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 32
Environment.reset(): Trial set up with start = (6, 5), destination = (5, 2), deadline = 20
RoutePlanner.route_to(): destination = (5, 2)
{'forward': -0.1437271823173862, None: 0.0, 'right': 6.242726539014928, 'left': 0.05223862320058734}
LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': 0.0, None: 0.0, 'right': 6.768129965437151, 'left': 0.1427011936930666}
LearningAgent.update(): deadline = 19, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': -0.1437271823173862, None: 0.0, 'right': 9.017420848244376, 'left': 0.05223862320058734}
LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': -0.25, None: 0.5, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': 'right', 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.6565130975440026, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.656893856386102, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 15, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 8.408115556231817, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 14, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 8.531246000659355, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 13, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 33
Environment.reset(): Trial set up with start = (5, 5), destination = (8, 3), deadline = 25
RoutePlanner.route_to(): destination = (8, 3)
{'forward': -0.16603632831761644, None: 6.657103273749257, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 25, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.657308203597488, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.658711973057865, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 8.891402550609904, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 22, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 8.48090342610633, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 21, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.16603632831761644, None: 6.659010274068194, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.659239965846148, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.659425633366661, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 8.428868391219131, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 17, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -1.0, None: 4.978951523292371, 'right': 1.7043849668547753, 'left': -0.01974371301775152}
LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 5.007080109015275, 'right': 1.7043849668547753, 'left': -0.01974371301775152}
LearningAgent.update(): deadline = 15, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 5.0319739073800465, 'right': 1.7043849668547753, 'left': -0.01974371301775152}
LearningAgent.update(): deadline = 14, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 0.6967761938669329, None: 0.0, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 13, inputs = {'light': 'green', 'oncoming': 'right', 'right': None, 'left': None}, action = forward, reward = 0.5
{'forward': 8.490174202995558, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 12, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 8.42635401725449, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 11, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 8.371651000905002, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 10, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.16603632831761644, None: 6.659498043699661, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 9, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.659565249539977, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 8, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.659627909102859, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 7, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.659686565415891, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 6, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 8.334234294573346, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 5, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 8.371727537364045, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 4, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 8.33787068228021, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 3, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.16603632831761644, None: 6.659734157015328, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 2, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 8.328252747480894, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 1, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 0.0, None: 0.0, 'right': 0.39326597990056816, 'left': 7.215431181963244}
LearningAgent.update(): deadline = 0, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2
Environment.reset(): Primary agent could not reach destination within deadline!
Simulator.run(): Trial 34
Environment.reset(): Trial set up with start = (1, 5), destination = (5, 3), deadline = 30
RoutePlanner.route_to(): destination = (5, 3)
{'forward': -0.16603632831761644, None: 6.659775752073236, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 30, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.659817097560797, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 29, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.660844532926677, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 28, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.661281192957176, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 27, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 8.106198169658462, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 26, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.16603632831761644, None: 6.661483148221282, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 25, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 1.532452135197618, None: 0.0, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 24, inputs = {'light': 'green', 'oncoming': 'forward', 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.16603632831761644, None: 6.661612736182417, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.661721034692794, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 8.204206953977366, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 21, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.16603632831761644, None: 6.661803461892358, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.661876409963973, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.661941731646283, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.6620007933340375, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.66205463033403, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 8.199129064741037, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 15, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 0.0, None: 0.0, 'right': 0.39326597990056816, 'left': 7.245252198884623}
LearningAgent.update(): deadline = 14, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2
{'forward': -0.16603632831761644, None: 6.662097868174649, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 13, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 35
Environment.reset(): Trial set up with start = (2, 5), destination = (4, 1), deadline = 30
RoutePlanner.route_to(): destination = (4, 1)
{'forward': 8.167579307282649, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 30, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.16603632831761644, None: 6.662138181102519, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 29, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.662817453937142, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 28, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 8.163021838167289, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 27, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 0.0, None: 0.0, 'right': 0.39326597990056816, 'left': 7.809690986737148}
LearningAgent.update(): deadline = 26, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2
{'forward': -0.16603632831761644, None: 6.662961799414499, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 25, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.663072945432065, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.66316278846293, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.663237871567296, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.663302161475409, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 8.10755350473249, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.16603632831761644, None: 6.663352629053278, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 8.178814138758865, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 18, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 36
Environment.reset(): Trial set up with start = (6, 2), destination = (3, 3), deadline = 20
RoutePlanner.route_to(): destination = (3, 3)
{'forward': 0.0, None: 0.0, 'right': 0.39326597990056816, 'left': 7.797537549066992}
LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2
{'forward': -0.16603632831761644, None: 6.663394054523444, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.663884946344927, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.6640935753690576, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.664222229933939, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 8.372108608555408, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 15, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.16603632831761644, None: 6.664295563035921, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 14, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.6643548406266895, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 13, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.664404379756118, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 12, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 8.110242260145112, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 11, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -1.0, None: 5.05921878670149, 'right': 1.7043849668547753, 'left': -0.01974371301775152}
LearningAgent.update(): deadline = 10, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 5.083330504900968, 'right': 1.7043849668547753, 'left': -0.01974371301775152}
LearningAgent.update(): deadline = 9, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 37
Environment.reset(): Trial set up with start = (3, 4), destination = (8, 4), deadline = 25
RoutePlanner.route_to(): destination = (8, 4)
{'forward': -0.1437271823173862, None: 0.0, 'right': 8.89445020047604, 'left': 0.05223862320058734}
LearningAgent.update(): deadline = 25, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': -0.16603632831761644, None: 6.66443522912308, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.664769944754617, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.664912198898021, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.664999922286453, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 8.30610817538967, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.16603632831761644, None: 6.66504992461786, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.66509034316908, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.665124121529743, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 8.400368647101114, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 16, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 8.318700520012133, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 15, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.16603632831761644, None: 6.6651472597067976, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 14, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.6651679788926135, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 13, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.665186712489789, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 12, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.6652037888841384, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 11, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 38
Environment.reset(): Trial set up with start = (5, 2), destination = (1, 3), deadline = 25
RoutePlanner.route_to(): destination = (1, 3)
{'forward': -1.0, None: 5.100294820919887, 'right': 1.7043849668547753, 'left': -0.01974371301775152}
LearningAgent.update(): deadline = 25, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 5.11707737641003, 'right': 1.7043849668547753, 'left': -0.01974371301775152}
LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 5.349515769948526, 'right': 1.7043849668547753, 'left': -0.01974371301775152}
LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 5.448302087202386, 'right': 1.7043849668547753, 'left': -0.01974371301775152}
LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 5.5092203161756, 'right': 1.7043849668547753, 'left': -0.01974371301775152}
LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 0.0, None: 0.0, 'right': 0.39326597990056816, 'left': 7.7645089669381235}
LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2
{'forward': 8.188045060120011, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 19, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.16603632831761644, None: 6.665240360828701, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.665270924525229, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 8.28451921524276, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 16, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.16603632831761644, None: 6.665294186894252, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 15, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.665314774090839, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 14, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.665333208989599, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 13, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.665349877210563, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 12, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.665365070935057, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 11, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 8.307041601432378, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 10, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 1.1543901383569721, None: 0.0, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 9, inputs = {'light': 'green', 'oncoming': 'right', 'right': None, 'left': None}, action = forward, reward = 0.5
{'forward': 8.35416308641895, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 8, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 8.398096941538782, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 7, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 8.357400462025227, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 6, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 8.396684142588187, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 5, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.16603632831761644, None: 6.665374832903044, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 4, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.66538406028707, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 3, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.665392805330567, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 2, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 8.364897174846568, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 1, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.16603632831761644, None: 6.665400766963918, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 0, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
Environment.reset(): Primary agent could not reach destination within deadline!
Simulator.run(): Trial 39
Environment.reset(): Trial set up with start = (4, 3), destination = (8, 2), deadline = 25
RoutePlanner.route_to(): destination = (8, 2)
{'forward': 0.0, None: 0.0, 'right': 6.879816073635849, 'left': 0.1427011936930666}
LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': -0.1437271823173862, None: 0.0, 'right': 8.84529581853377, 'left': 0.05223862320058734}
LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': -0.16603632831761644, None: 6.66559065191933, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.66567135302538, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.665721118707445, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 8.190138618860258, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 8.085283485268473, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 19, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.16603632831761644, None: 6.665744757406426, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.665764512604859, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.665781427993518, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 40
Environment.reset(): Trial set up with start = (5, 2), destination = (7, 5), deadline = 25
RoutePlanner.route_to(): destination = (7, 5)
{'forward': 0.0, None: 0.0, 'right': 0.39326597990056816, 'left': 7.753553994366609}
LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2
{'forward': -0.16603632831761644, None: 6.6657961819714036, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.665926754675693, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 7.966563573929472, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 22, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 0.0, None: 0.0, 'right': 7.1418899629153465, 'left': 0.1427011936930666}
LearningAgent.update(): deadline = 21, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': 7.8914321158156895, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.16603632831761644, None: 6.665948952035423, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.665966894901204, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.665981890010464, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.665994729572768, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 41
Environment.reset(): Trial set up with start = (7, 3), destination = (4, 5), deadline = 25
RoutePlanner.route_to(): destination = (4, 5)
{'forward': -0.1437271823173862, None: 0.0, 'right': 8.8300093163015, 'left': 0.05223862320058734}
LearningAgent.update(): deadline = 25, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': 7.982130469440984, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 24, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 8.590520895211618, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 23, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -1.0, None: 5.59602879246243, 'right': 1.7043849668547753, 'left': -0.01974371301775152}
LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 5.649560686172642, 'right': 1.7043849668547753, 'left': -0.01974371301775152}
LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 5.687702160441169, 'right': 1.7043849668547753, 'left': -0.01974371301775152}
LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 0.0, None: 0.0, 'right': 0.39326597990056816, 'left': 7.736062299520658}
LearningAgent.update(): deadline = 19, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2
{'forward': -0.16603632831761644, None: 6.666011528000116, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.14285714285714285, None: 0.0, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': 'right'}, action = forward, reward = -1
{'forward': -0.16603632831761644, None: 6.666023811850114, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 42
Environment.reset(): Trial set up with start = (5, 3), destination = (8, 6), deadline = 30
RoutePlanner.route_to(): destination = (8, 6)
{'forward': -0.1437271823173862, None: 0.0, 'right': 8.745631222098893, 'left': 0.05223862320058734}
LearningAgent.update(): deadline = 30, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': 0.0, None: 0.0, 'right': 7.200137771488373, 'left': 0.1427011936930666}
LearningAgent.update(): deadline = 29, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': -0.16603632831761644, None: 6.666120240072597, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 28, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 8.946231828070747, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 27, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 9.108750064975185, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 26, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.1437271823173862, None: 0.0, 'right': 8.475773967589596, 'left': 0.05223862320058734}
LearningAgent.update(): deadline = 25, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': -0.16603632831761644, None: 6.666136632870419, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.666149883715326, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.666160957635713, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.666170439680043, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 9.179159786114486, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 9.241472389322768, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 19, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.16603632831761644, None: 6.666177206411678, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.08333333333333333, None: 0.0, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': 'right', 'right': None, 'left': None}, action = forward, reward = -1
{'forward': -0.16603632831761644, None: 6.666182854030006, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 43
Environment.reset(): Trial set up with start = (4, 3), destination = (3, 6), deadline = 20
RoutePlanner.route_to(): destination = (3, 6)
{'forward': 9.19391385827061, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 0.0, None: 0.0, 'right': 0.39326597990056816, 'left': 7.884545476664184}
LearningAgent.update(): deadline = 19, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2
{'forward': 7.666255425925505, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 18, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 44
Environment.reset(): Trial set up with start = (4, 3), destination = (8, 6), deadline = 35
RoutePlanner.route_to(): destination = (8, 6)
{'forward': -0.1437271823173862, None: 0.0, 'right': 8.297945536677357, 'left': 0.05223862320058734}
LearningAgent.update(): deadline = 35, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': 0.0, None: 0.0, 'right': 7.858227441762526, 'left': 0.1427011936930666}
LearningAgent.update(): deadline = 34, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': 7.666255425925505, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 33, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 7.666255425925505, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 32, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.16603632831761644, None: 6.6662070446618396, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 31, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 7.919564900818665, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 30, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 0.0, None: 0.0, 'right': 8.032907986549194, 'left': 0.1427011936930666}
LearningAgent.update(): deadline = 29, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': 7.877350082009316, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 28, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.16603632831761644, None: 6.6662168937048, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 27, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 7.979649767971641, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 26, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 45
Environment.reset(): Trial set up with start = (2, 6), destination = (5, 2), deadline = 35
RoutePlanner.route_to(): destination = (5, 2)
{'forward': 0.0, None: 0.0, 'right': 0.39326597990056816, 'left': 7.860294241440283}
LearningAgent.update(): deadline = 35, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2
{'forward': -0.16603632831761644, None: 6.66622438992083, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 34, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.666290731432706, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 33, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.6663189265752525, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 32, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 7.875223541177416, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 31, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.16603632831761644, None: 6.666331966828681, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 30, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.666342007823821, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 29, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.666350124294892, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 28, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 7.990370193184106, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 27, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 0.0, None: 0.0, 'right': 0.39326597990056816, 'left': 7.976734294286059}
LearningAgent.update(): deadline = 26, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2
{'forward': 8.079419578853258, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 8.158228285170459, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 24, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.16603632831761644, None: 6.66635444078178, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.66635834360534, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.666361901179125, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 46
Environment.reset(): Trial set up with start = (7, 6), destination = (7, 1), deadline = 25
RoutePlanner.route_to(): destination = (7, 1)
{'forward': 8.213675839257919, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 8.268529312408727, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 24, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 7.666407616002257, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 23, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.16603632831761644, None: 6.6663847585906915, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.66639885399449, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 7.878917330402172, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 47
Environment.reset(): Trial set up with start = (8, 5), destination = (4, 1), deadline = 40
RoutePlanner.route_to(): destination = (4, 1)
{'forward': -1.0, None: 5.717071095627934, 'right': 1.7043849668547753, 'left': -0.01974371301775152}
LearningAgent.update(): deadline = 40, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 5.7455589627590955, 'right': 1.7043849668547753, 'left': -0.01974371301775152}
LearningAgent.update(): deadline = 39, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 5.8837251183452315, 'right': 1.7043849668547753, 'left': -0.01974371301775152}
LearningAgent.update(): deadline = 38, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 0.0, None: 0.0, 'right': 0.39326597990056816, 'left': 4.9883671471430295}
LearningAgent.update(): deadline = 37, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2
{'forward': -0.16603632831761644, None: 6.666412244628099, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 36, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.666421785454546, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 35, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.66642913189091, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 34, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.666435070260304, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 33, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 7.848567684590613, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 32, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 7.951407040504539, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 31, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 0.0, None: 0.0, 'right': 0.0, 'left': 1.7678750221316457}
LearningAgent.update(): deadline = 30, inputs = {'light': 'green', 'oncoming': None, 'right': 'right', 'left': None}, action = left, reward = 0.5
{'forward': 0.0, None: 0.0, 'right': 7.429617187894275, 'left': 0.1427011936930666}
LearningAgent.update(): deadline = 29, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': -0.1437271823173862, None: 0.0, 'right': 7.725405033343051, 'left': 0.05223862320058734}
LearningAgent.update(): deadline = 28, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': 0.6388724841434381, None: 0.0, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 27, inputs = {'light': 'green', 'oncoming': None, 'right': 'forward', 'left': None}, action = forward, reward = 2
{'forward': -0.16603632831761644, None: 6.666437742526532, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 26, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 7.931054543407612, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.16603632831761644, None: 6.666440031767934, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.66644215647011, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 7.978721709201073, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 22, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 48
Environment.reset(): Trial set up with start = (4, 1), destination = (8, 6), deadline = 45
RoutePlanner.route_to(): destination = (8, 6)
{'forward': 0.0, None: 0.0, 'right': 0.39326597990056816, 'left': 5.137150963023949}
LearningAgent.update(): deadline = 45, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2
{'forward': -0.16603632831761644, None: 6.666444027388414, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 44, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.666477423280152, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 43, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.66649161653414, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 42, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 7.874653764152056, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 41, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 8.079354247996353, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 40, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 8.126518320339109, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 39, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 0.0, None: 0.0, 'right': 7.469100635587566, 'left': 0.1427011936930666}
LearningAgent.update(): deadline = 38, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': 8.060803970869811, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 37, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.16603632831761644, None: 6.666494898724125, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 36, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 8.148679460244203, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 35, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 8.22644926834054, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 34, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.16603632831761644, None: 6.66649724101425, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 33, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.666499358834905, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 32, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.6665012893098865, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 31, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 49
Environment.reset(): Trial set up with start = (3, 2), destination = (1, 4), deadline = 20
RoutePlanner.route_to(): destination = (1, 4)
{'forward': 0.0, None: 0.0, 'right': 7.483202454182269, 'left': 0.1427011936930666}
LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': -0.16603632831761644, None: 6.666503061210138, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.6665276020286175, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.666538031876471, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.666544463615981, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 7.761481530897994, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 15, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -1.0, None: 5.907213364794875, 'right': 1.7043849668547753, 'left': -0.01974371301775152}
LearningAgent.update(): deadline = 14, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 5.926199697341669, 'right': 1.7043849668547753, 'left': -0.01974371301775152}
LearningAgent.update(): deadline = 13, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 5.942066846684348, 'right': 1.7043849668547753, 'left': -0.01974371301775152}
LearningAgent.update(): deadline = 12, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 0.8871574126579118, None: 0.0, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 11, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': 'right'}, action = forward, reward = 0.5
{'forward': 7.75093500458417, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 10, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.16603632831761644, None: 6.666546296661742, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 9, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.6665479380709, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 8, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.666549422178347, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 7, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.666550774999366, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 6, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 7.744908801310261, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 5, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.16603632831761644, None: 6.666551933916039, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 4, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.666553009535576, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 3, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 7.74030063994526, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 2, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.16603632831761644, None: 6.666553956678335, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 1, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 7.78445616120885, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 0, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
Environment.reset(): Primary agent could not reach destination within deadline!
Simulator.run(): Trial 50
Environment.reset(): Trial set up with start = (4, 1), destination = (8, 2), deadline = 25
RoutePlanner.route_to(): destination = (8, 2)
{'forward': -0.1437271823173862, None: 0.0, 'right': 7.722463324834728, 'left': 0.05223862320058734}
LearningAgent.update(): deadline = 25, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': -0.16603632831761644, None: 6.666554802003247, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.666571581702759, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.666578713075053, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 8.061900019815074, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 21, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.16603632831761644, None: 6.666582011334738, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.666584550994696, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.666586603886495, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.6665883195174995, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.666589788526546, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 8.149757241707043, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 15, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 8.170853726141832, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 14, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 51
Environment.reset(): Trial set up with start = (7, 1), destination = (3, 1), deadline = 20
RoutePlanner.route_to(): destination = (3, 1)
{'forward': -0.1437271823173862, None: 0.0, 'right': 7.8336235377788945, 'left': 0.05223862320058734}
LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': 8.241251175330806, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 19, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 9.005063499031184, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 18, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 52
Environment.reset(): Trial set up with start = (1, 4), destination = (7, 5), deadline = 35
RoutePlanner.route_to(): destination = (7, 5)
{'forward': 0.0, None: 0.0, 'right': 0.39326597990056816, 'left': 7.395727468600228}
LearningAgent.update(): deadline = 35, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2
{'forward': 9.329683736603846, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 34, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 9.930231176113269, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 33, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 10.185463837904773, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 32, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 10.342857312676202, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 31, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 9.921787986285167, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 30, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 53
Environment.reset(): Trial set up with start = (2, 6), destination = (7, 6), deadline = 25
RoutePlanner.route_to(): destination = (7, 6)
{'forward': -0.2, None: 0.0, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 25, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': 'right'}, action = forward, reward = -1
{'forward': -1.0, None: 5.963804841283818, 'right': 1.7043849668547753, 'left': -0.01974371301775152}
LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 0.0, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': 'left', 'right': None, 'left': None}, action = forward, reward = -1
{'forward': 0.0, None: 0.0, 'right': 0.39326597990056816, 'left': 7.531164394423897}
LearningAgent.update(): deadline = 22, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2
{'forward': 9.170059097605968, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 21, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.16603632831761644, None: 6.666592671456801, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.666594891313097, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.666596685696937, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 8.955280252639744, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 17, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.16603632831761644, None: 6.666597997840119, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 8.812094479920228, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 15, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.16603632831761644, None: 6.666599027872518, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 14, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 54
Environment.reset(): Trial set up with start = (8, 1), destination = (5, 2), deadline = 20
RoutePlanner.route_to(): destination = (5, 2)
{'forward': -0.1437271823173862, None: 0.0, 'right': 7.908619580445546, 'left': 0.05223862320058734}
LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': -0.1437271823173862, None: 0.0, 'right': 8.052406919307968, 'left': 0.05223862320058734}
LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': 7.66660917369164, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 18, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 55
Environment.reset(): Trial set up with start = (3, 2), destination = (8, 2), deadline = 25
RoutePlanner.route_to(): destination = (8, 2)
{'forward': 3.450744867630156, None: 0.0, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': 'left', 'left': None}, action = forward, reward = 0.5
{'forward': 0.0, None: 0.0, 'right': 0.39326597990056816, 'left': 8.023891096030894}
LearningAgent.update(): deadline = 24, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2
{'forward': 8.516617797637894, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 23, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.16603632831761644, None: 6.666604100782079, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.666607229076309, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.666609457985947, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 8.346617845967927, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 19, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.16603632831761644, None: 6.666610888202966, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.666612083455759, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.6666131068909635, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 8.42972977075735, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 15, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 8.29368020519074, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 14, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -1.0, None: 5.973389320720857, 'right': 1.7043849668547753, 'left': -0.01974371301775152}
LearningAgent.update(): deadline = 13, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 5.98205528754518, 'right': 1.7043849668547753, 'left': -0.01974371301775152}
LearningAgent.update(): deadline = 12, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 5.989954649611967, 'right': 1.7043849668547753, 'left': -0.01974371301775152}
LearningAgent.update(): deadline = 11, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 56
Environment.reset(): Trial set up with start = (1, 2), destination = (6, 1), deadline = 30
RoutePlanner.route_to(): destination = (6, 1)
{'forward': 8.248890272024067, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 30, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.16603632831761644, None: 6.666613680745703, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 29, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.666621628633847, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 28, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.666625006486308, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 27, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.666627089495327, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 26, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 6.68666770401805, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 1.5333266052142056, None: 0.0, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 24, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': 'forward'}, action = forward, reward = 2
{'forward': -0.16603632831761644, None: 6.66662807892461, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.666628905804798, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 6.809163562257553, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 21, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 7.032623992187409, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 57
Environment.reset(): Trial set up with start = (4, 1), destination = (1, 3), deadline = 25
RoutePlanner.route_to(): destination = (1, 3)
{'forward': 7.096025049962076, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.16603632831761644, None: 6.666629472217727, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.666635051385067, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.666637422531187, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.666638884737961, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 7.238679550478373, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.16603632831761644, None: 6.666639718195822, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.666640391907593, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.666640954938145, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.6666414370330545, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 7.222321983999684, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 15, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -1.0, None: 6.000105329867788, 'right': 1.7043849668547753, 'left': -0.01974371301775152}
LearningAgent.update(): deadline = 14, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.009194802642318, 'right': 1.7043849668547753, 'left': -0.01974371301775152}
LearningAgent.update(): deadline = 13, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.017413200942622, 'right': 1.7043849668547753, 'left': -0.01974371301775152}
LearningAgent.update(): deadline = 12, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.024904587085592, 'right': 1.7043849668547753, 'left': -0.01974371301775152}
LearningAgent.update(): deadline = 11, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 0.0, None: 0.0, 'right': 0.39326597990056816, 'left': 7.998373533562837}
LearningAgent.update(): deadline = 10, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2
{'forward': -0.16603632831761644, None: 6.666641689329391, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 9, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.666641923491928, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 8, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 58
Environment.reset(): Trial set up with start = (4, 2), destination = (6, 6), deadline = 30
RoutePlanner.route_to(): destination = (6, 6)
{'forward': 7.24845866935077, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 30, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.16603632831761644, None: 6.666642141814058, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 29, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.666645820541949, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 28, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.09090909090909091, None: 0.6473477564102563, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 27, inputs = {'light': 'red', 'oncoming': 'left', 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.09090909090909091, None: 0.948313701923077, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 26, inputs = {'light': 'red', 'oncoming': 'left', 'right': None, 'left': None}, action = None, reward = 1
{'forward': 2.211136470352943, None: 0.0, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': 'left', 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 0.0, None: 0.0, 'right': 7.618799937135447, 'left': 0.1427011936930666}
LearningAgent.update(): deadline = 24, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': 7.318157049035751, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 23, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.16603632831761644, None: 6.666646267244621, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 7.430941604366331, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 21, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 59
Environment.reset(): Trial set up with start = (8, 4), destination = (2, 3), deadline = 35
RoutePlanner.route_to(): destination = (2, 3)
{'forward': 7.4571313513431745, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 35, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.16603632831761644, None: 6.666646607234988, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 34, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.66664961614974, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 33, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.66665089493851, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 32, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.666651683524917, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 31, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 2.0846404121604243, None: 0.0, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 30, inputs = {'light': 'green', 'oncoming': None, 'right': 'left', 'left': None}, action = forward, reward = 2
{'forward': -0.16603632831761644, None: 6.66665213301917, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 29, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.666652496360357, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 28, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.6666528000097784, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 27, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 7.567310138505491, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 26, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 7.578348443116914, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.16603632831761644, None: 6.666653008009631, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.666653194264045, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.666653362669077, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.666653516176742, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 7.5846560892335795, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.16603632831761644, None: 6.666653647681642, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.666653769734626, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 7.6370869043707295, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 17, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 60
Environment.reset(): Trial set up with start = (4, 1), destination = (7, 3), deadline = 25
RoutePlanner.route_to(): destination = (7, 3)
{'forward': -1.0, None: 6.030252604415434, 'right': 1.7043849668547753, 'left': -0.01974371301775152}
LearningAgent.update(): deadline = 25, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.035556054934195, 'right': 1.7043849668547753, 'left': -0.01974371301775152}
LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.130222646694065, 'right': 1.7043849668547753, 'left': -0.01974371301775152}
LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.170455948192011, 'right': 1.7043849668547753, 'left': -0.01974371301775152}
LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.195266484115743, 'right': 1.7043849668547753, 'left': -0.01974371301775152}
LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 0.0, None: 0.0, 'right': 0.39326597990056816, 'left': 8.121661117350907}
LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2
{'forward': 7.6430006643514705, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 19, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.16603632831761644, None: 6.666654092157928, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.666654361611687, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.666654592331468, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 7.7355539179307655, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 15, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 0.0, None: 0.0, 'right': 7.714442026446017, 'left': 0.1427011936930666}
LearningAgent.update(): deadline = 14, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 61
Environment.reset(): Trial set up with start = (2, 2), destination = (5, 3), deadline = 20
RoutePlanner.route_to(): destination = (5, 3)
{'forward': 0.0, None: 0.0, 'right': 0.39326597990056816, 'left': 8.162893818522747}
LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2
{'forward': 7.729290507526309, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 19, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.16603632831761644, None: 6.666656403481747, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 8.143283115002712, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 17, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 62
Environment.reset(): Trial set up with start = (2, 4), destination = (8, 3), deadline = 35
RoutePlanner.route_to(): destination = (8, 3)
{'forward': -0.1437271823173862, None: 0.0, 'right': 8.220696520365017, 'left': 0.05223862320058734}
LearningAgent.update(): deadline = 35, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': 0.0, None: 0.0, 'right': 8.116891566881447, 'left': 0.1427011936930666}
LearningAgent.update(): deadline = 34, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': 8.921790647752305, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 33, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.16603632831761644, None: 6.666657173220616, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 32, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.66665764789292, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 31, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.6666579860969355, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 30, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 9.054136928319735, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 29, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 7.878447440266446, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 28, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 7.995337852260737, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 27, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 63
Environment.reset(): Trial set up with start = (5, 1), destination = (2, 4), deadline = 30
RoutePlanner.route_to(): destination = (2, 4)
{'forward': -0.16603632831761644, None: 6.666658148857618, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 30, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.14285714285714285, None: 0.125, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 29, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': 'right'}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.666659426528975, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 28, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.666659969539301, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 27, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 7.885778892876626, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 26, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 7.830999413184571, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.16603632831761644, None: 6.666660170453122, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.666660332858461, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.666660468582923, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.666660584796992, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 7.768219090774995, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -1.0, None: 6.202337486854008, 'right': 1.7043849668547753, 'left': -0.01974371301775152}
LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.208669248396908, 'right': 1.7043849668547753, 'left': -0.01974371301775152}
LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.21439421612528, 'right': 1.7043849668547753, 'left': -0.01974371301775152}
LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.219612744400758, 'right': 1.7043849668547753, 'left': -0.01974371301775152}
LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 0.0, None: 0.0, 'right': 0.39326597990056816, 'left': 8.194328990568176}
LearningAgent.update(): deadline = 15, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2
{'forward': 7.823870233200578, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 14, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 64
Environment.reset(): Trial set up with start = (8, 4), destination = (6, 2), deadline = 20
RoutePlanner.route_to(): destination = (6, 2)
{'forward': 0.0, None: 0.0, 'right': 8.150228950090138, 'left': 0.1427011936930666}
LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': 7.89285925659908, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 19, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 0.0, None: 0.0, 'right': 8.708930368109218, 'left': 0.1427011936930666}
LearningAgent.update(): deadline = 18, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 65
Environment.reset(): Trial set up with start = (6, 5), destination = (4, 2), deadline = 25
RoutePlanner.route_to(): destination = (4, 2)
{'forward': -0.1437271823173862, None: 0.0, 'right': 8.811643666628926, 'left': 0.05223862320058734}
LearningAgent.update(): deadline = 25, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': 0.0, None: 0.0, 'right': 8.187795932593332, 'left': 0.1427011936930666}
LearningAgent.update(): deadline = 24, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': -0.16603632831761644, None: 6.666661497077444, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.6666618847966355, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.666662123890138, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 8.292118721607956, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.1437271823173862, None: 0.0, 'right': 8.582647494364466, 'left': 0.05223862320058734}
LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': -0.16603632831761644, None: 6.666662237459551, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.666662332371133, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.666662413639174, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 8.222623647161882, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 15, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.16603632831761644, None: 6.666662477434587, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 14, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.666662534560478, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 13, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.666662586211806, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 12, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.666662633293978, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 11, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 8.182912189386025, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 10, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.16603632831761644, None: 6.666662673627704, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 9, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.666662711062445, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 8, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 66
Environment.reset(): Trial set up with start = (2, 1), destination = (8, 4), deadline = 45
RoutePlanner.route_to(): destination = (8, 4)
{'forward': 0.0, None: 0.0, 'right': 8.232953546027732, 'left': 0.1427011936930666}
LearningAgent.update(): deadline = 45, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': 8.15254460791644, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 44, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.16603632831761644, None: 6.6666633044030785, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 43, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.666663556572848, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 42, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.1, None: 0.3333333333333333, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 41, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': 'forward'}, action = None, reward = 1
{'forward': 3.382410683092897, None: 0.0, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 40, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': 'forward'}, action = forward, reward = 2
{'forward': 8.307968269678947, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 39, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 8.433602396270306, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 38, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 8.514232127392201, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 37, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 0.0, None: 0.0, 'right': 8.358471516309686, 'left': 0.1427011936930666}
LearningAgent.update(): deadline = 36, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': 8.594550480824553, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 35, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 67
Environment.reset(): Trial set up with start = (2, 3), destination = (4, 5), deadline = 20
RoutePlanner.route_to(): destination = (4, 5)
{'forward': -1.0, None: 6.226318553234746, 'right': 1.7043849668547753, 'left': -0.01974371301775152}
LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.232923774936225, 'right': 1.7043849668547753, 'left': -0.01974371301775152}
LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.297985208695791, 'right': 1.7043849668547753, 'left': -0.01974371301775152}
LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.325636318043607, 'right': 1.7043849668547753, 'left': -0.01974371301775152}
LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.342687835474759, 'right': 1.7043849668547753, 'left': -0.01974371301775152}
LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 0.0, None: 0.0, 'right': 0.39326597990056816, 'left': 8.47208872010135}
LearningAgent.update(): deadline = 15, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2
{'forward': 8.69658054243229, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 14, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 0.0, None: 0.0, 'right': 8.243170267439226, 'left': 0.1427011936930666}
LearningAgent.update(): deadline = 13, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': -0.16603632831761644, None: 6.666663623217715, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 12, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.666663680282383, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 11, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 68
Environment.reset(): Trial set up with start = (2, 2), destination = (5, 4), deadline = 25
RoutePlanner.route_to(): destination = (5, 4)
{'forward': -1.0, None: 6.348087482661291, 'right': 1.7043849668547753, 'left': -0.01974371301775152}
LearningAgent.update(): deadline = 25, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.353397135728047, 'right': 1.7043849668547753, 'left': -0.01974371301775152}
LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.40038756536884, 'right': 1.7043849668547753, 'left': -0.01974371301775152}
LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.420358497966177, 'right': 1.7043849668547753, 'left': -0.01974371301775152}
LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.4326739064012015, 'right': 1.7043849668547753, 'left': -0.01974371301775152}
LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 0.0, None: 0.0, 'right': 0.39326597990056816, 'left': 8.27073257213602}
LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2
{'forward': 8.490597259593837, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 19, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.16603632831761644, None: 6.66666375494199, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.66666381733609, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 8.555109443060026, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 16, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.1437271823173862, None: 0.0, 'right': 8.480871577739043, 'left': 0.05223862320058734}
LearningAgent.update(): deadline = 15, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': -0.16603632831761644, None: 6.666663860076049, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 14, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 69
Environment.reset(): Trial set up with start = (7, 5), destination = (6, 2), deadline = 20
RoutePlanner.route_to(): destination = (6, 2)
{'forward': 0.0, None: 0.0, 'right': 8.330949410497313, 'left': 0.1427011936930666}
LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': -0.1437271823173862, None: 0.0, 'right': 7.9410688535374865, 'left': 0.05223862320058734}
LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': 7.666664281064642, None: 0.0, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 18, inputs = {'light': 'green', 'oncoming': None, 'right': 'forward', 'left': None}, action = forward, reward = 2
{'forward': -0.16603632831761644, None: 6.666664070570345, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.666664200375162, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 70
Environment.reset(): Trial set up with start = (6, 1), destination = (3, 2), deadline = 20
RoutePlanner.route_to(): destination = (3, 2)
{'forward': -1.0, None: 6.441448634911156, 'right': 1.7043849668547753, 'left': -0.01974371301775152}
LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.449894311101988, 'right': 1.7043849668547753, 'left': -0.01974371301775152}
LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.48241016443669, 'right': 1.7043849668547753, 'left': -0.01974371301775152}
LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.496229402103938, 'right': 1.7043849668547753, 'left': -0.01974371301775152}
LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.504751265332075, 'right': 1.7043849668547753, 'left': -0.01974371301775152}
LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 0.0, None: 0.0, 'right': 0.39326597990056816, 'left': 8.52101018575227}
LearningAgent.update(): deadline = 15, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2
{'forward': 8.377420468511799, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 14, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.16603632831761644, None: 6.666664262032449, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 13, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.666664313560326, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 12, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.66666435768107, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 11, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 8.283155813736295, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 10, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -1.0, None: 6.507179996352095, 'right': 1.7043849668547753, 'left': -0.01974371301775152}
LearningAgent.update(): deadline = 9, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.509354814583657, 'right': 1.7043849668547753, 'left': -0.01974371301775152}
LearningAgent.update(): deadline = 8, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.511321212734694, 'right': 1.7043849668547753, 'left': -0.01974371301775152}
LearningAgent.update(): deadline = 7, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.513113660280063, 'right': 1.7043849668547753, 'left': -0.01974371301775152}
LearningAgent.update(): deadline = 6, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 71
Environment.reset(): Trial set up with start = (7, 5), destination = (4, 4), deadline = 20
RoutePlanner.route_to(): destination = (4, 4)
{'forward': 0.0, None: 0.0, 'right': 8.283500502892426, 'left': 0.1427011936930666}
LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': -0.16603632831761644, None: 6.666664382420201, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.666664725057171, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 8.661919127706074, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 17, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 8.788271227623571, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 16, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 72
Environment.reset(): Trial set up with start = (5, 6), destination = (3, 2), deadline = 30
RoutePlanner.route_to(): destination = (3, 2)
{'forward': 0.0, None: 0.0, 'right': 0.39326597990056816, 'left': 8.758265275184211}
LearningAgent.update(): deadline = 30, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2
{'forward': 8.778680552094395, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 29, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.1437271823173862, None: 0.0, 'right': 7.6666650162985945, 'left': 0.05223862320058734}
LearningAgent.update(): deadline = 28, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': 8.222672784196494, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 27, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.16603632831761644, None: 6.666664822137646, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 26, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.666664891307484, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 25, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 8.3759926006706, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 24, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 73
Environment.reset(): Trial set up with start = (7, 1), destination = (8, 6), deadline = 30
RoutePlanner.route_to(): destination = (8, 6)
{'forward': 0.0, None: 0.0, 'right': 8.32236129638599, 'left': 0.1427011936930666}
LearningAgent.update(): deadline = 30, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': -0.1437271823173862, None: 0.0, 'right': 7.666665039850722, 'left': 0.05223862320058734}
LearningAgent.update(): deadline = 29, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': -0.16603632831761644, None: 6.666665157611361, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 28, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.666665270790509, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 27, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 8.623859637303736, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 26, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.16603632831761644, None: 6.666665323135865, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 25, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.66666536344179, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.666665396022411, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.666665423250503, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.666665446564556, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 8.51750474755664, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.16603632831761644, None: 6.666665464866088, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 8.583175137362685, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 18, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 74
Environment.reset(): Trial set up with start = (5, 2), destination = (7, 4), deadline = 20
RoutePlanner.route_to(): destination = (7, 4)
{'forward': 0.0, None: 0.0, 'right': 8.40347276058368, 'left': 0.1427011936930666}
LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': 8.629823196457139, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 19, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 0.0, None: 0.0, 'right': 7.666665645136175, 'left': 0.1427011936930666}
LearningAgent.update(): deadline = 18, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': -0.16603632831761644, None: 6.666665555001131, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.666665610584409, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 75
Environment.reset(): Trial set up with start = (1, 2), destination = (6, 3), deadline = 30
RoutePlanner.route_to(): destination = (6, 3)
{'forward': 0.0, None: 0.0, 'right': 7.879165683443569, 'left': 0.1427011936930666}
LearningAgent.update(): deadline = 30, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': 0.0, None: 0.0, 'right': 8.243211691829819, 'left': 0.1427011936930666}
LearningAgent.update(): deadline = 29, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': 7.666665768996747, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 28, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.16603632831761644, None: 6.6666656897905785, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 27, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.666665738634383, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 26, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 7.666665796207367, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.16603632831761644, None: 6.666665766475352, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.666665788980135, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.6666658077877035, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.666665823891684, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 7.7611102551594655, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 7.885672223449054, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 19, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 0.0, None: 0.0, 'right': 8.284994391657262, 'left': 0.1427011936930666}
LearningAgent.update(): deadline = 18, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 76
Environment.reset(): Trial set up with start = (5, 4), destination = (8, 3), deadline = 20
RoutePlanner.route_to(): destination = (8, 3)
{'forward': -0.1437271823173862, None: 0.0, 'right': 7.781296722605552, 'left': 0.05223862320058734}
LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': 0.0, None: 0.0, 'right': 8.233467021544817, 'left': 0.1427011936930666}
LearningAgent.update(): deadline = 19, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': -0.16603632831761644, None: 6.666665950307931, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.666666004034836, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.6666660371664275, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 8.089959515069715, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 15, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 77
Environment.reset(): Trial set up with start = (1, 6), destination = (5, 5), deadline = 25
RoutePlanner.route_to(): destination = (5, 5)
{'forward': 0.0, None: 0.0, 'right': 8.309594060078798, 'left': 0.1427011936930666}
LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': -0.1437271823173862, None: 0.0, 'right': 8.000330495646292, 'left': 0.05223862320058734}
LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': 7.666666131591463, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 23, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 8.091666171722103, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 22, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 78
Environment.reset(): Trial set up with start = (5, 6), destination = (7, 2), deadline = 30
RoutePlanner.route_to(): destination = (7, 2)
{'forward': 7.9499994916785575, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 30, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.16603632831761644, None: 6.66666606864144, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 29, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.666666158345224, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 28, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.666666196469333, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 27, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 7.812048531531723, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 26, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -1.0, None: 6.518871898019561, 'right': 1.7043849668547753, 'left': -0.01974371301775152}
LearningAgent.update(): deadline = 25, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 0.0, None: 0.0, 'right': 0.39326597990056816, 'left': 8.734660470507762}
LearningAgent.update(): deadline = 24, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2
{'forward': 7.787818154109591, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 23, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.16603632831761644, None: 6.66666620654499, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.666666215172272, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 7.774356835085906, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.16603632831761644, None: 6.666666221944688, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.666666228009078, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.666666233492297, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.666666238490463, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 79
Environment.reset(): Trial set up with start = (6, 5), destination = (2, 2), deadline = 35
RoutePlanner.route_to(): destination = (2, 2)
{'forward': -0.1437271823173862, None: 0.0, 'right': 8.057469811764367, 'left': 0.05223862320058734}
LearningAgent.update(): deadline = 35, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': -0.1437271823173862, None: 0.0, 'right': 8.029555275403833, 'left': 0.05223862320058734}
LearningAgent.update(): deadline = 34, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': -0.16603632831761644, None: 6.6666663027168935, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 33, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.666666330013126, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 32, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.666666346845804, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 31, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 6.706441068517404, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 30, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 0.0, None: 0.0, 'right': 0.0, 'left': 2.9269310079187125}
LearningAgent.update(): deadline = 29, inputs = {'light': 'green', 'oncoming': None, 'right': 'right', 'left': None}, action = left, reward = 0.5
{'forward': 0.0, None: 0.0, 'right': 8.208074201438963, 'left': 0.1427011936930666}
LearningAgent.update(): deadline = 28, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': 6.825669646345864, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 27, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -1.0, None: 6.5216430499316935, 'right': 1.7043849668547753, 'left': -0.01974371301775152}
LearningAgent.update(): deadline = 26, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 80
Environment.reset(): Trial set up with start = (8, 4), destination = (4, 4), deadline = 20
RoutePlanner.route_to(): destination = (4, 4)
{'forward': 0.0, None: 0.0, 'right': 8.162934756767298, 'left': 0.1427011936930666}
LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': 6.9341307077956555, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 19, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 7.894011101626307, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 18, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.16603632831761644, None: 6.666666370832369, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.666666385624084, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.666666396163181, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 15, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 81
Environment.reset(): Trial set up with start = (7, 4), destination = (6, 1), deadline = 20
RoutePlanner.route_to(): destination = (6, 1)
{'forward': 0.0, None: 0.0, 'right': 8.318046714064279, 'left': 0.1427011936930666}
LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': 0.0, None: 0.0, 'right': 8.187770658599163, 'left': 0.1427011936930666}
LearningAgent.update(): deadline = 19, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': -0.16603632831761644, None: 6.666666436738703, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.6666664539833, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.666666464617469, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 8.09798568531532, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 15, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.16603632831761644, None: 6.666666470678946, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 14, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.666666475578639, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 13, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.666666479673382, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 12, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 82
Environment.reset(): Trial set up with start = (1, 2), destination = (4, 4), deadline = 25
RoutePlanner.route_to(): destination = (4, 4)
{'forward': 0.0, None: 0.0, 'right': 8.28424995875043, 'left': 0.1427011936930666}
LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': 0.0, None: 0.0, 'right': 7.790854067954355, 'left': 0.1427011936930666}
LearningAgent.update(): deadline = 24, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': 7.666666507722375, None: 0.0, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 23, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': 'left'}, action = forward, reward = 2
{'forward': -0.16603632831761644, None: 6.666666493697878, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.6666665023463185, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 8.279769760009804, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.1437271823173862, None: 0.0, 'right': 8.231205079524734, 'left': 0.05223862320058734}
LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': 8.319252555268841, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 18, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 83
Environment.reset(): Trial set up with start = (1, 1), destination = (1, 6), deadline = 25
RoutePlanner.route_to(): destination = (1, 6)
{'forward': 0.0, None: 0.0, 'right': 7.773112990674358, 'left': 0.1427011936930666}
LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': -0.16603632831761644, None: 6.66666650586747, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.666666529987349, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 7.992959552879044, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 22, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 7.884195218749112, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 21, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.16603632831761644, None: 6.666666535112824, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 7.84068948596847, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 19, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.16603632831761644, None: 6.666666538401669, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 84
Environment.reset(): Trial set up with start = (1, 2), destination = (4, 1), deadline = 20
RoutePlanner.route_to(): destination = (4, 1)
{'forward': 7.8158290676360345, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.16603632831761644, None: 6.666666541150206, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.666666559977675, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.66666656797935, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.666666572913717, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 0.0, None: 0.0, 'right': 0.0, 'left': 3.9719847664573353}
LearningAgent.update(): deadline = 15, inputs = {'light': 'green', 'oncoming': None, 'right': 'right', 'left': None}, action = left, reward = 0.5
{'forward': 0.0, None: 0.0, 'right': 7.947181334037612, 'left': 0.1427011936930666}
LearningAgent.update(): deadline = 14, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 85
Environment.reset(): Trial set up with start = (4, 5), destination = (7, 2), deadline = 30
RoutePlanner.route_to(): destination = (7, 2)
{'forward': -0.1437271823173862, None: 0.0, 'right': 8.137115330766722, 'left': 0.05223862320058734}
LearningAgent.update(): deadline = 30, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': -0.14285714285714285, None: 0.28854166666666664, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 29, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': 'right'}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.666666586976659, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 28, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 8.229641887563332, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 27, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 8.627915058352755, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 26, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 0.0, None: 0.0, 'right': 0.39326597990056816, 'left': 8.467662002613363}
LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2
{'forward': -0.16603632831761644, None: 6.66666658936736, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.666666591299842, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.666666592914845, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.666666594297692, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 8.521109674663897, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.16603632831761644, None: 6.666666595383227, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.666666596355275, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.666666597234166, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.66666659803531, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 86
Environment.reset(): Trial set up with start = (4, 3), destination = (6, 6), deadline = 25
RoutePlanner.route_to(): destination = (6, 6)
{'forward': -0.1437271823173862, None: 0.0, 'right': 8.21610303738798, 'left': 0.05223862320058734}
LearningAgent.update(): deadline = 25, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': 8.554150953743603, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 24, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.1437271823173862, None: 0.0, 'right': 7.666666608330013, 'left': 0.05223862320058734}
LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': 8.912589632212832, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 22, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 87
Environment.reset(): Trial set up with start = (2, 3), destination = (7, 6), deadline = 40
RoutePlanner.route_to(): destination = (7, 6)
{'forward': 0.0, None: 0.0, 'right': 8.490021285152045, 'left': 0.1427011936930666}
LearningAgent.update(): deadline = 40, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': 8.497281957585226, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 39, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.16603632831761644, None: 6.666666608330013, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 38, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 8.859985810766334, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 37, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 8.462212746204393, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 36, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 8.650789082748105, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 35, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 0.0, None: 0.0, 'right': 8.662651172188815, 'left': 0.1427011936930666}
LearningAgent.update(): deadline = 34, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': 8.486768671803507, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 33, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 88
Environment.reset(): Trial set up with start = (5, 3), destination = (2, 2), deadline = 20
RoutePlanner.route_to(): destination = (2, 2)
{'forward': 0.0, None: 0.0, 'right': 8.5203676643162, 'left': 0.1427011936930666}
LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': -0.16603632831761644, None: 6.666666609580085, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.666666618143072, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 8.076717648612558, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 17, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.16603632831761644, None: 6.666666620569252, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 8.186704890729546, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 15, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 89
Environment.reset(): Trial set up with start = (1, 4), destination = (7, 5), deadline = 35
RoutePlanner.route_to(): destination = (7, 5)
{'forward': 0.0, None: 0.0, 'right': 8.608033962876984, 'left': 0.1427011936930666}
LearningAgent.update(): deadline = 35, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': 8.34110374400766, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 34, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 9.08993818240651, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 33, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 9.408192818726022, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 32, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 9.604449844456388, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 31, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 9.332504037612418, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 30, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 90
Environment.reset(): Trial set up with start = (1, 5), destination = (7, 1), deadline = 50
RoutePlanner.route_to(): destination = (7, 1)
{'forward': -0.1437271823173862, None: 0.0, 'right': 8.119858973058122, 'left': 0.05223862320058734}
LearningAgent.update(): deadline = 50, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': 8.999336555586709, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 49, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.16603632831761644, None: 6.666666627483864, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 48, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 9.324386313917705, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 47, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 9.524833664888487, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 46, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 9.667652402455168, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 45, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.16603632831761644, None: 6.666666628659349, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 44, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.666666629609532, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 43, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.666666630403614, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 42, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 9.402120426203515, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 41, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -1.0, None: 6.524060110210609, 'right': 1.7043849668547753, 'left': -0.01974371301775152}
LearningAgent.update(): deadline = 40, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.5261992085574505, 'right': 1.7043849668547753, 'left': -0.01974371301775152}
LearningAgent.update(): deadline = 39, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 0.0, None: 0.0, 'right': 0.39326597990056816, 'left': 8.606220217127873}
LearningAgent.update(): deadline = 38, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2
{'forward': 9.257499277006811, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 37, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.16603632831761644, None: 6.666666630822034, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 36, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 9.30116892761031, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 35, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 91
Environment.reset(): Trial set up with start = (2, 4), destination = (7, 2), deadline = 35
RoutePlanner.route_to(): destination = (7, 2)
{'forward': 0.0, None: 0.0, 'right': 0.39326597990056816, 'left': 8.543583311732597}
LearningAgent.update(): deadline = 35, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2
{'forward': -0.16603632831761644, None: 6.66666663118048, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 34, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.6666666365034075, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 33, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 8.908916783257627, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 32, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 7.66666506771906, None: 0.0, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 31, inputs = {'light': 'green', 'oncoming': None, 'right': 'forward', 'left': None}, action = forward, reward = 2
{'forward': -0.16603632831761644, None: 6.666666637634529, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 30, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 9.041649279759898, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 29, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 7.868041066466582, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 28, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.14285714285714285, None: 0.0, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 27, inputs = {'light': 'red', 'oncoming': 'forward', 'right': None, 'left': None}, action = forward, reward = -1
{'forward': -0.14285714285714285, None: 0.125, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 26, inputs = {'light': 'red', 'oncoming': 'forward', 'right': None, 'left': None}, action = None, reward = 1
{'forward': 0.0, None: 0.0, 'right': 0.39326597990056816, 'left': 8.559611266706375}
LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 92
Environment.reset(): Trial set up with start = (8, 3), destination = (6, 1), deadline = 20
RoutePlanner.route_to(): destination = (6, 1)
{'forward': -0.1437271823173862, None: 0.0, 'right': 8.074539739951245, 'left': 0.05223862320058734}
LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': -0.16603632831761644, None: 6.666666638070012, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.66666664235951, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.666666644182547, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.666666645306753, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 8.230238016961296, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 15, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 0.0, None: 0.0, 'right': 8.58976047661439, 'left': 0.1427011936930666}
LearningAgent.update(): deadline = 14, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 93
Environment.reset(): Trial set up with start = (4, 2), destination = (8, 3), deadline = 25
RoutePlanner.route_to(): destination = (8, 3)
{'forward': -0.16603632831761644, None: 6.666666645840751, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 25, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.666666646361399, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.66666664940719, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 7.948452334478704, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 22, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.16603632831761644, None: 6.666666650270164, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 8.150385371935753, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.16603632831761644, None: 6.6666666507620596, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.666666651159675, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.25, None: 0.6321428571428571, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': 'right', 'left': None}, action = None, reward = 1
{'forward': 0.0, None: 0.0, 'right': 0.0, 'left': 4.395906518019988}
LearningAgent.update(): deadline = 16, inputs = {'light': 'green', 'oncoming': None, 'right': 'right', 'left': None}, action = left, reward = 0.5
{'forward': 0.0, None: 0.0, 'right': 8.48719449626676, 'left': 0.1427011936930666}
LearningAgent.update(): deadline = 15, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': -0.25, None: 0.7226607142857143, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 14, inputs = {'light': 'red', 'oncoming': None, 'right': 'right', 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.666666651371133, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 13, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.666666651562327, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 12, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.666666651736608, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 11, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 8.226366082642253, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 10, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 0.0, None: 0.0, 'right': 8.52087560786537, 'left': 0.1427011936930666}
LearningAgent.update(): deadline = 9, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 94
Environment.reset(): Trial set up with start = (1, 2), destination = (6, 5), deadline = 40
RoutePlanner.route_to(): destination = (6, 5)
{'forward': -0.16603632831761644, None: 6.666666651876578, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 40, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.666666652015235, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 39, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.66666665421295, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 38, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 7.94651636936163, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 37, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.16603632831761644, None: 6.666666654835636, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 36, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 8.148522005510568, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 35, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.16603632831761644, None: 6.666666655190567, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 34, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.66666665547747, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 33, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.666666655717239, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 32, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 8.088290086991703, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 31, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.16603632831761644, None: 6.666666655899729, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 30, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.666666656061234, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 29, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 8.159813403987272, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 28, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 8.250057642545462, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 27, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 0.0, None: 0.0, 'right': 8.558696637734469, 'left': 0.1427011936930666}
LearningAgent.update(): deadline = 26, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': -0.16603632831761644, None: 6.666666656174863, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 25, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.666666656279781, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.666666656377157, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.666666656467947, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.666666656552937, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 7.6666665156354075, None: 0.0, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': 'left'}, action = forward, reward = 2
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 95
Environment.reset(): Trial set up with start = (8, 5), destination = (3, 4), deadline = 30
RoutePlanner.route_to(): destination = (3, 4)
{'forward': 8.220888093321689, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 30, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.16603632831761644, None: 6.66666665662879, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 29, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.666666658134472, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 28, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.6666666587743855, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 27, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 8.476510355322272, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 26, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 8.658641216997687, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.16603632831761644, None: 6.666666659011154, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.6666666592025425, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.666666659362488, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 8.74629169417898, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 21, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.16603632831761644, None: 6.666666659484225, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.666666659591962, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.666666659688435, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.666666659775663, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.666666659855174, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 8.784048869028647, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 15, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 96
Environment.reset(): Trial set up with start = (2, 5), destination = (7, 3), deadline = 35
RoutePlanner.route_to(): destination = (7, 3)
{'forward': -0.16603632831761644, None: 6.6666666599232896, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 35, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.666666659990724, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 34, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.666666660992115, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 33, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 8.225357765435971, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 32, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.16603632831761644, None: 6.666666661275842, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 31, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.666666661477999, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 30, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 8.113619544800038, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 29, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.16603632831761644, None: 6.6666666616077155, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 28, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.666666661716122, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 27, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.666666661808945, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 26, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 8.063958113437545, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.16603632831761644, None: 6.666666661881811, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 8.135813230072488, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 23, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 8.230801258958149, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 22, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 0.0, None: 0.0, 'right': 0.39326597990056816, 'left': 8.593193559276225}
LearningAgent.update(): deadline = 21, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2
{'forward': -0.16603632831761644, None: 6.666666661933077, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.666666661980414, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.6666666620243475, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.666666662065309, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.666666662103653, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 97
Environment.reset(): Trial set up with start = (6, 5), destination = (2, 2), deadline = 35
RoutePlanner.route_to(): destination = (2, 2)
{'forward': 0.0, None: 0.0, 'right': 8.596391137962883, 'left': 0.1427011936930666}
LearningAgent.update(): deadline = 35, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': 0.0, None: 0.0, 'right': 8.61743271333928, 'left': 0.1427011936930666}
LearningAgent.update(): deadline = 34, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': 8.996181070114426, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 33, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 8.331423866451265, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 32, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 8.662555179746974, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 31, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 0.0, None: 0.0, 'right': 8.379741200701487, 'left': 0.1427011936930666}
LearningAgent.update(): deadline = 30, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': 8.005966434732233, None: 0.0, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 29, inputs = {'light': 'green', 'oncoming': None, 'right': 'forward', 'left': None}, action = forward, reward = 2
{'forward': 8.779324633586633, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 28, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 98
Environment.reset(): Trial set up with start = (7, 5), destination = (4, 2), deadline = 30
RoutePlanner.route_to(): destination = (4, 2)
{'forward': -1.0, None: 6.529209225516934, 'right': 1.7043849668547753, 'left': -0.01974371301775152}
LearningAgent.update(): deadline = 30, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.532154742113, 'right': 1.7043849668547753, 'left': -0.01974371301775152}
LearningAgent.update(): deadline = 29, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.5523315307960495, 'right': 1.7043849668547753, 'left': -0.01974371301775152}
LearningAgent.update(): deadline = 28, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.560906665986346, 'right': 1.7043849668547753, 'left': -0.01974371301775152}
LearningAgent.update(): deadline = 27, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 0.0, None: 0.0, 'right': 0.39326597990056816, 'left': 8.28435126044685}
LearningAgent.update(): deadline = 26, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2
{'forward': -0.16603632831761644, None: 6.666666662274766, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 25, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 8.915944894579034, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 24, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 8.950417415581907, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 23, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 0.0, None: 0.0, 'right': 8.555186001064792, 'left': 0.1427011936930666}
LearningAgent.update(): deadline = 22, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': 9.032597089039745, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 21, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 99
Environment.reset(): Trial set up with start = (2, 4), destination = (8, 6), deadline = 40
RoutePlanner.route_to(): destination = (8, 6)
{'forward': -1.0, None: 6.562669332664352, 'right': 1.7043849668547753, 'left': -0.01974371301775152}
LearningAgent.update(): deadline = 40, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.56440262156439, 'right': 1.7043849668547753, 'left': -0.01974371301775152}
LearningAgent.update(): deadline = 39, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.579742228329731, 'right': 1.7043849668547753, 'left': -0.01974371301775152}
LearningAgent.update(): deadline = 38, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 0.0, None: 0.0, 'right': 0.39326597990056816, 'left': 7.975508961690201}
LearningAgent.update(): deadline = 37, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2
{'forward': -0.16603632831761644, None: 6.666666662494361, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 36, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.666666662650822, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 35, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 8.759411003882436, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 34, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.16603632831761644, None: 6.6666666627512186, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 33, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.666666662835121, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 32, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.666666662906962, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 31, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 8.008365336784387, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 30, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 8.08823985673262, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 29, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.16603632831761644, None: 6.666666662958231, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 28, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.666666663004586, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 27, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.666666663046841, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 26, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 8.058127485793849, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.16603632831761644, None: 6.6666666630830385, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.666666663116636, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.66666666314796, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16603632831761644, None: 6.666666663177282, 'right': 0.7100476631769346, 'left': 1.075207790399283}
LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 8.12201067606286, None: 2.4327113776953917, 'right': 0.22926510886394222, 'left': 1.025101752705642}
LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.1437271823173862, None: 0.0, 'right': 8.115998206686355, 'left': 0.05223862320058734}
LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
Environment.act(): Primary agent has reached destination!
