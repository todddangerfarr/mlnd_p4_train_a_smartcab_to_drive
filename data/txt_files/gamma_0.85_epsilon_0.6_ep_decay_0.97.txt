Gamma: 0.85, Epsilon: 0.6, Epsilon_Decay: 0.97
Simulator.run(): Trial 0
Environment.reset(): Trial set up with start = (3, 6), destination = (3, 2), deadline = 20
RoutePlanner.route_to(): destination = (3, 2)
{'forward': 0.0, None: 0.2, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 0.0, None: 0.2, 'right': 0.1, 'left': 0.0}
LearningAgent.update(): deadline = 19, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 0.5
{'forward': -1.0, None: 0.0, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 1
Environment.reset(): Trial set up with start = (1, 1), destination = (8, 3), deadline = 45
RoutePlanner.route_to(): destination = (8, 3)
{'forward': -0.5, None: 0.0, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 45, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1
{'forward': -0.5, None: 0.5, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 44, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.5, None: 1.425, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 43, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.5, None: 1.8181249999999998, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 42, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 0.0, None: 0.5233333333333333, 'right': 0.1, 'left': 0.0}
LearningAgent.update(): deadline = 41, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 0.5113515625, None: 0.5233333333333333, 'right': 0.1, 'left': 0.0}
LearningAgent.update(): deadline = 40, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 0.5
{'forward': -0.5, None: 1.9635812499999998, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 39, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.5, None: 2.081158385416667, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 38, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.5, None: 2.1794192771577383, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 37, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.5, None: 2.263555165711031, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 36, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 0.5113515625, None: 0.6257222222222222, 'right': 0.1, 'left': 0.0}
LearningAgent.update(): deadline = 35, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 0.5113515625, None: 0.7163363888888888, 'right': 0.1, 'left': 0.0}
LearningAgent.update(): deadline = 34, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 0.5113515625, None: 0.7974772563131313, 'right': 0.1, 'left': 0.0}
LearningAgent.update(): deadline = 33, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 0.5113515625, None: 0.7974772563131313, 'right': 0.18982130565551347, 'left': 0.0}
LearningAgent.update(): deadline = 32, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 0.5
{'forward': 0.5113515625, None: 0.8651986725864413, 'right': 0.18982130565551347, 'left': 0.0}
LearningAgent.update(): deadline = 31, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.5, None: 2.263555165711031, 'right': 0.0, 'left': 0.06600156363245545}
LearningAgent.update(): deadline = 30, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1
{'forward': -0.5, None: 2.263555165711031, 'right': 0.0, 'left': 0.12320291878058351}
LearningAgent.update(): deadline = 29, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1
{'forward': 0.0, None: 0.0625, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 28, inputs = {'light': 'red', 'oncoming': 'left', 'right': None, 'left': None}, action = None, reward = 1
{'forward': 0.0, None: 0.12077205882352941, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 27, inputs = {'light': 'red', 'oncoming': 'left', 'right': None, 'left': None}, action = None, reward = 1
{'forward': 0.0, None: 0.17532118055555554, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 26, inputs = {'light': 'red', 'oncoming': 'left', 'right': None, 'left': None}, action = None, reward = 1
{'forward': 0.5113515625, None: 0.9109997356976011, 'right': 0.18982130565551347, 'left': 0.0}
LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 0.5113515625, None: 0.954167237679869, 'right': 0.18982130565551347, 'left': 0.0}
LearningAgent.update(): deadline = 24, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 0.5113515625, None: 0.9949708050297746, 'right': 0.18982130565551347, 'left': 0.0}
LearningAgent.update(): deadline = 23, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 0.5113515625, None: 1.0336414586318443, 'right': 0.18982130565551347, 'left': 0.0}
LearningAgent.update(): deadline = 22, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 2
Environment.reset(): Trial set up with start = (7, 2), destination = (1, 3), deadline = 35
RoutePlanner.route_to(): destination = (1, 3)
{'forward': -1.0, None: 0.0, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 35, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1
{'forward': -1.0, None: 0.0, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 34, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1
{'forward': -1.0, None: 1.0, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 33, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 1.425, None: 0.0, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 32, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -1.0, None: 1.2833333333333334, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 31, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 1.4852083333333335, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 30, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 1.7822500000000001, None: 0.0, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 29, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 1.7822500000000001, None: 0.41915208333333337, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 28, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 2.0297732142857146, None: 0.41915208333333337, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 27, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 2.2417149665178573, None: 0.41915208333333337, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 26, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 2.355127423941799, None: 0.41915208333333337, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -1.0, None: 1.5629302083333336, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 2.497754193661124, None: 0.41915208333333337, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 23, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.5, None: 2.318594059472976, 'right': 0.0, 'left': 0.12320291878058351}
LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.5, None: 2.3687641280175185, 'right': 0.0, 'left': 0.12320291878058351}
LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 0.5113515625, None: 1.093995300146503, 'right': 0.18982130565551347, 'left': 0.0}
LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 3
Environment.reset(): Trial set up with start = (8, 1), destination = (4, 4), deadline = 35
RoutePlanner.route_to(): destination = (4, 4)
{'forward': -0.06666666666666667, None: 0.0, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 35, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1
{'forward': -0.06666666666666667, None: 0.06666666666666667, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 34, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.06666666666666667, None: 1.0566666666666666, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 33, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 0.25, None: 0.0, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 32, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 0.5
{'forward': 0.25, None: 0.0, 'right': 1.1094968923611113, 'left': 0.0}
LearningAgent.update(): deadline = 31, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': -1.0, None: 1.7543203255208337, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 30, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 2.696437810267441, None: 0.41915208333333337, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 29, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -1.0, None: 1.8771289840494796, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 28, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 1.9797619343912767, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 27, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 2.696437810267441, None: 0.7782545902575824, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 26, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 2.873719402318539, None: 0.7782545902575824, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 2.8793370625991375, None: 0.7782545902575824, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 24, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 0.5113515625, None: 1.1699862733263233, 'right': 0.18982130565551347, 'left': 0.0}
LearningAgent.update(): deadline = 23, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 0.5113515625, None: 1.2386947782430775, 'right': 0.18982130565551347, 'left': 0.0}
LearningAgent.update(): deadline = 22, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 0.5113515625, None: 1.3013252231095036, 'right': 0.18982130565551347, 'left': 0.0}
LearningAgent.update(): deadline = 21, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.3918964636560793, None: 2.3687641280175185, 'right': 0.0, 'left': 0.12320291878058351}
LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1
{'forward': -0.06666666666666667, None: 0.0, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': 'forward', 'right': None, 'left': None}, action = forward, reward = -1
{'forward': -0.06666666666666667, None: 0.0625, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': 'forward', 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.06666666666666667, None: 0.12077205882352941, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': 'forward', 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.06666666666666667, None: 0.17532118055555554, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': 'forward', 'right': None, 'left': None}, action = None, reward = 1
{'forward': 0.5113515625, None: 1.3436831818744288, 'right': 0.18982130565551347, 'left': 0.0}
LearningAgent.update(): deadline = 15, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 0.5113515625, None: 1.3836055580103706, 'right': 0.18982130565551347, 'left': 0.0}
LearningAgent.update(): deadline = 14, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 0.5113515625, None: 1.4213417087864868, 'right': 0.18982130565551347, 'left': 0.0}
LearningAgent.update(): deadline = 13, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 0.5113515625, None: 1.4571052880447608, 'right': 0.18982130565551347, 'left': 0.0}
LearningAgent.update(): deadline = 12, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 0.5113515625, None: 1.491080688340121, 'right': 0.18982130565551347, 'left': 0.0}
LearningAgent.update(): deadline = 11, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.3918964636560793, None: 2.3956260188840757, 'right': 0.0, 'left': 0.12320291878058351}
LearningAgent.update(): deadline = 10, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.3918964636560793, None: 2.4212522627707713, 'right': 0.0, 'left': 0.12320291878058351}
LearningAgent.update(): deadline = 9, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.3918964636560793, None: 2.445745038177863, 'right': 0.0, 'left': 0.12320291878058351}
LearningAgent.update(): deadline = 8, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.3918964636560793, None: 2.445745038177863, 'right': 0.05178395061728394, 'left': 0.12320291878058351}
LearningAgent.update(): deadline = 7, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 0.5
{'forward': -0.06666666666666667, None: 1.086720238095238, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 6, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.06666666666666667, None: 1.1155820299671595, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 5, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.06666666666666667, None: 1.143337453150657, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 4, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 0.25, None: 0.0, 'right': 1.168644488043235, 'left': 0.0}
LearningAgent.update(): deadline = 3, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': 0.25, None: 0.0, 'right': 1.2249942488911982, 'left': 0.0}
LearningAgent.update(): deadline = 2, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': -0.06666666666666667, None: 1.1684434950302751, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 1, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 0.25, None: 0.0, 'right': 1.3089321616429626, 'left': 0.0}
LearningAgent.update(): deadline = 0, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
Environment.reset(): Primary agent could not reach destination within deadline!
Simulator.run(): Trial 4
Environment.reset(): Trial set up with start = (4, 2), destination = (7, 3), deadline = 20
RoutePlanner.route_to(): destination = (7, 3)
{'forward': 0.25, None: 0.0, 'right': 1.3767568897169518, 'left': 0.0}
LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': -1.0, None: 1.9998486689581714, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 2.6998713686144455, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 2.997381015968362, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 3.1808452985032774, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 3.3354324228812993, None: 0.7782545902575824, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 15, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 3.266981332460186, None: 0.7782545902575824, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 14, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.06666666666666667, None: 1.305899074321185, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 13, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.06666666666666667, None: 1.420772665585731, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 12, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 5
Environment.reset(): Trial set up with start = (8, 6), destination = (4, 4), deadline = 30
RoutePlanner.route_to(): destination = (4, 4)
{'forward': 0.25, None: 0.0, 'right': 1.8017790450762277, 'left': 0.0}
LearningAgent.update(): deadline = 30, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': 3.4557254324765574, None: 0.7782545902575824, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 29, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 4.937366617605074, None: 0.7782545902575824, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 28, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 4.234439402959934, None: 0.7782545902575824, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 27, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.06666666666666667, None: 1.6830673656397779, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 26, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.06666666666666667, None: 1.8699523394282864, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 25, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.06666666666666667, None: 2.013853769245438, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.06666666666666667, None: 2.130174091680969, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 0.25, None: 0.0, 'right': 2.34427825185333, 'left': 0.0}
LearningAgent.update(): deadline = 22, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 6
Environment.reset(): Trial set up with start = (1, 3), destination = (2, 6), deadline = 20
RoutePlanner.route_to(): destination = (2, 6)
{'forward': 0.5113515625, None: 1.5881229254337437, 'right': 0.18982130565551347, 'left': 0.0}
LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 0.5113515625, None: 1.6833456205818609, 'right': 0.18982130565551347, 'left': 0.0}
LearningAgent.update(): deadline = 19, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 0.5113515625, None: 1.6833456205818609, 'right': 0.18982130565551347, 'left': 3.9926365140753304}
LearningAgent.update(): deadline = 18, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2
{'forward': 0.25, None: 0.0, 'right': 3.9717758721846366, 'left': 0.0}
LearningAgent.update(): deadline = 17, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': 4.689384099478604, None: 0.7782545902575824, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 16, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 4.689384099478604, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 15, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 3.2854199395481793, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 14, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16666666666666666, None: 0.0, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 13, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': 'forward'}, action = forward, reward = -1
{'forward': -1.0, None: 3.3578752265578613, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 12, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 7
Environment.reset(): Trial set up with start = (3, 4), destination = (6, 3), deadline = 20
RoutePlanner.route_to(): destination = (6, 3)
{'forward': 0.25, None: 0.5470011864196176, 'right': 3.9717758721846366, 'left': 0.0}
LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 0.25, None: 0.5470011864196176, 'right': 4.223550948731159, 'left': 0.0}
LearningAgent.update(): deadline = 19, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': 2.0, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 18, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 3.039441641225592, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 17, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.3918964636560793, None: 2.6567911196023033, 'right': 0.05178395061728394, 'left': 0.12320291878058351}
LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.3918964636560793, None: 2.807161452617217, 'right': 0.05178395061728394, 'left': 0.12320291878058351}
LearningAgent.update(): deadline = 15, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 8
Environment.reset(): Trial set up with start = (8, 4), destination = (3, 6), deadline = 35
RoutePlanner.route_to(): destination = (3, 6)
{'forward': -0.3918964636560793, None: 2.9229466090387004, 'right': 0.05178395061728394, 'left': 0.12320291878058351}
LearningAgent.update(): deadline = 35, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.3918964636560793, None: 3.0352582107675397, 'right': 0.05178395061728394, 'left': 0.12320291878058351}
LearningAgent.update(): deadline = 34, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.3918964636560793, None: 3.5799694791524086, 'right': 0.05178395061728394, 'left': 0.12320291878058351}
LearningAgent.update(): deadline = 33, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.3918964636560793, None: 3.811471768215978, 'right': 0.05178395061728394, 'left': 0.12320291878058351}
LearningAgent.update(): deadline = 32, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 0.5113515625, None: 1.6833456205818609, 'right': 0.18982130565551347, 'left': 4.189599474397472}
LearningAgent.update(): deadline = 31, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2
{'forward': 3.4931297165627395, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 30, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 3.7653425617650282, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 29, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -1.0, None: 3.440595012560582, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 28, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 3.509725119434284, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 27, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 3.9175830354842924, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 26, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -1.0, None: 3.562340811888157, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 25, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 3.6089056997098345, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 4.037780123438774, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 23, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.3918964636560793, None: 3.8471617044466115, 'right': 0.05178395061728394, 'left': 0.12320291878058351}
LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.3918964636560793, None: 3.8796944540106892, 'right': 0.05178395061728394, 'left': 0.12320291878058351}
LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.3918964636560793, None: 3.90955487057486, 'right': 0.05178395061728394, 'left': 0.12320291878058351}
LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 0.5113515625, None: 1.6833456205818609, 'right': 0.44983443903991155, 'left': 4.189599474397472}
LearningAgent.update(): deadline = 19, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 0.5
{'forward': 0.25, None: 0.5470011864196176, 'right': 4.0845790144354615, 'left': 0.0}
LearningAgent.update(): deadline = 18, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': -0.06666666666666667, None: 2.1702019673426074, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.06666666666666667, None: 2.2076725065036413, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 0.25, None: 0.5470011864196176, 'right': 4.073628625808758, 'left': 0.0}
LearningAgent.update(): deadline = 15, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': 0.25, None: 0.5470011864196176, 'right': 4.136103276517751, 'left': 0.0}
LearningAgent.update(): deadline = 14, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': -0.3918964636560793, None: 3.92924852626123, 'right': 0.05178395061728394, 'left': 0.12320291878058351}
LearningAgent.update(): deadline = 13, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.3918964636560793, None: 3.9479127408549033, 'right': 0.05178395061728394, 'left': 0.12320291878058351}
LearningAgent.update(): deadline = 12, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 0.5113515625, None: 1.6833456205818609, 'right': 0.44983443903991155, 'left': 4.2436218061594495}
LearningAgent.update(): deadline = 11, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 9
Environment.reset(): Trial set up with start = (8, 4), destination = (4, 2), deadline = 30
RoutePlanner.route_to(): destination = (4, 2)
{'forward': -0.3918964636560793, None: 3.964904952891227, 'right': 0.05178395061728394, 'left': 0.12320291878058351}
LearningAgent.update(): deadline = 30, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.3918964636560793, None: 3.981790963602324, 'right': 0.05178395061728394, 'left': 0.12320291878058351}
LearningAgent.update(): deadline = 29, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.3918964636560793, None: 4.3845223190619755, 'right': 0.05178395061728394, 'left': 0.12320291878058351}
LearningAgent.update(): deadline = 28, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.3918964636560793, None: 4.555683145132328, 'right': 0.05178395061728394, 'left': 0.12320291878058351}
LearningAgent.update(): deadline = 27, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 0.5113515625, None: 1.6833456205818609, 'right': 0.44983443903991155, 'left': 4.6397855724139525}
LearningAgent.update(): deadline = 26, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2
{'forward': 4.29522755376742, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 4.449696011964608, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 24, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -1.0, None: 3.685349723883755, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 3.749235086943389, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 4.378049214285044, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 21, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.06666666666666667, None: 2.2819890758396917, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.06666666666666667, None: 2.3477592397020963, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 0.25, None: 0.5470011864196176, 'right': 4.231625689916308, 'left': 0.0}
LearningAgent.update(): deadline = 18, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': -1.0, None: 3.78570298168993, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 3.818944870362739, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 3.849456175323138, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 15, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 10
Environment.reset(): Trial set up with start = (8, 4), destination = (6, 2), deadline = 20
RoutePlanner.route_to(): destination = (6, 2)
{'forward': 0.25, None: 0.5470011864196176, 'right': 4.322642766350478, 'left': 0.0}
LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': 0.25, None: 0.5470011864196176, 'right': 4.415889370736599, 'left': 0.0}
LearningAgent.update(): deadline = 19, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': 5.753505965126109, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 18, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 0.25, None: 0.5470011864196176, 'right': 4.843963559880633, 'left': 0.0}
LearningAgent.update(): deadline = 17, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': -1.0, None: 3.990316699890315, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 4.090679823644429, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 15, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 5.9809007861723265, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 14, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 11
Environment.reset(): Trial set up with start = (6, 3), destination = (3, 4), deadline = 20
RoutePlanner.route_to(): destination = (3, 4)
{'forward': -1.0, None: 4.155079494719985, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 4.217869174018651, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 4.585188797915853, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 5.9391556322004, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 17, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -1.0, None: 4.6892626913533935, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 4.763415340427641, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 15, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 5.1513245057603205, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 14, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -1.0, None: 4.810996623583617, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 13, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 5.254325386846343, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 12, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 12
Environment.reset(): Trial set up with start = (7, 1), destination = (4, 6), deadline = 40
RoutePlanner.route_to(): destination = (4, 6)
{'forward': -0.06666666666666667, None: 2.428738753957682, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 40, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.06666666666666667, None: 2.5081999023209756, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 39, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.06666666666666667, None: 3.131969916972829, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 38, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.06666666666666667, None: 3.3970721731998665, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 37, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 0.25, None: 0.5470011864196176, 'right': 5.268432048553268, 'left': 0.0}
LearningAgent.update(): deadline = 36, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': 0.25, None: 0.5470011864196176, 'right': 5.567868181119799, 'left': 0.0}
LearningAgent.update(): deadline = 35, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': -1.0, None: 4.866666724876109, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 34, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 4.911666723420873, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 33, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 4.949273865061855, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 32, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 5.405806785842974, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 31, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -1.0, None: 4.977897078421934, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 30, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 5.003228622245606, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 29, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 5.025911868305894, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 28, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 5.046421303285403, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 27, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 5.065116442093648, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 26, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 5.444236139465037, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 0.5113515625, None: 1.6833456205818609, 'right': 0.44983443903991155, 'left': 4.750823132638329}
LearningAgent.update(): deadline = 24, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2
{'forward': -1.0, None: 5.080130975449019, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 5.0941298197832925, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 5.107234293507321, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 5.491442087360626, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 5.533927440466655, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 19, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -1.0, None: 5.1183730961727445, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.045454545454545456, None: 0.0, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': 'forward', 'right': None, 'left': None}, action = forward, reward = -1
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 13
Environment.reset(): Trial set up with start = (2, 2), destination = (7, 4), deadline = 35
RoutePlanner.route_to(): destination = (7, 4)
{'forward': -1.0, None: 5.128470662936836, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 35, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 5.13850237600464, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 34, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 5.367727019603944, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 33, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 5.465147493133648, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 32, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 5.904410083365637, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 31, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -1.0, None: 5.510204462141136, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 30, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 5.544898328276902, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 29, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 5.572942536736647, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 28, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 6.063601295864945, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 27, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 0.8942576376856504, None: 0.0, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 26, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': 'left'}, action = forward, reward = 2
{'forward': -1.0, None: 5.591171272235481, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 25, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 5.607303703151949, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 5.6217495617453315, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 5.634811025556848, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 5.646717052185039, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 6.141491281980678, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 6.057892619663292, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 19, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.06666666666666667, None: 3.4277246215761177, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 0.25, None: 0.5470011864196176, 'right': 5.660888213213563, 'left': 0.0}
LearningAgent.update(): deadline = 17, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 14
Environment.reset(): Trial set up with start = (2, 6), destination = (4, 4), deadline = 20
RoutePlanner.route_to(): destination = (4, 4)
{'forward': 0.5113515625, None: 1.6833456205818609, 'right': 0.44983443903991155, 'left': 4.884066776753633}
LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2
{'forward': 6.063090627473142, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 19, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 0.5113515625, None: 1.6833456205818609, 'right': 0.44983443903991155, 'left': 7.15362703335217}
LearningAgent.update(): deadline = 18, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 15
Environment.reset(): Trial set up with start = (2, 2), destination = (5, 5), deadline = 30
RoutePlanner.route_to(): destination = (5, 5)
{'forward': 0.5113515625, None: 1.6833456205818609, 'right': 0.44983443903991155, 'left': 7.15362703335217}
LearningAgent.update(): deadline = 30, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2
{'forward': 6.608358830412656, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 29, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 6.811754981231529, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 28, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 0.25, None: 0.5470011864196176, 'right': 6.725439973630181, 'left': 0.0}
LearningAgent.update(): deadline = 27, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': 7.137833898836619, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 26, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 16
Environment.reset(): Trial set up with start = (2, 6), destination = (7, 4), deadline = 35
RoutePlanner.route_to(): destination = (7, 4)
{'forward': -0.06666666666666667, None: 3.5491849482670133, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 35, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.06666666666666667, None: 3.666090512707, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 34, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.06666666666666667, None: 4.11617693580095, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 33, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.06666666666666667, None: 4.307463665615879, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 32, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.06666666666666667, None: 4.4254238156684185, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 31, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 0.25, None: 0.5470011864196176, 'right': 6.7440073538119565, 'left': 0.0}
LearningAgent.update(): deadline = 30, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': 7.323698881871521, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 29, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 7.473939743158066, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 28, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -1.0, None: 5.668573115352503, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 27, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 5.687287369439644, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 26, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 5.7036103577267605, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 25, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 5.718056202360859, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 7.418158654871581, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 23, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -1.0, None: 5.729913833164682, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 5.7407225197050895, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 7.465474677977136, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 0.4154937500493442, None: 0.0, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 19, inputs = {'light': 'green', 'oncoming': 'forward', 'right': None, 'left': None}, action = forward, reward = 0.5
{'forward': 0.25, None: 0.5470011864196176, 'right': 6.80578228486997, 'left': 0.0}
LearningAgent.update(): deadline = 18, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': -0.06666666666666667, None: 4.445199487883109, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.06666666666666667, None: 4.463711714372971, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.06666666666666667, None: 4.481103463996344, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 15, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 0.25, None: 0.5470011864196176, 'right': 6.759109704294596, 'left': 0.0}
LearningAgent.update(): deadline = 14, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': -0.3918964636560793, None: 4.5707615988575725, 'right': 0.05178395061728394, 'left': 0.12320291878058351}
LearningAgent.update(): deadline = 13, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.3918964636560793, None: 4.585051860683544, 'right': 0.05178395061728394, 'left': 0.12320291878058351}
LearningAgent.update(): deadline = 12, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 0.5113515625, None: 1.6833456205818609, 'right': 0.44983443903991155, 'left': 7.141713429369438}
LearningAgent.update(): deadline = 11, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2
{'forward': -1.0, None: 5.7465096706236, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 10, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 5.752030612599858, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 9, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 7.499327708681115, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 8, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 17
Environment.reset(): Trial set up with start = (5, 3), destination = (2, 1), deadline = 25
RoutePlanner.route_to(): destination = (2, 1)
{'forward': -0.3918964636560793, None: 4.596616387383451, 'right': 0.05178395061728394, 'left': 0.12320291878058351}
LearningAgent.update(): deadline = 25, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.3918964636560793, None: 4.608116666712802, 'right': 0.05178395061728394, 'left': 0.12320291878058351}
LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.3918964636560793, None: 4.916899166705882, 'right': 0.05178395061728394, 'left': 0.12320291878058351}
LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 0.5113515625, None: 1.6833456205818609, 'right': 0.44983443903991155, 'left': 7.758070990874193}
LearningAgent.update(): deadline = 22, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2
{'forward': -1.0, None: 5.7977624153031995, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 5.830346324729329, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 5.85543593498745, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 5.87571670327943, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 7.427189349982029, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 17, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 0.9681554060813008, None: 0.0, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 16, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': 'right'}, action = forward, reward = 2
{'forward': -0.06666666666666667, None: 4.517529517374182, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 15, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.06666666666666667, None: 4.54976657461357, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 14, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.06666666666666667, None: 4.578633394050658, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 13, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.06666666666666667, None: 4.604733809958358, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 12, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.06666666666666667, None: 4.628525342920377, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 11, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 0.25, None: 0.5470011864196176, 'right': 6.77591323954409, 'left': 0.0}
LearningAgent.update(): deadline = 10, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 18
Environment.reset(): Trial set up with start = (3, 3), destination = (7, 1), deadline = 30
RoutePlanner.route_to(): destination = (7, 1)
{'forward': -0.3918964636560793, None: 4.93439684170549, 'right': 0.05178395061728394, 'left': 0.12320291878058351}
LearningAgent.update(): deadline = 30, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.3918964636560793, None: 4.951719539955102, 'right': 0.05178395061728394, 'left': 0.12320291878058351}
LearningAgent.update(): deadline = 29, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.3918964636560793, None: 5.208961608961836, 'right': 0.05178395061728394, 'left': 0.12320291878058351}
LearningAgent.update(): deadline = 28, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 0.5113515625, None: 1.6833456205818609, 'right': 0.44983443903991155, 'left': 8.03559096917946}
LearningAgent.update(): deadline = 27, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2
{'forward': -1.0, None: 5.915264201448792, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 26, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 5.943441793894463, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 25, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 5.965138540077629, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 5.982676743242355, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 7.37834447594974, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 22, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 7.341710820425523, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 21, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -1.0, None: 5.9940765752994265, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.004165426669935, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 7.477032775277978, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 18, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 0.5113515625, None: 1.6833456205818609, 'right': 0.44983443903991155, 'left': 7.9579201061369575}
LearningAgent.update(): deadline = 17, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2
{'forward': -1.0, None: 6.011809671746821, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 19
Environment.reset(): Trial set up with start = (4, 3), destination = (1, 2), deadline = 20
RoutePlanner.route_to(): destination = (1, 2)
{'forward': 0.25, None: 0.5470011864196176, 'right': 6.799779309646999, 'left': 0.0}
LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': -1.0, None: 6.018825996692391, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.116002097188533, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 7.337817278944115, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 17, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -1.0, None: 6.14353532566244, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 7.4483160625080735, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 15, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.06666666666666667, None: 4.689669582632766, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 14, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.06666666666666667, None: 4.739094509733614, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 13, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.06666666666666667, None: 4.780399627382179, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 12, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 20
Environment.reset(): Trial set up with start = (8, 5), destination = (7, 1), deadline = 25
RoutePlanner.route_to(): destination = (7, 1)
{'forward': 0.25, None: 0.5470011864196176, 'right': 6.7077243563504805, 'left': 0.0}
LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': -0.06666666666666667, None: 4.815767134368763, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.06666666666666667, None: 5.093402064213449, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 0.25, None: 0.5470011864196176, 'right': 6.964864691581777, 'left': 0.0}
LearningAgent.update(): deadline = 22, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': -0.3333333333333333, None: 0.0, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': 'left', 'left': None}, action = forward, reward = -1
{'forward': -1.0, None: 6.163152750950099, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 7.6248665806328315, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 19, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 7.560502123578624, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 18, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -1.0, None: 6.173942334858311, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 21
Environment.reset(): Trial set up with start = (2, 4), destination = (5, 6), deadline = 25
RoutePlanner.route_to(): destination = (5, 6)
{'forward': -0.06666666666666667, None: 5.1229007755094464, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 25, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.06666666666666667, None: 5.151846385968644, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.06666666666666667, None: 5.379069428073347, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 0.25, None: 0.5470011864196176, 'right': 7.695645748311804, 'left': 0.0}
LearningAgent.update(): deadline = 22, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': -1.0, None: 6.19857855144873, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.216131855769403, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.229647900096321, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.24057336926058, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 7.523928586477606, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 17, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 7.404963639900698, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 16, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.06666666666666667, None: 5.400529382049902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 15, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.06666666666666667, None: 5.419521441319153, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 14, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 0.25, None: 0.5470011864196176, 'right': 7.750061507003057, 'left': 0.0}
LearningAgent.update(): deadline = 13, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 22
Environment.reset(): Trial set up with start = (2, 5), destination = (7, 4), deadline = 30
RoutePlanner.route_to(): destination = (7, 4)
{'forward': 7.479068261068607, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 30, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 7.464519852968847, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 29, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -1.0, None: 6.304487363871493, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 28, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.331650811581131, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 27, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 7.4369809652605525, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 26, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 7.658094179063282, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 7.879321761293908, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 24, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 23
Environment.reset(): Trial set up with start = (1, 1), destination = (4, 2), deadline = 20
RoutePlanner.route_to(): destination = (4, 2)
{'forward': 1.2107053483694021, None: 0.0, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': 'left', 'left': None}, action = forward, reward = 0.5
{'forward': 0.5113515625, None: 1.6833456205818609, 'right': 0.44983443903991155, 'left': 8.081170671297436}
LearningAgent.update(): deadline = 19, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2
{'forward': 7.381903189843961, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 18, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -1.0, None: 6.356777000712546, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 24
Environment.reset(): Trial set up with start = (2, 6), destination = (5, 2), deadline = 35
RoutePlanner.route_to(): destination = (5, 2)
{'forward': -0.3918964636560793, None: 5.281846861847078, 'right': 0.05178395061728394, 'left': 0.12320291878058351}
LearningAgent.update(): deadline = 35, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.3918964636560793, None: 5.351087852088058, 'right': 0.05178395061728394, 'left': 0.12320291878058351}
LearningAgent.update(): deadline = 34, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.3918964636560793, None: 5.548424674274849, 'right': 0.05178395061728394, 'left': 0.12320291878058351}
LearningAgent.update(): deadline = 33, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.3918964636560793, None: 5.632292823704235, 'right': 0.05178395061728394, 'left': 0.12320291878058351}
LearningAgent.update(): deadline = 32, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.3918964636560793, None: 5.684011515852356, 'right': 0.05178395061728394, 'left': 0.12320291878058351}
LearningAgent.update(): deadline = 31, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 0.5113515625, None: 1.6833456205818609, 'right': 0.44983443903991155, 'left': 7.911693116124493}
LearningAgent.update(): deadline = 30, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2
{'forward': 7.386174641996302, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 29, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -1.0, None: 6.3645242423614, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 28, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 7.577426714383376, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 27, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 0.5113515625, None: 1.6833456205818609, 'right': 0.44983443903991155, 'left': 7.977833065012165}
LearningAgent.update(): deadline = 26, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2
{'forward': -1.0, None: 6.369559949433154, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 25, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.374016550191657, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.16666666666666666, None: 0.09090909090909091, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': 'forward'}, action = None, reward = 1
{'forward': -1.0, None: 6.377674676647594, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.381009199609353, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 7.566457507617988, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -1.0, None: 6.383865774279926, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.386517032646052, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 7.6173417060801825, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 17, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 25
Environment.reset(): Trial set up with start = (6, 1), destination = (5, 4), deadline = 20
RoutePlanner.route_to(): destination = (5, 4)
{'forward': 0.25, None: 0.5470011864196176, 'right': 7.807344651350684, 'left': 0.0}
LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': 0.5113515625, None: 1.6833456205818609, 'right': 0.44983443903991155, 'left': 7.947316754608663}
LearningAgent.update(): deadline = 19, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2
{'forward': -1.0, None: 6.428539477749144, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.446399016917958, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.457412399405394, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 7.585206414433783, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 15, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 26
Environment.reset(): Trial set up with start = (1, 5), destination = (7, 4), deadline = 35
RoutePlanner.route_to(): destination = (7, 4)
{'forward': 0.25, None: 0.5470011864196176, 'right': 7.743635828979465, 'left': 0.0}
LearningAgent.update(): deadline = 35, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': -1.0, None: 6.463690027423232, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 34, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.494136523309748, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 33, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 7.552611229623534, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 32, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 2.5066720149377617, None: 0.0, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 31, inputs = {'light': 'green', 'oncoming': 'right', 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -1.0, None: 6.500606403685632, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 30, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.505588211575064, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 29, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.509615172952354, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 28, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 7.5498343249643876, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 27, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -1.0, None: 6.5125598884594975, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 26, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 7.646225975103869, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 7.757125301735218, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 24, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.3918964636560793, None: 5.697411358818005, 'right': 0.05178395061728394, 'left': 0.12320291878058351}
LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.3918964636560793, None: 5.7095270501661135, 'right': 0.05178395061728394, 'left': 0.12320291878058351}
LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.3918964636560793, None: 5.720570968818043, 'right': 0.05178395061728394, 'left': 0.12320291878058351}
LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 27
Environment.reset(): Trial set up with start = (1, 2), destination = (3, 4), deadline = 20
RoutePlanner.route_to(): destination = (3, 4)
{'forward': -0.3918964636560793, None: 5.7307077084378495, 'right': 0.05178395061728394, 'left': 0.12320291878058351}
LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.3918964636560793, None: 5.7407358401331585, 'right': 0.05178395061728394, 'left': 0.12320291878058351}
LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.3918964636560793, None: 5.879625464113184, 'right': 0.05178395061728394, 'left': 0.12320291878058351}
LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.3918964636560793, None: 5.938653554304695, 'right': 0.05178395061728394, 'left': 0.12320291878058351}
LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.3918964636560793, None: 5.975054209922794, 'right': 0.05178395061728394, 'left': 0.12320291878058351}
LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 0.5113515625, None: 1.6833456205818609, 'right': 0.44983443903991155, 'left': 8.108876692575231}
LearningAgent.update(): deadline = 15, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2
{'forward': 7.527018886412431, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 14, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.06666666666666667, None: 5.450700071952841, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 13, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 0.25, None: 0.5470011864196176, 'right': 7.83711157533248, 'left': 0.0}
LearningAgent.update(): deadline = 12, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': -1.0, None: 6.515449390550882, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 11, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.5179696784861445, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 10, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.520200133308852, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 9, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 28
Environment.reset(): Trial set up with start = (3, 6), destination = (6, 4), deadline = 25
RoutePlanner.route_to(): destination = (6, 4)
{'forward': -1.0, None: 6.522197404218277, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 25, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.524167439615301, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.545542323673006, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 7.545364930767243, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 22, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 7.834763350895548, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 21, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 7.6457715327802545, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.3918964636560793, None: 5.99580258362511, 'right': 0.05178395061728394, 'left': 0.12320291878058351}
LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.3918964636560793, None: 6.012574185701149, 'right': 0.05178395061728394, 'left': 0.12320291878058351}
LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.3918964636560793, None: 6.026590453150411, 'right': 0.05178395061728394, 'left': 0.12320291878058351}
LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.3918964636560793, None: 6.038591882153841, 'right': 0.05178395061728394, 'left': 0.12320291878058351}
LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 0.5113515625, None: 1.6833456205818609, 'right': 0.44983443903991155, 'left': 8.152213260385007}
LearningAgent.update(): deadline = 15, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 29
Environment.reset(): Trial set up with start = (4, 1), destination = (8, 4), deadline = 35
RoutePlanner.route_to(): destination = (8, 4)
{'forward': 0.7563710975122055, None: 0.0, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 35, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': 'forward'}, action = forward, reward = 2
{'forward': -1.0, None: 6.547359188817911, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 34, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.565255310495224, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 33, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.572861162208082, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 32, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 7.6261583511457935, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 31, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -1.0, None: 6.576378868625279, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 30, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.579087502566521, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 29, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.581276981669025, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 28, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 7.748454957906955, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 27, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 7.609034970813575, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 26, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.06666666666666667, None: 5.470966181864738, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 25, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.06666666666666667, None: 5.4889016891367675, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 0.25, None: 0.5470011864196176, 'right': 7.894435952592394, 'left': 0.0}
LearningAgent.update(): deadline = 23, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': 7.607789176113999, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 22, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -1.0, None: 6.5822622472651515, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 30
Environment.reset(): Trial set up with start = (8, 1), destination = (7, 4), deadline = 20
RoutePlanner.route_to(): destination = (7, 4)
{'forward': -0.06666666666666667, None: 5.501520599610302, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.06666666666666667, None: 5.5140043074716205, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.06666666666666667, None: 5.686903661350877, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 0.25, None: 0.5470011864196176, 'right': 4.947217976296197, 'left': 0.0}
LearningAgent.update(): deadline = 17, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': -0.3333333333333333, None: 0.0, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': 'forward', 'right': None, 'left': None}, action = forward, reward = -1
{'forward': 0.25, None: 0.5470011864196176, 'right': 5.942758800053961, 'left': 0.0}
LearningAgent.update(): deadline = 15, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': -0.3918964636560793, None: 6.057434125689226, 'right': 0.05178395061728394, 'left': 0.12320291878058351}
LearningAgent.update(): deadline = 14, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.3918964636560793, None: 6.072664939213661, 'right': 0.05178395061728394, 'left': 0.12320291878058351}
LearningAgent.update(): deadline = 13, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.3918964636560793, None: 6.085393547659083, 'right': 0.05178395061728394, 'left': 0.12320291878058351}
LearningAgent.update(): deadline = 12, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 0.5113515625, None: 1.6833456205818609, 'right': 0.44983443903991155, 'left': 8.191514202798993}
LearningAgent.update(): deadline = 11, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2
{'forward': -1.0, None: 6.58366898758851, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 10, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.5849139527746825, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 9, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.586028762509573, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 8, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.5870367363115365, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 7, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.58795554320025, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 6, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 31
Environment.reset(): Trial set up with start = (1, 2), destination = (6, 2), deadline = 25
RoutePlanner.route_to(): destination = (6, 2)
{'forward': 0.25, None: 0.5470011864196176, 'right': 6.021943527196241, 'left': 0.0}
LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': 0.25, None: 0.5470011864196176, 'right': 6.1965633323748595, 'left': 0.0}
LearningAgent.update(): deadline = 24, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': 8.4666207996969, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 23, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -1.0, None: 6.593858877460232, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.597499266920554, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.600093044411033, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 8.295312457307396, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 19, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -1.0, None: 6.601757384967424, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 8.1976240744381, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 17, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -1.0, None: 6.602974433999284, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.604035971210407, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 15, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.604975431642251, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 14, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 8.073646259684477, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 13, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.06666666666666667, None: 5.699150698917324, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 12, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.06666666666666667, None: 5.710314344699047, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 11, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.06666666666666667, None: 5.7205609767201295, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 10, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 32
Environment.reset(): Trial set up with start = (8, 4), destination = (3, 5), deadline = 30
RoutePlanner.route_to(): destination = (3, 5)
{'forward': -0.06666666666666667, None: 5.730022033619595, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 30, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.06666666666666667, None: 5.739388479950066, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 29, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.06666666666666667, None: 5.878480207957557, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 28, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.06666666666666667, None: 5.93759419236074, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 27, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 0.25, None: 0.5470011864196176, 'right': 6.669118593881878, 'left': 0.0}
LearningAgent.update(): deadline = 26, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': -1.0, None: 6.607288852955667, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 25, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 7.9821561127500456, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 24, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -1.0, None: 6.608773298298441, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.610013870477761, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 7.23438659865629, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 21, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.1111111111111111, None: 0.0, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': 'left', 'right': None, 'left': None}, action = forward, reward = -1
{'forward': -0.1111111111111111, None: 0.1, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': 'left', 'right': None, 'left': None}, action = None, reward = 1
{'forward': 0.6925919809005543, None: 0.0, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 18, inputs = {'light': 'green', 'oncoming': 'left', 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -1.0, None: 6.6107220304301215, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.6113675454636205, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 7.229972164145856, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 15, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 33
Environment.reset(): Trial set up with start = (1, 3), destination = (4, 5), deadline = 25
RoutePlanner.route_to(): destination = (4, 5)
{'forward': -0.3918964636560793, None: 6.091206278849159, 'right': 0.05178395061728394, 'left': 0.12320291878058351}
LearningAgent.update(): deadline = 25, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.3918964636560793, None: 6.096960882727334, 'right': 0.05178395061728394, 'left': 0.12320291878058351}
LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.3918964636560793, None: 6.182416750318234, 'right': 0.05178395061728394, 'left': 0.12320291878058351}
LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 0.5113515625, None: 1.6833456205818609, 'right': 0.44983443903991155, 'left': 7.905588308221535}
LearningAgent.update(): deadline = 22, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2
{'forward': -1.0, None: 6.614132501523773, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 7.327982279683194, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 7.396135984706476, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 19, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 0.25, None: 0.5470011864196176, 'right': 6.827934265950766, 'left': 0.0}
LearningAgent.update(): deadline = 18, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': -1.0, None: 6.615258233633979, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 34
Environment.reset(): Trial set up with start = (6, 3), destination = (2, 5), deadline = 30
RoutePlanner.route_to(): destination = (2, 5)
{'forward': -1.0, None: 6.616222141753341, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 30, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.617167976595466, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 29, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.624592780106146, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 28, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 7.513519923898349, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 27, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -1.0, None: 6.626696474434173, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 26, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.628195356642891, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 25, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 7.688114326181399, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 24, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 7.679089614008909, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 23, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -1.0, None: 6.629019741857687, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 7.626085191979108, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 21, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 0.5113515625, None: 1.6833456205818609, 'right': 0.44983443903991155, 'left': 7.9696532087727245}
LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 35
Environment.reset(): Trial set up with start = (5, 6), destination = (3, 2), deadline = 30
RoutePlanner.route_to(): destination = (3, 2)
{'forward': 0.5113515625, None: 1.6833456205818609, 'right': 0.44983443903991155, 'left': 7.9361545659533554}
LearningAgent.update(): deadline = 30, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2
{'forward': -1.0, None: 6.629584445729822, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 29, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.635146778870348, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 28, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.637510770455073, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 27, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 7.433041815821616, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 26, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.06666666666666667, None: 5.964934410147212, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 25, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 0.25, None: 0.5470011864196176, 'right': 6.990724243737976, 'left': 0.0}
LearningAgent.update(): deadline = 24, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': -1.0, None: 6.638239667860363, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 7.462964944658715, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 22, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -1.0, None: 6.638772674087981, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.639237573964293, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.6396490103548285, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 7.479395555035341, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 18, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -1.0, None: 6.639986731058727, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.640294576469588, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 36
Environment.reset(): Trial set up with start = (3, 6), destination = (2, 3), deadline = 20
RoutePlanner.route_to(): destination = (2, 3)
{'forward': 0.5113515625, None: 1.6833456205818609, 'right': 0.44983443903991155, 'left': 7.874300257572768}
LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2
{'forward': -0.06666666666666667, None: 5.972452970038492, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.06666666666666667, None: 6.076585024532718, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.06666666666666667, None: 6.120841147692763, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.06666666666666667, None: 6.148132423641458, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 0.25, None: 0.5470011864196176, 'right': 7.332414738248492, 'left': 0.0}
LearningAgent.update(): deadline = 15, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': -1.0, None: 6.641085739175501, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 14, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.6417252623627805, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 13, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.642259721026436, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 12, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 7.589156888378428, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 11, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 37
Environment.reset(): Trial set up with start = (6, 3), destination = (1, 2), deadline = 30
RoutePlanner.route_to(): destination = (1, 2)
{'forward': 7.595463985544432, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 30, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -1.0, None: 6.642666503453772, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 29, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.6462665279357065, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 28, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 8.025804186628601, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 27, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -1.0, None: 6.647286534872255, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 26, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.648013289814546, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 25, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.648572891120111, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.649025235508775, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 8.139536954057988, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 22, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -1.0, None: 6.649356012342986, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.64964452324838, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.649899855399655, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 8.095253128879053, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 18, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -1.0, None: 6.650109440540492, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.650300485457333, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 8.033157373965924, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 15, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.06666666666666667, None: 6.15331776607171, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 14, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.06666666666666667, None: 6.158130412014788, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 13, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 38
Environment.reset(): Trial set up with start = (4, 3), destination = (8, 2), deadline = 25
RoutePlanner.route_to(): destination = (8, 2)
{'forward': 0.25, None: 0.5470011864196176, 'right': 7.385364019969828, 'left': 0.0}
LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': 0.25, None: 0.5470011864196176, 'right': 7.40109292542094, 'left': 0.0}
LearningAgent.update(): deadline = 24, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': -1.0, None: 6.652755412638733, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.653798756690827, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.6544421521896195, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 8.231913972442202, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -1.0, None: 6.654808887623932, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.6551053321, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.655353074983571, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 8.160055990103931, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 16, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -1.0, None: 6.6555416348449565, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 15, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.655708510322283, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 14, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 39
Environment.reset(): Trial set up with start = (5, 4), destination = (2, 5), deadline = 20
RoutePlanner.route_to(): destination = (2, 5)
{'forward': -1.0, None: 6.655857939726978, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.656005331457974, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.6576045317392785, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 7.909509921041159, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 17, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -1.0, None: 6.658057638485648, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.658380477042436, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 15, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 7.8595326179301415, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 14, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -1.0, None: 6.658587631783042, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 13, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 7.773178563621622, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 12, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 40
Environment.reset(): Trial set up with start = (7, 4), destination = (1, 4), deadline = 30
RoutePlanner.route_to(): destination = (1, 4)
{'forward': 7.759006179045867, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 30, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -1.0, None: 6.658739113687109, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 29, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.659928246634043, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 28, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 7.709972594342402, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 27, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -1.0, None: 6.660265167635674, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 26, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.660505223849336, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 25, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 7.700263963528309, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 24, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -1.0, None: 6.66065925991977, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.660787990064347, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 7.805884014212154, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 21, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 7.789860211694658, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -1.0, None: 6.660876170213381, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 41
Environment.reset(): Trial set up with start = (6, 6), destination = (3, 2), deadline = 35
RoutePlanner.route_to(): destination = (3, 2)
{'forward': 7.865453026989731, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 35, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 7.940015031167143, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 34, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 7.23441085021257, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 33, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 0.25, None: 0.5470011864196176, 'right': 7.5314188350511575, 'left': 0.0}
LearningAgent.update(): deadline = 32, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': 7.376855481702172, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 31, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -1.0, None: 6.66109331383038, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 30, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.661260514415468, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 29, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.661395668221748, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 28, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 7.5044942928085545, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 27, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -1.0, None: 6.66149449944259, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 26, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.661580702229657, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 25, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.661656991696213, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 42
Environment.reset(): Trial set up with start = (7, 1), destination = (3, 5), deadline = 40
RoutePlanner.route_to(): destination = (3, 5)
{'forward': 7.5839784615429835, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 40, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 7.591108459851966, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 39, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -1.0, None: 6.662408442941781, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 38, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.662727809721147, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 37, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 5.727405639901312, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 36, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -1.0, None: 6.662875516856604, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 35, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.662989251350906, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 34, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.6630811867338, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 33, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 5.945641153882625, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 32, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 0.5113515625, None: 1.6833456205818609, 'right': 0.44983443903991155, 'left': 7.771737097976201}
LearningAgent.update(): deadline = 31, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2
{'forward': 6.136527582198303, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 30, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -1.0, None: 6.663134968932794, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 29, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 6.2346658424410535, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 28, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 43
Environment.reset(): Trial set up with start = (2, 3), destination = (7, 1), deadline = 35
RoutePlanner.route_to(): destination = (7, 1)
{'forward': 0.25, None: 0.5470011864196176, 'right': 7.542439325762967, 'left': 0.0}
LearningAgent.update(): deadline = 35, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': -1.0, None: 6.663179115154467, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 34, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.663702247881297, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 33, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 6.767065904257974, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 32, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -1.0, None: 6.6638504688205655, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 31, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.663956076239794, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 30, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.664037393952601, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 29, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.664103125770453, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 28, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 6.907771634881017, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 27, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -1.0, None: 6.664151192162256, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 26, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.664193116737329, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 25, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.66423021998627, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 6.976573821436228, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 23, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -1.0, None: 6.664260675569775, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.664288437005509, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 7.092959729425052, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 0.5113515625, None: 1.6833456205818609, 'right': 0.44983443903991155, 'left': 7.7645976362081}
LearningAgent.update(): deadline = 19, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2
{'forward': -1.0, None: 6.664310732908582, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 44
Environment.reset(): Trial set up with start = (7, 6), destination = (2, 2), deadline = 45
RoutePlanner.route_to(): destination = (2, 2)
{'forward': -1.0, None: 6.664331520559389, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 45, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.6643521247897475, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 44, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.664699306071285, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 43, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.664846858115939, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 42, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.664937848543476, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 41, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 7.326973739571613, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 40, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 7.394618425909681, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 39, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -1.0, None: 6.664981068996556, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 38, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 7.521876602497331, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 37, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 7.630841416200506, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 36, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 7.717533861833619, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 35, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 0.25, None: 0.5470011864196176, 'right': 7.644185771442528, 'left': 0.0}
LearningAgent.update(): deadline = 34, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': -1.0, None: 6.665004054419331, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 33, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.665024837072423, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 32, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.665043781260049, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 31, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 7.777703141885402, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 30, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 7.833259443799881, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 29, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 45
Environment.reset(): Trial set up with start = (2, 6), destination = (8, 4), deadline = 40
RoutePlanner.route_to(): destination = (8, 4)
{'forward': 0.5113515625, None: 1.6833456205818609, 'right': 0.44983443903991155, 'left': 7.820452191896963}
LearningAgent.update(): deadline = 40, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2
{'forward': 7.884822636514258, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 39, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 8.702099241037118, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 38, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 9.049441797959334, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 37, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 9.263636374728033, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 36, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -1.0, None: 6.665104639462798, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 35, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.665151500278914, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 34, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.665189379438608, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 33, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.665221035593495, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 32, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.665248141176117, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 31, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 9.195163928992965, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 30, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 0.5113515625, None: 1.6833456205818609, 'right': 0.44983443903991155, 'left': 7.804953064707237}
LearningAgent.update(): deadline = 29, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 46
Environment.reset(): Trial set up with start = (1, 5), destination = (7, 5), deadline = 30
RoutePlanner.route_to(): destination = (7, 5)
{'forward': -1.0, None: 6.6652674847055335, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 30, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.665286564459549, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 29, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.665493579790617, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 28, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.66558156130632, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 27, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 9.402072399209985, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 26, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 9.54949468423961, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 9.172744612813762, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 24, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -1.0, None: 6.6656086889403285, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 9.261900085396325, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 22, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 9.338239458795146, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 21, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -1.0, None: 6.665626321902433, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.665641927073897, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.665655900795616, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.6656685353690035, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.665680052268592, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 47
Environment.reset(): Trial set up with start = (2, 4), destination = (4, 6), deadline = 20
RoutePlanner.route_to(): destination = (4, 6)
{'forward': -0.3918964636560793, None: 6.187605142279111, 'right': 0.05178395061728394, 'left': 0.12320291878058351}
LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.3918964636560793, None: 6.192737944326121, 'right': 0.05178395061728394, 'left': 0.12320291878058351}
LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.3918964636560793, None: 6.263827252677203, 'right': 0.05178395061728394, 'left': 0.12320291878058351}
LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 0.5113515625, None: 1.6833456205818609, 'right': 0.44983443903991155, 'left': 7.73539055456777}
LearningAgent.update(): deadline = 17, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2
{'forward': 9.058012274438813, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 16, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 0.25, None: 0.5470011864196176, 'right': 7.649596339688971, 'left': 0.0}
LearningAgent.update(): deadline = 15, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': -1.0, None: 6.665709650700535, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 14, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.665733576099688, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 13, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 48
Environment.reset(): Trial set up with start = (1, 5), destination = (6, 5), deadline = 25
RoutePlanner.route_to(): destination = (6, 5)
{'forward': -0.3918964636560793, None: 6.27245952583412, 'right': 0.05178395061728394, 'left': 0.12320291878058351}
LearningAgent.update(): deadline = 25, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.3918964636560793, None: 6.280906821709103, 'right': 0.05178395061728394, 'left': 0.12320291878058351}
LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.3918964636560793, None: 6.338770798452738, 'right': 0.05178395061728394, 'left': 0.12320291878058351}
LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.3918964636560793, None: 6.363362988568783, 'right': 0.05178395061728394, 'left': 0.12320291878058351}
LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 0.5113515625, None: 1.6833456205818609, 'right': 0.44983443903991155, 'left': 7.712218216273426}
LearningAgent.update(): deadline = 21, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2
{'forward': -1.0, None: 6.66576856699595, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 8.779590475940363, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 19, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -1.0, None: 6.665791019487718, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 8.62049503174382, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 17, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -1.0, None: 6.665807437872322, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.1111111111111111, None: 0.20944444444444443, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 15, inputs = {'light': 'red', 'oncoming': 'left', 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.1111111111111111, None: 0.30630277777777776, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 14, inputs = {'light': 'red', 'oncoming': 'left', 'right': None, 'left': None}, action = None, reward = 1
{'forward': 1.3265323755633651, None: 0.0, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 13, inputs = {'light': 'green', 'oncoming': 'left', 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -1.0, None: 6.665818178232252, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 12, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.665827968483419, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 11, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 49
Environment.reset(): Trial set up with start = (8, 2), destination = (1, 1), deadline = 40
RoutePlanner.route_to(): destination = (1, 1)
{'forward': 8.67098972783228, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 40, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 8.599201445359325, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 39, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -1.0, None: 6.665953773210906, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 38, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 8.132631076294297, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 37, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.3333333333333333, None: 0.0, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 36, inputs = {'light': 'red', 'oncoming': None, 'right': 'right', 'left': None}, action = forward, reward = -1
{'forward': 2.228184103712538, None: 0.0, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 35, inputs = {'light': 'green', 'oncoming': None, 'right': 'right', 'left': None}, action = forward, reward = 2
{'forward': 8.288652144005468, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 34, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 8.184886904542768, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 33, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 8.230211187998892, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 32, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 50
Environment.reset(): Trial set up with start = (8, 5), destination = (3, 4), deadline = 30
RoutePlanner.route_to(): destination = (3, 4)
{'forward': -0.06666666666666667, None: 6.167665466789511, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 30, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.06666666666666667, None: 6.177021739287207, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 29, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.06666666666666667, None: 6.250468478394126, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 28, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.06666666666666667, None: 6.281683342514566, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 27, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 0.25, None: 0.5470011864196176, 'right': 7.933783189371189, 'left': 0.0}
LearningAgent.update(): deadline = 26, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': 0.25, None: 0.5470011864196176, 'right': 7.866852568835709, 'left': 0.0}
LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': -1.0, None: 6.665975160014579, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.665992447680882, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.666006895230578, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.666019265945004, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 8.315263223754465, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 8.250348538984344, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 19, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 8.319661967998194, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 18, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 8.237976040759792, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 17, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.06666666666666667, None: 6.286125457793244, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 0.25, None: 0.5470011864196176, 'right': 7.852514269351248, 'left': 0.0}
LearningAgent.update(): deadline = 15, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 51
Environment.reset(): Trial set up with start = (8, 2), destination = (7, 5), deadline = 20
RoutePlanner.route_to(): destination = (7, 5)
{'forward': 0.25, None: 0.5470011864196176, 'right': 7.907322459991069, 'left': 0.0}
LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': 0.25, None: 0.5470011864196176, 'right': 7.950526661580492, 'left': 0.0}
LearningAgent.update(): deadline = 19, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': 0.5113515625, None: 1.6833456205818609, 'right': 0.44983443903991155, 'left': 9.002279634645824}
LearningAgent.update(): deadline = 18, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2
{'forward': -1.0, None: 6.666067820999128, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.666097763282505, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.666119097159411, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 15, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 52
Environment.reset(): Trial set up with start = (3, 2), destination = (4, 5), deadline = 20
RoutePlanner.route_to(): destination = (4, 5)
{'forward': 0.25, None: 0.5470011864196176, 'right': 7.829062657089246, 'left': 0.0}
LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': -0.06666666666666667, None: 6.297541694059447, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.06666666666666667, None: 6.35291043995053, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 0.25, None: 0.5470011864196176, 'right': 7.614518265523598, 'left': 0.0}
LearningAgent.update(): deadline = 17, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': 0.25, None: 0.5470011864196176, 'right': 7.631745921210899, 'left': 0.0}
LearningAgent.update(): deadline = 16, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': 8.4290519392313, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 15, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 8.27648179790214, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 14, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -1.0, None: 6.666132786397093, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 13, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.666144226688584, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 12, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 53
Environment.reset(): Trial set up with start = (2, 1), destination = (7, 6), deadline = 50
RoutePlanner.route_to(): destination = (7, 6)
{'forward': 0.25, None: 0.5470011864196176, 'right': 7.636055505145198, 'left': 0.0}
LearningAgent.update(): deadline = 50, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': -1.0, None: 6.666154022438173, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 49, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.666230919072447, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 48, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 7.971389039556859, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 47, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 7.869691453441767, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 46, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.1111111111111111, None: 0.544816423611111, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 45, inputs = {'light': 'red', 'oncoming': 'left', 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.1111111111111111, None: 0.7284719309027778, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 44, inputs = {'light': 'red', 'oncoming': 'left', 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.1111111111111111, None: 0.876926799296875, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 43, inputs = {'light': 'red', 'oncoming': 'left', 'right': None, 'left': None}, action = None, reward = 1
{'forward': 2.23221293351311, None: 0.0, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 42, inputs = {'light': 'green', 'oncoming': 'left', 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -1.0, None: 6.666239089339839, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 41, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.666246215628619, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 40, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.666252522394189, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 39, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 7.926141973981008, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 38, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 0.25, None: 0.5470011864196176, 'right': 7.7278192695400865, 'left': 0.0}
LearningAgent.update(): deadline = 37, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': 7.906155256292859, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 36, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 7.964303592832579, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 35, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 8.017993890237586, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 34, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 54
Environment.reset(): Trial set up with start = (8, 5), destination = (7, 1), deadline = 25
RoutePlanner.route_to(): destination = (7, 1)
{'forward': -0.06666666666666667, None: 6.355851904575993, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 25, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.06666666666666667, None: 6.358765792970593, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.06666666666666667, None: 6.404950924025004, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.06666666666666667, None: 6.424579604723129, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 0.25, None: 0.5470011864196176, 'right': 8.008094972729749, 'left': 0.0}
LearningAgent.update(): deadline = 21, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': 0.25, None: 0.5470011864196176, 'right': 7.922649890556077, 'left': 0.0}
LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': 7.947658040997081, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 19, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -1.0, None: 6.666262876001001, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.666271528658123, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.6662789374957825, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 8.037419295869352, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 15, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 55
Environment.reset(): Trial set up with start = (1, 1), destination = (8, 1), deadline = 35
RoutePlanner.route_to(): destination = (8, 1)
{'forward': -0.3918964636560793, None: 6.3679125437402515, 'right': 0.05178395061728394, 'left': 0.12320291878058351}
LearningAgent.update(): deadline = 35, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.3918964636560793, None: 6.372393855584148, 'right': 0.05178395061728394, 'left': 0.12320291878058351}
LearningAgent.update(): deadline = 34, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.3918964636560793, None: 6.416534777246526, 'right': 0.05178395061728394, 'left': 0.12320291878058351}
LearningAgent.update(): deadline = 33, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.3918964636560793, None: 6.435294668953037, 'right': 0.05178395061728394, 'left': 0.12320291878058351}
LearningAgent.update(): deadline = 32, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 0.5113515625, None: 1.6833456205818609, 'right': 0.44983443903991155, 'left': 8.945455223593532}
LearningAgent.update(): deadline = 31, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2
{'forward': 8.236016072274252, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 30, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.2, None: 0.0, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 29, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': 'right'}, action = forward, reward = -1
{'forward': -1.0, None: 6.666288630725054, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 28, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.6662967314952315, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 27, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 8.164808090961339, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 26, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -1.0, None: 6.6663028970814215, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 25, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.6663083536252, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 8.119494819108619, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 23, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -1.0, None: 6.6663128325382175, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.666316915239699, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.6663206625764175, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 8.089286668714042, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 19, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -1.0, None: 6.666323906364763, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.666326930720367, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.666329761853253, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 8.130687037118932, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 15, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 56
Environment.reset(): Trial set up with start = (7, 2), destination = (1, 4), deadline = 40
RoutePlanner.route_to(): destination = (1, 4)
{'forward': 8.107471700141748, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 40, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -1.0, None: 6.666332288639353, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 39, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.66638244534345, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 38, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 8.499411322631117, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 37, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 8.741107423166227, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 36, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -1.0, None: 6.66639310364307, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 35, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.666401310533779, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 34, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.6664079444371005, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 33, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.666413488484877, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 32, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.666418235575786, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 31, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 8.621701653952137, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 30, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -1.0, None: 6.666421962042149, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 29, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 8.534861382477926, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 28, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -1.0, None: 6.666425020849955, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 27, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.6664278090709175, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 26, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.6664303682594435, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 25, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 8.463870654886737, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 24, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.3918964636560793, None: 6.437463781431602, 'right': 0.05178395061728394, 'left': 0.12320291878058351}
LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.3918964636560793, None: 6.439486159830736, 'right': 0.05178395061728394, 'left': 0.12320291878058351}
LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.3918964636560793, None: 6.441379330721035, 'right': 0.05178395061728394, 'left': 0.12320291878058351}
LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 0.5113515625, None: 1.6833456205818609, 'right': 0.44983443903991155, 'left': 8.579904948667556}
LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 57
Environment.reset(): Trial set up with start = (4, 6), destination = (4, 1), deadline = 25
RoutePlanner.route_to(): destination = (4, 1)
{'forward': -1.0, None: 6.666432140497497, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 25, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.666433899443765, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.6664688145272, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.666483653437661, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 8.198084138398496, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 21, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -1.0, None: 6.666490516433749, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.666495800940737, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.666500072583886, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 8.308125192575671, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 17, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -1.0, None: 6.666503196222938, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.666505920730334, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 15, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.666508331919379, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 14, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 8.376650758131458, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 13, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 8.317474201798126, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 12, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -1.0, None: 6.666510158858771, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 11, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 58
Environment.reset(): Trial set up with start = (6, 1), destination = (2, 5), deadline = 40
RoutePlanner.route_to(): destination = (2, 5)
{'forward': 8.27097844702897, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 40, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -1.0, None: 6.666511835728142, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 39, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.66653506036892, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 38, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.666544930841251, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 37, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 8.069506695091002, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 36, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -1.0, None: 6.666549495934705, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 35, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.6665530110566635, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 34, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.666555852446914, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 33, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 8.182302980196196, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 32, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -1.0, None: 6.666557930213534, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 31, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.6665597424877525, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 30, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.666561346350436, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 29, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 8.118018384824985, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 28, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.3918964636560793, None: 6.444195422420355, 'right': 0.05178395061728394, 'left': 0.12320291878058351}
LearningAgent.update(): deadline = 27, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.3918964636560793, None: 6.446762398315506, 'right': 0.05178395061728394, 'left': 0.12320291878058351}
LearningAgent.update(): deadline = 26, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.3918964636560793, None: 6.449118515476411, 'right': 0.05178395061728394, 'left': 0.12320291878058351}
LearningAgent.update(): deadline = 25, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 0.5113515625, None: 1.6833456205818609, 'right': 0.44983443903991155, 'left': 8.51901642838291}
LearningAgent.update(): deadline = 24, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2
{'forward': -1.0, None: 6.666562333728401, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.666563254313151, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.666564116082764, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 8.094258443448426, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -1.0, None: 6.666564885212143, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.666565612222532, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.666566301230105, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.666566955787301, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 8.127002661510208, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 15, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 59
Environment.reset(): Trial set up with start = (4, 6), destination = (6, 3), deadline = 25
RoutePlanner.route_to(): destination = (6, 3)
{'forward': -0.06666666666666667, None: 6.42603212709479, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 25, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.06666666666666667, None: 6.427475934332221, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 0.0, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': 'left'}, action = forward, reward = -1
{'forward': -0.06666666666666667, None: 6.445415239257304, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 1.9928676511229029, None: 0.0, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 21, inputs = {'light': 'green', 'oncoming': None, 'right': 'right', 'left': None}, action = forward, reward = 0.5
{'forward': -0.06666666666666667, None: 6.453712167785156, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 0.25, None: 0.5470011864196176, 'right': 7.835250980968338, 'left': 0.0}
LearningAgent.update(): deadline = 19, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': -0.06666666666666667, None: 6.459036030257193, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 0.25, None: 0.5470011864196176, 'right': 7.988494021156244, 'left': 0.0}
LearningAgent.update(): deadline = 17, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': 8.224621361606891, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 16, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -1.0, None: 6.66656861763529, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 15, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.6665700883707615, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 14, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.666571405347523, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 13, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.666572596114012, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 12, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.666573681543466, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 11, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 2.7328522928425643, None: 0.0, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 10, inputs = {'light': 'green', 'oncoming': 'left', 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 0.5113515625, None: 1.6833456205818609, 'right': 0.44983443903991155, 'left': 8.550477210315107}
LearningAgent.update(): deadline = 9, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 60
Environment.reset(): Trial set up with start = (8, 1), destination = (5, 5), deadline = 35
RoutePlanner.route_to(): destination = (5, 5)
{'forward': -1.0, None: 6.666574553278996, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 35, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.666575416842005, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 34, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.666589104315705, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 33, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 8.607774759486375, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 32, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -1.0, None: 6.666592982433253, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 31, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.666595745592006, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 30, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.666597873224246, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 29, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.666599593060306, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 28, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 8.709036728925954, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 27, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 8.555625980079578, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 26, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.3918964636560793, None: 6.452744317996249, 'right': 0.05178395061728394, 'left': 0.12320291878058351}
LearningAgent.update(): deadline = 25, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.3918964636560793, None: 6.4559531532263055, 'right': 0.05178395061728394, 'left': 0.12320291878058351}
LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 0.5113515625, None: 1.6833456205818609, 'right': 0.44983443903991155, 'left': 8.61609583511079}
LearningAgent.update(): deadline = 23, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2
{'forward': 8.481541286248051, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 22, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -1.0, None: 6.6666003669865335, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 8.533524772466823, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 61
Environment.reset(): Trial set up with start = (5, 5), destination = (6, 1), deadline = 25
RoutePlanner.route_to(): destination = (6, 1)
{'forward': -0.06666666666666667, None: 6.461112336621288, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 25, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.06666666666666667, None: 6.463167879921742, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.06666666666666667, None: 6.49369269793348, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.06666666666666667, None: 6.506665745588469, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.06666666666666667, None: 6.514665791642379, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 0.25, None: 0.5470011864196176, 'right': 7.875736996591189, 'left': 0.0}
LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': 0.1, None: 0.0, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 19, inputs = {'light': 'green', 'oncoming': None, 'right': 'left', 'left': None}, action = forward, reward = 0.5
{'forward': 0.25, None: 0.5470011864196176, 'right': 8.11706107380002, 'left': 0.0}
LearningAgent.update(): deadline = 18, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': 0.5113515625, None: 1.6833456205818609, 'right': 0.44983443903991155, 'left': 8.707153009608792}
LearningAgent.update(): deadline = 17, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2
{'forward': -1.0, None: 6.666601610105536, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.666602694381554, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 15, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.666603653965831, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 14, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 62
Environment.reset(): Trial set up with start = (1, 5), destination = (8, 4), deadline = 40
RoutePlanner.route_to(): destination = (8, 4)
{'forward': 0.25, None: 0.5470011864196176, 'right': 8.188192059157291, 'left': 0.0}
LearningAgent.update(): deadline = 40, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': 0.25, None: 0.5470011864196176, 'right': 8.140775790676715, 'left': 0.0}
LearningAgent.update(): deadline = 39, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': -1.0, None: 6.666613105870956, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 38, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 8.100072956228567, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 37, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 7.955589017482483, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 36, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -1.0, None: 6.666615114400795, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 35, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 7.8977957834341215, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 34, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -1.0, None: 6.666616403207442, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 33, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.666617480281568, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 32, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 7.868899417784773, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 31, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -1.0, None: 6.666618300054653, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 30, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.666619025553834, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 29, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 7.850510940869862, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 28, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -1.0, None: 6.666619621067744, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 27, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.666620163901578, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 26, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 63
Environment.reset(): Trial set up with start = (6, 4), destination = (3, 2), deadline = 25
RoutePlanner.route_to(): destination = (3, 2)
{'forward': 0.25, None: 0.5470011864196176, 'right': 8.17878711275262, 'left': 0.0}
LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': 7.837376383616039, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 24, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -1.0, None: 6.666627139316341, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 8.394672714727882, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 22, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.06666666666666667, None: 6.522265835393593, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.06666666666666667, None: 6.5276808665663335, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.06666666666666667, None: 6.531850440569344, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.06666666666666667, None: 6.535220846221778, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 0.25, None: 0.5470011864196176, 'right': 8.31545635486206, 'left': 0.0}
LearningAgent.update(): deadline = 17, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': -1.0, None: 6.666627880454159, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.666628526891035, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 15, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.66662909898767, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 14, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 64
Environment.reset(): Trial set up with start = (4, 4), destination = (7, 2), deadline = 25
RoutePlanner.route_to(): destination = (7, 2)
{'forward': 0.25, None: 0.5470011864196176, 'right': 8.390003214194483, 'left': 0.0}
LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': 8.328487443765303, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 24, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -1.0, None: 6.666634734139519, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 7.908023812003831, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 22, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.3918964636560793, None: 6.466488828898324, 'right': 0.05178395061728394, 'left': 0.12320291878058351}
LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.3918964636560793, None: 6.473995497814637, 'right': 0.05178395061728394, 'left': 0.12320291878058351}
LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 0.5113515625, None: 1.6833456205818609, 'right': 0.44983443903991155, 'left': 8.710086455727685}
LearningAgent.update(): deadline = 19, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 65
Environment.reset(): Trial set up with start = (1, 1), destination = (4, 4), deadline = 30
RoutePlanner.route_to(): destination = (4, 4)
{'forward': -0.06666666666666667, None: 6.5385069917329, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 30, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.06666666666666667, None: 6.541710983606245, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 29, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.06666666666666667, None: 6.560454336065308, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 28, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.06666666666666667, None: 6.56842026086041, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 27, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 0.25, None: 0.5470011864196176, 'right': 8.637169720151427, 'left': 0.0}
LearningAgent.update(): deadline = 26, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': -0.06666666666666667, None: 6.572104501078145, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 25, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.06666666666666667, None: 6.574941366045801, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.06666666666666667, None: 6.577234498561323, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.06666666666666667, None: 6.579150902163581, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.06666666666666667, None: 6.580791822748013, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 0.25, None: 0.5470011864196176, 'right': 8.529333031692222, 'left': 0.0}
LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': -1.0, None: 6.666635213127427, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.666635642039326, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.666636029847168, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.666636383348932, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 7.966152128303791, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 15, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 7.935268397959701, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 14, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.3918964636560793, None: 6.475801790022625, 'right': 0.05178395061728394, 'left': 0.12320291878058351}
LearningAgent.update(): deadline = 13, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.3918964636560793, None: 6.477485891875366, 'right': 0.05178395061728394, 'left': 0.12320291878058351}
LearningAgent.update(): deadline = 12, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.3918964636560793, None: 6.47906239833196, 'right': 0.05178395061728394, 'left': 0.12320291878058351}
LearningAgent.update(): deadline = 11, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 0.5113515625, None: 1.6833456205818609, 'right': 0.44983443903991155, 'left': 8.711922860071795}
LearningAgent.update(): deadline = 10, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 66
Environment.reset(): Trial set up with start = (7, 3), destination = (3, 6), deadline = 35
RoutePlanner.route_to(): destination = (3, 6)
{'forward': -0.06666666666666667, None: 6.581435884077402, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 35, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.06666666666666667, None: 6.5820751149468215, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 34, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.06666666666666667, None: 6.594763847704798, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 33, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.06666666666666667, None: 6.600156559126939, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 32, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.06666666666666667, None: 6.603482064503925, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 31, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 0.25, None: 0.5470011864196176, 'right': 8.30023971247625, 'left': 0.0}
LearningAgent.update(): deadline = 30, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': 0.25, None: 0.5470011864196176, 'right': 8.38918739763415, 'left': 0.0}
LearningAgent.update(): deadline = 29, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': 7.890497152607516, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 28, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -1.0, None: 6.666637032277169, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 27, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 7.862515193211026, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 26, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -1.0, None: 6.666637526183661, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 25, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.666637963290906, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 8.002753305742845, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 23, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 0.5094133129023614, None: 0.0, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 22, inputs = {'light': 'green', 'oncoming': 'right', 'right': None, 'left': None}, action = forward, reward = 0.5
{'forward': -0.06666666666666667, None: 6.604211117605804, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 0.25, None: 0.5470011864196176, 'right': 8.333786829943492, 'left': 0.0}
LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': -0.06666666666666667, None: 6.604835673096412, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.06666666666666667, None: 6.605415338661133, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.06666666666666667, None: 6.605955791555299, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.06666666666666667, None: 6.606461715514561, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 0.25, None: 0.5470011864196176, 'right': 8.000429628367518, 'left': 0.0}
LearningAgent.update(): deadline = 15, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': -0.06666666666666667, None: 6.6069132526482015, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 14, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.06666666666666667, None: 6.6073400627483325, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 13, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.06666666666666667, None: 6.607744562320503, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 12, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 0.25, None: 0.5470011864196176, 'right': 8.03529531017247, 'left': 0.0}
LearningAgent.update(): deadline = 11, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': 7.988748679203446, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 10, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -1.0, None: 6.66663813551116, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 9, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.6666383001139815, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 8, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 67
Environment.reset(): Trial set up with start = (7, 1), destination = (4, 3), deadline = 25
RoutePlanner.route_to(): destination = (4, 3)
{'forward': -0.3918964636560793, None: 6.480104644267153, 'right': 0.05178395061728394, 'left': 0.12320291878058351}
LearningAgent.update(): deadline = 25, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.3918964636560793, None: 6.48114109994715, 'right': 0.05178395061728394, 'left': 0.12320291878058351}
LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.3918964636560793, None: 6.508969934955077, 'right': 0.05178395061728394, 'left': 0.12320291878058351}
LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.3918964636560793, None: 6.520797189833447, 'right': 0.05178395061728394, 'left': 0.12320291878058351}
LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 0.5113515625, None: 1.6833456205818609, 'right': 0.44983443903991155, 'left': 8.363496091746825}
LearningAgent.update(): deadline = 21, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2
{'forward': -1.0, None: 6.666639363859708, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.666640182943917, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.666640845036986, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 7.94273382764316, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 17, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -1.0, None: 6.666641329192543, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.666641751483778, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 15, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.6666421252115216, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 14, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 7.906365080708184, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 13, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.3918964636560793, None: 6.522620558293862, 'right': 0.05178395061728394, 'left': 0.12320291878058351}
LearningAgent.update(): deadline = 12, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.3918964636560793, None: 6.524282628775087, 'right': 0.05178395061728394, 'left': 0.12320291878058351}
LearningAgent.update(): deadline = 11, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.3918964636560793, None: 6.525808172038211, 'right': 0.05178395061728394, 'left': 0.12320291878058351}
LearningAgent.update(): deadline = 10, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 0.5113515625, None: 1.6833456205818609, 'right': 0.44983443903991155, 'left': 8.317039406059022}
LearningAgent.update(): deadline = 9, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2
{'forward': -1.0, None: 6.666642355287664, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 8, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.666642569799832, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 7, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.666642770607055, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 6, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 68
Environment.reset(): Trial set up with start = (5, 6), destination = (1, 2), deadline = 40
RoutePlanner.route_to(): destination = (1, 2)
{'forward': 0.45896896413694505, None: 0.0, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 40, inputs = {'light': 'green', 'oncoming': None, 'right': 'forward', 'left': None}, action = forward, reward = 2
{'forward': 7.893748305671753, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 39, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -1.0, None: 6.666646355015996, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 38, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 8.301717182746373, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 37, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 8.477811793046449, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 36, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.06666666666666667, None: 6.609954141233484, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 35, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.06666666666666667, None: 6.611655516996479, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 34, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.06666666666666667, None: 6.613030795738235, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 33, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.06666666666666667, None: 6.614180135829558, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 32, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.06666666666666667, None: 6.615164258282754, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 31, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 0.25, None: 0.5470011864196176, 'right': 7.9943346536825945, 'left': 0.0}
LearningAgent.update(): deadline = 30, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': -1.0, None: 6.666646659690756, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 29, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 8.40406978101833, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 28, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -1.0, None: 6.666646909777955, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 27, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.666647137742056, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 26, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 8.351396944308505, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -1.0, None: 6.666647333031302, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.666647514284134, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 69
Environment.reset(): Trial set up with start = (5, 1), destination = (6, 6), deadline = 30
RoutePlanner.route_to(): destination = (6, 6)
{'forward': 0.25, None: 0.5470011864196176, 'right': 7.972484945791874, 'left': 0.0}
LearningAgent.update(): deadline = 30, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': -0.06666666666666667, None: 6.6156186912979065, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 29, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.06666666666666667, None: 6.623275887603221, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 28, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.06666666666666667, None: 6.626530196032979, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 27, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 70
Environment.reset(): Trial set up with start = (4, 2), destination = (7, 5), deadline = 30
RoutePlanner.route_to(): destination = (7, 5)
{'forward': -0.06666666666666667, None: 6.628537019564664, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 30, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.06666666666666667, None: 6.630443501919765, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 29, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.06666666666666667, None: 6.6358769766318, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 28, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.06666666666666667, None: 6.638186203384414, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 27, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.06666666666666667, None: 6.639610226548528, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 26, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 0.25, None: 0.5470011864196176, 'right': 7.896026306129284, 'left': 0.0}
LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': -1.0, None: 6.66664808885561, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.666648553300886, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.2, None: 0.14285714285714285, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': 'right'}, action = None, reward = 1
{'forward': -1.0, None: 6.666648892926495, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 8.434429217458918, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 8.355353164969651, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 19, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 0.25, None: 0.5470011864196176, 'right': 8.005664841047004, 'left': 0.0}
LearningAgent.update(): deadline = 18, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': 8.417577917074198, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 17, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 71
Environment.reset(): Trial set up with start = (6, 5), destination = (3, 6), deadline = 20
RoutePlanner.route_to(): destination = (3, 6)
{'forward': -0.06666666666666667, None: 6.639922416242198, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.06666666666666667, None: 6.640231003747097, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.06666666666666667, None: 6.644196353185032, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.06666666666666667, None: 6.645881626696155, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.06666666666666667, None: 6.64692087869468, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 0.25, None: 0.5470011864196176, 'right': 8.20545240950774, 'left': 0.0}
LearningAgent.update(): deadline = 15, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': 0.25, None: 0.5470011864196176, 'right': 8.097692239403697, 'left': 0.0}
LearningAgent.update(): deadline = 14, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': -1.0, None: 6.666649337269999, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 13, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 8.522915533136894, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 12, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 72
Environment.reset(): Trial set up with start = (5, 6), destination = (7, 2), deadline = 30
RoutePlanner.route_to(): destination = (7, 2)
{'forward': 8.41588258357972, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 30, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -1.0, None: 6.666649662196186, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 29, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.666652212866758, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 28, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.666653296901751, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 27, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.666653965389997, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 26, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 8.579282811472332, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 0.5113515625, None: 1.6833456205818609, 'right': 0.44983443903991155, 'left': 8.186962698963518}
LearningAgent.update(): deadline = 24, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2
{'forward': -1.0, None: 6.666654282921915, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.666654548287874, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 8.668421258757226, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 21, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 8.557114048455833, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -1.0, None: 6.666654730063557, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.6666548928354175, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.666655040008308, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.666655174162059, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 73
Environment.reset(): Trial set up with start = (4, 5), destination = (7, 6), deadline = 20
RoutePlanner.route_to(): destination = (7, 6)
{'forward': -0.3918964636560793, None: 6.527317370194944, 'right': 0.05178395061728394, 'left': 0.12320291878058351}
LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.3918964636560793, None: 6.528810398371427, 'right': 0.05178395061728394, 'left': 0.12320291878058351}
LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.3918964636560793, None: 6.549488838615713, 'right': 0.05178395061728394, 'left': 0.12320291878058351}
LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.3918964636560793, None: 6.558277175719534, 'right': 0.05178395061728394, 'left': 0.12320291878058351}
LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 0.5113515625, None: 1.6833456205818609, 'right': 0.44983443903991155, 'left': 8.013527431988262}
LearningAgent.update(): deadline = 16, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2
{'forward': 8.73622227163874, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 15, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 8.518954366689089, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 14, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.06666666666666667, None: 6.64741452339398, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 13, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.06666666666666667, None: 6.647827069321252, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 12, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 74
Environment.reset(): Trial set up with start = (6, 5), destination = (1, 6), deadline = 30
RoutePlanner.route_to(): destination = (1, 6)
{'forward': 8.609223972313668, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 30, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 8.697801022832786, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 29, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 7.6666568980377505, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 28, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -1.0, None: 6.666656036099905, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 27, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 7.666657142253474, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 26, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -1.0, None: 6.666656434746159, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 25, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 7.895625377240784, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 24, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 75
Environment.reset(): Trial set up with start = (1, 6), destination = (2, 3), deadline = 20
RoutePlanner.route_to(): destination = (2, 3)
{'forward': -0.06666666666666667, None: 6.648298059254888, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.06666666666666667, None: 6.648757274440182, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.06666666666666667, None: 6.651443683274155, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.06666666666666667, None: 6.652585407028593, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.06666666666666667, None: 6.653289470010497, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 0.25, None: 0.5470011864196176, 'right': 8.294028780426057, 'left': 0.0}
LearningAgent.update(): deadline = 15, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': 0.25, None: 0.5470011864196176, 'right': 8.39752268777885, 'left': 0.0}
LearningAgent.update(): deadline = 14, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': 0.5113515625, None: 1.6833456205818609, 'right': 0.44983443903991155, 'left': 7.955715854912591}
LearningAgent.update(): deadline = 13, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2
{'forward': -1.0, None: 6.666656654001598, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 12, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 76
Environment.reset(): Trial set up with start = (2, 1), destination = (6, 2), deadline = 25
RoutePlanner.route_to(): destination = (6, 2)
{'forward': 0.5113515625, None: 1.6833456205818609, 'right': 0.44983443903991155, 'left': 8.05016156938035}
LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2
{'forward': 7.867004474573356, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 24, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -1.0, None: 6.6666581559013585, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.6666587942087565, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 7.800222974741385, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 21, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.3333333333333333, None: 0.25, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': None, 'right': 'right', 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.666659030382495, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.666659221289599, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 7.779519128279604, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 17, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.06666666666666667, None: 6.6535402924478, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.06666666666666667, None: 6.653759065351447, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 15, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.06666666666666667, None: 6.653952679371175, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 14, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 77
Environment.reset(): Trial set up with start = (1, 6), destination = (7, 6), deadline = 30
RoutePlanner.route_to(): destination = (7, 6)
{'forward': -0.06666666666666667, None: 6.6541260519252035, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 30, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.06666666666666667, None: 6.654297060308042, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 29, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.06666666666666667, None: 6.656152501261835, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 28, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.06666666666666667, None: 6.6569410636671975, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 27, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.06666666666666667, None: 6.657427343817171, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 26, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 0.25, None: 0.5470011864196176, 'right': 8.214807100358177, 'left': 0.0}
LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': -1.0, None: 6.666659444650911, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.666659625201305, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.6666597760898485, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.666659905288164, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 7.76697932730353, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -1.0, None: 6.666660006708842, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 7.842884154658482, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 18, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 7.911514769391918, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 17, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 7.892679864492734, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 16, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 78
Environment.reset(): Trial set up with start = (8, 3), destination = (5, 5), deadline = 25
RoutePlanner.route_to(): destination = (5, 5)
{'forward': 7.4717741598861105, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.045454545454545456, None: 0.07142857142857142, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': 'forward', 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.045454545454545456, None: 1.0607142857142857, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': 'forward', 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.045454545454545456, None: 1.4811607142857142, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': 'forward', 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.045454545454545456, None: 1.740436011904762, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': 'forward', 'right': None, 'left': None}, action = None, reward = 1
{'forward': 7.691582628890382, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -1.0, None: 6.666660206507577, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.666660368011554, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.666660502982735, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 7.676951750199285, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 16, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.3918964636560793, None: 6.56008366723532, 'right': 0.05178395061728394, 'left': 0.12320291878058351}
LearningAgent.update(): deadline = 15, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.3918964636560793, None: 6.561682412226791, 'right': 0.05178395061728394, 'left': 0.12320291878058351}
LearningAgent.update(): deadline = 14, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 0.5113515625, None: 1.6833456205818609, 'right': 0.44983443903991155, 'left': 8.01529792012171}
LearningAgent.update(): deadline = 13, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2
{'forward': -1.0, None: 6.666660580028784, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 12, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.666660650259222, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 11, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 79
Environment.reset(): Trial set up with start = (1, 1), destination = (3, 4), deadline = 25
RoutePlanner.route_to(): destination = (3, 4)
{'forward': -1.0, None: 6.666660714720731, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 25, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.666660778491581, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.666661661717844, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.666662037089005, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 7.673522077308075, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 21, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -1.0, None: 6.666662210698168, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.666662344377223, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.66666245243446, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 7.8605312141647, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 17, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.06666666666666667, None: 6.6576005811206, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.06666666666666667, None: 6.657751682546367, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 15, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.06666666666666667, None: 6.6578854073081715, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 14, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 0.25, None: 0.5470011864196176, 'right': 8.164975826195551, 'left': 0.0}
LearningAgent.update(): deadline = 13, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': -1.0, None: 6.666662505112363, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 12, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.666662553130298, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 11, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.666662597203902, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 10, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 7.915259235356387, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 9, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 80
Environment.reset(): Trial set up with start = (2, 3), destination = (8, 3), deadline = 30
RoutePlanner.route_to(): destination = (8, 3)
{'forward': 0.5113515625, None: 1.6833456205818609, 'right': 0.44983443903991155, 'left': 7.993508250590561}
LearningAgent.update(): deadline = 30, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2
{'forward': -1.0, None: 6.666662635355116, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 29, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.666663240051848, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 28, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 7.790961494700229, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 27, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 7.749528914481511, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 26, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -1.0, None: 6.666663368549905, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 25, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 7.732955904238693, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 24, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -1.0, None: 6.666663451002824, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.666663519909907, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 7.8379629810342175, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 21, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -1.0, None: 6.666663572355852, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.666663618770515, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.666663660332735, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.6666636979119085, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.666663732166771, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 81
Environment.reset(): Trial set up with start = (8, 4), destination = (4, 5), deadline = 25
RoutePlanner.route_to(): destination = (4, 5)
{'forward': 0.5113515625, None: 1.6833456205818609, 'right': 0.44983443903991155, 'left': 7.970162245001361}
LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2
{'forward': -1.0, None: 6.6666637636078425, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.666664199066666, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 7.752313775120442, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 22, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -1.0, None: 6.666664322446666, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.666664410354916, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 2.3078572746253765, None: 0.0, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 19, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': 'right'}, action = forward, reward = 2
{'forward': -1.0, None: 6.66666446676271, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.666664513903509, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 7.730453309529483, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 16, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.3918964636560793, None: 6.563432149800788, 'right': 0.05178395061728394, 'left': 0.12320291878058351}
LearningAgent.update(): deadline = 15, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.3918964636560793, None: 6.564980667553777, 'right': 0.05178395061728394, 'left': 0.12320291878058351}
LearningAgent.update(): deadline = 14, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 82
Environment.reset(): Trial set up with start = (3, 1), destination = (5, 5), deadline = 30
RoutePlanner.route_to(): destination = (5, 5)
{'forward': -0.3918964636560793, None: 6.566367294814407, 'right': 0.05178395061728394, 'left': 0.12320291878058351}
LearningAgent.update(): deadline = 30, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.3918964636560793, None: 6.567735013521483, 'right': 0.05178395061728394, 'left': 0.12320291878058351}
LearningAgent.update(): deadline = 29, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.3918964636560793, None: 6.582574761493261, 'right': 0.05178395061728394, 'left': 0.12320291878058351}
LearningAgent.update(): deadline = 28, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 0.5113515625, None: 1.6833456205818609, 'right': 0.44983443903991155, 'left': 8.270523779050711}
LearningAgent.update(): deadline = 27, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2
{'forward': -1.0, None: 6.666664621541667, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 26, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.666664698233855, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 25, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.666664757286839, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.666664805021336, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 7.720274636198407, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 22, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.06666666666666667, None: 6.6580500559211435, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.06666666666666667, None: 6.658193666100235, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.06666666666666667, None: 6.658320761108732, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 0.25, None: 0.5470011864196176, 'right': 8.201090154793105, 'left': 0.0}
LearningAgent.update(): deadline = 18, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': 7.7904378699125925, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 17, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 7.854394356028987, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 16, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -1.0, None: 6.666664824967536, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 15, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.6666648433845275, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 14, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.666664860477797, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 13, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 83
Environment.reset(): Trial set up with start = (2, 6), destination = (1, 1), deadline = 30
RoutePlanner.route_to(): destination = (1, 1)
{'forward': 0.5113515625, None: 1.6833456205818609, 'right': 0.44983443903991155, 'left': 7.901669439106551}
LearningAgent.update(): deadline = 30, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2
{'forward': -0.06666666666666667, None: 6.658394401451891, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 29, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.06666666666666667, None: 6.659635241234107, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 28, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.06666666666666667, None: 6.660162598141548, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 27, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.06666666666666667, None: 6.660487801567804, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 26, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 0.25, None: 0.5470011864196176, 'right': 8.06748389894636, 'left': 0.0}
LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': -1.0, None: 6.666664914663464, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.666664958463544, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 7.971800191256937, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 22, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -1.0, None: 6.666664990492353, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.666665018428591, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.666665043152163, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 3.1813807468277253, None: 0.0, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 18, inputs = {'light': 'green', 'oncoming': 'left', 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -1.0, None: 6.666665063446094, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.666665081944793, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 8.029245189207757, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 15, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 84
Environment.reset(): Trial set up with start = (7, 3), destination = (2, 6), deadline = 40
RoutePlanner.route_to(): destination = (2, 6)
{'forward': 8.005073197904112, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 40, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -1.0, None: 6.666665097792012, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 39, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.66666533312321, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 38, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 7.835869365529421, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 37, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -1.0, None: 6.666665399800383, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 36, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.3333333333333333, None: 0.25, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 35, inputs = {'light': 'red', 'oncoming': None, 'right': 'left', 'left': None}, action = None, reward = 1
{'forward': 1.7320977921400016, None: 0.0, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 34, inputs = {'light': 'green', 'oncoming': 'right', 'right': 'left', 'left': None}, action = forward, reward = 2
{'forward': 7.807668736246238, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 33, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -1.0, None: 6.666665426947517, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 32, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 7.781108712624118, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 31, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 0.5113515625, None: 1.6833456205818609, 'right': 0.44983443903991155, 'left': 7.31736343841531}
LearningAgent.update(): deadline = 30, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2
{'forward': 1.5421282283340352, None: 0.0, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 29, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': 'forward'}, action = forward, reward = 2
{'forward': -1.0, None: 6.666665443852779, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 28, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.666665459137952, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 27, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.666665473070975, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 26, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 85
Environment.reset(): Trial set up with start = (3, 3), destination = (1, 6), deadline = 25
RoutePlanner.route_to(): destination = (1, 6)
{'forward': 7.772934208301704, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -1.0, None: 6.666665485859501, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.666665662980575, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.6666657382570325, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.666665784677515, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 7.728497793043595, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 0.5113515625, None: 1.6833456205818609, 'right': 0.44983443903991155, 'left': 7.567735375549659}
LearningAgent.update(): deadline = 19, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2
{'forward': 7.8686186815508385, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 18, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -1.0, None: 6.666665803577283, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.666665819760209, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.6666658338753155, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 15, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.666665846367186, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 14, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 86
Environment.reset(): Trial set up with start = (8, 3), destination = (5, 4), deadline = 20
RoutePlanner.route_to(): destination = (5, 4)
{'forward': 7.850259344083681, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -1.0, None: 6.666665857553088, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.666665978920125, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.666666030501116, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.666666062309393, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 7.804361046303507, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 15, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 7.762526546496661, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 14, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.3918964636560793, None: 6.584677059122596, 'right': 0.05178395061728394, 'left': 0.12320291878058351}
LearningAgent.update(): deadline = 13, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.3918964636560793, None: 6.586433979284255, 'right': 0.05178395061728394, 'left': 0.12320291878058351}
LearningAgent.update(): deadline = 12, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 87
Environment.reset(): Trial set up with start = (3, 2), destination = (5, 6), deadline = 30
RoutePlanner.route_to(): destination = (5, 6)
{'forward': 0.5113515625, None: 1.6833456205818609, 'right': 0.44983443903991155, 'left': 7.580101722726324}
LearningAgent.update(): deadline = 30, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2
{'forward': -1.0, None: 6.666666073641092, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 29, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.666666162594928, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 28, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.666666200400308, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 27, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.6666662237136265, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 26, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 8.036235238398596, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 0.25, None: 0.5470011864196176, 'right': 7.987320377188405, 'left': 0.0}
LearningAgent.update(): deadline = 24, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': -1.0, None: 6.666666234787453, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.666666244042008, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 8.135555827678623, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 21, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 8.083456992096076, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -1.0, None: 6.666666250381378, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.6666662560579955, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.666666261190604, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.666666265869174, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 88
Environment.reset(): Trial set up with start = (1, 2), destination = (8, 6), deadline = 55
RoutePlanner.route_to(): destination = (8, 6)
{'forward': -0.06666666666666667, None: 6.660554003693863, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 55, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.06666666666666667, None: 6.66061949651143, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 54, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.06666666666666667, None: 6.661526572034715, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 53, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.06666666666666667, None: 6.661912079132112, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 52, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.06666666666666667, None: 6.66214980850884, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 51, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 0.25, None: 0.5470011864196176, 'right': 8.208224893711721, 'left': 0.0}
LearningAgent.update(): deadline = 50, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': 8.00009885887462, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 49, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -1.0, None: 6.666666275889112, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 48, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 7.952465641107639, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 47, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -1.0, None: 6.666666283216191, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 46, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 0.9732884216601658, None: 0.0, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 45, inputs = {'light': 'green', 'oncoming': 'forward', 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 8.033178656491025, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 44, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.16666666666666666, None: 0.1805785123966942, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 43, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': 'forward'}, action = None, reward = 1
{'forward': -1.0, None: 6.6666662880093215, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 42, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.666666292378444, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 41, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 8.006999205921785, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 40, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -1.0, None: 6.666666296121327, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 39, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.66666629959519, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 38, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 8.064057556141384, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 37, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 0.25, None: 0.5470011864196176, 'right': 7.884997045145314, 'left': 0.0}
LearningAgent.update(): deadline = 36, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': -1.0, None: 6.666666302493123, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 35, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.666666305224425, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 34, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.666666307806154, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 33, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.666666310252931, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 32, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.666666312577369, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 31, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 8.096990529748833, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 30, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 8.07977756318651, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 29, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -1.0, None: 6.666666314620191, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 28, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 89
Environment.reset(): Trial set up with start = (1, 4), destination = (8, 2), deadline = 45
RoutePlanner.route_to(): destination = (8, 2)
{'forward': 0.7704075554173743, None: 0.0, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 45, inputs = {'light': 'green', 'oncoming': None, 'right': 'forward', 'left': None}, action = forward, reward = 2
{'forward': 8.10896398413177, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 44, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 7.666666367427163, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 43, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 7.666666367427163, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 42, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -1.0, None: 6.6666663322225155, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 41, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.666666344764171, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 40, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 7.6666663725516395, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 39, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -1.0, None: 6.666666352811734, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 38, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.6666663595371976, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 37, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 7.666666376683512, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 36, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.16666666666666666, None: 0.28867998163452707, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 35, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': 'forward'}, action = None, reward = 1
{'forward': -1.0, None: 6.66666636414414, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 34, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 7.660466604475158, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 33, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.3918964636560793, None: 6.587436887876535, 'right': 0.05178395061728394, 'left': 0.12320291878058351}
LearningAgent.update(): deadline = 32, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.3918964636560793, None: 6.588351077631806, 'right': 0.05178395061728394, 'left': 0.12320291878058351}
LearningAgent.update(): deadline = 31, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.3918964636560793, None: 6.589190173228609, 'right': 0.05178395061728394, 'left': 0.12320291878058351}
LearningAgent.update(): deadline = 30, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 0.5113515625, None: 1.6833456205818609, 'right': 0.44983443903991155, 'left': 7.58587270184607}
LearningAgent.update(): deadline = 29, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2
{'forward': -1.0, None: 6.666666366980289, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 28, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.66666636962458, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 27, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.666666372099931, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 26, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 90
Environment.reset(): Trial set up with start = (4, 2), destination = (7, 1), deadline = 20
RoutePlanner.route_to(): destination = (7, 1)
{'forward': -1.0, None: 6.666666374425458, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.666666376732626, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.6666664202227315, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.666666438706026, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.666666450104058, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 7.87319910680734, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 15, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 8.03700313360312, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 14, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 7.96430455254332, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 13, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.3918964636560793, None: 6.590850383802281, 'right': 0.05178395061728394, 'left': 0.12320291878058351}
LearningAgent.update(): deadline = 12, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 91
Environment.reset(): Trial set up with start = (8, 6), destination = (2, 5), deadline = 35
RoutePlanner.route_to(): destination = (2, 5)
{'forward': -1.0, None: 6.666666454164607, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 35, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.66666645814902, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 34, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.666666489426667, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 33, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 8.366981711102571, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 32, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 6.244654474068382, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 31, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.1111111111111111, None: 1.0940420443232421, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 30, inputs = {'light': 'red', 'oncoming': 'left', 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.1111111111111111, None: 1.261220782993545, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 29, inputs = {'light': 'red', 'oncoming': 'left', 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.1111111111111111, None: 1.396356930085373, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 28, inputs = {'light': 'red', 'oncoming': 'left', 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.1111111111111111, None: 1.509292138726401, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 27, inputs = {'light': 'red', 'oncoming': 'left', 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.1111111111111111, None: 1.6059929111252809, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 26, inputs = {'light': 'red', 'oncoming': 'left', 'right': None, 'left': None}, action = None, reward = 1
{'forward': 3.639889141953325, None: 0.0, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': 'left', 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 5.951269926069937, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 24, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -1.0, None: 6.666666491843576, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.666666494028864, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.66666649602084, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.666666497849188, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 6.065629699210062, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 19, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -1.0, None: 6.666666499431852, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 6.2207248632785, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 17, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 92
Environment.reset(): Trial set up with start = (3, 3), destination = (4, 6), deadline = 20
RoutePlanner.route_to(): destination = (4, 6)
{'forward': -0.06666666666666667, None: 6.662187448993488, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.06666666666666667, None: 6.662224775807431, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.06666666666666667, None: 6.662891059436316, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 0.25, None: 0.5470011864196176, 'right': 8.293622266759415, 'left': 0.0}
LearningAgent.update(): deadline = 17, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': -0.06666666666666667, None: 6.663079839797835, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.06666666666666667, None: 6.663214345805416, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 15, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.06666666666666667, None: 6.6633179154312545, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 14, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.06666666666666667, None: 6.663401634212139, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 13, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 0.25, None: 0.5470011864196176, 'right': 8.204057160724796, 'left': 0.0}
LearningAgent.update(): deadline = 12, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': 6.354086272092029, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 11, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 93
Environment.reset(): Trial set up with start = (5, 5), destination = (8, 4), deadline = 20
RoutePlanner.route_to(): destination = (8, 4)
{'forward': -0.06666666666666667, None: 6.663456051419714, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.06666666666666667, None: 6.66350956167383, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.06666666666666667, None: 6.663983127422755, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.06666666666666667, None: 6.664184392866048, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.3333333333333333, None: 0.0, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': 'forward', 'left': None}, action = forward, reward = -1
{'forward': 1.868362146654019, None: 0.0, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 15, inputs = {'light': 'green', 'oncoming': None, 'right': 'forward', 'left': None}, action = forward, reward = 0.5
{'forward': -0.06666666666666667, None: 6.664258861080067, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 14, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.06666666666666667, None: 6.664319056219732, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 13, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.06666666666666667, None: 6.664369362157881, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 12, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 0.25, None: 0.5470011864196176, 'right': 8.103671682043975, 'left': 0.0}
LearningAgent.update(): deadline = 11, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': 6.499928522361477, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 10, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -1.0, None: 6.666666501940374, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 9, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 94
Environment.reset(): Trial set up with start = (5, 6), destination = (3, 3), deadline = 25
RoutePlanner.route_to(): destination = (3, 3)
{'forward': -1.0, None: 6.666666504186642, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 25, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.6666665064022785, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.666666530441937, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.666666540658792, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 4.999952348240986, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 21, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 2.222030232434345, None: 0.0, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': 'left', 'left': None}, action = forward, reward = 2
{'forward': -0.06666666666666667, None: 6.664438281293145, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.06666666666666667, None: 6.664493990927483, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.06666666666666667, None: 6.6645405482647515, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 0.25, None: 0.5470011864196176, 'right': 7.871957658789084, 'left': 0.0}
LearningAgent.update(): deadline = 16, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': 5.296253927276428, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 15, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -1.0, None: 6.66666654254891, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 14, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 95
Environment.reset(): Trial set up with start = (5, 2), destination = (3, 5), deadline = 25
RoutePlanner.route_to(): destination = (3, 5)
{'forward': -1.0, None: 6.666666544241425, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 25, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.666666545910859, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.66666656402423, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.666666571722413, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.666666576469625, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 5.597644405003562, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 5.998560089249238, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 19, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.3918964636560793, None: 6.592745790873892, 'right': 0.05178395061728394, 'left': 0.12320291878058351}
LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 0.5113515625, None: 1.6833456205818609, 'right': 0.44983443903991155, 'left': 7.51628746956261}
LearningAgent.update(): deadline = 17, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2
{'forward': -1.0, None: 6.66666657816082, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.666666579635917, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 15, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.666666580941379, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 14, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 5.6350546265902155, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 13, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -1.0, None: 6.666666582012945, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 12, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.666666582989719, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 11, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.666666583886258, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 10, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 96
Environment.reset(): Trial set up with start = (8, 3), destination = (3, 4), deadline = 30
RoutePlanner.route_to(): destination = (3, 4)
{'forward': 5.77049542457109, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 30, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -1.0, None: 6.666666584714061, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 29, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.666666597006952, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 28, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.66666660223143, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 27, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.666666605453193, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 26, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 6.2445382220871215, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 2.2487394330755635, None: 0.0, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 24, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': 'left'}, action = forward, reward = 2
{'forward': -1.0, None: 6.666666606983529, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.666666608262454, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 6.377453130422988, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 21, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 6.513717662847411, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.3918964636560793, None: 6.593854604010784, 'right': 0.05178395061728394, 'left': 0.12320291878058351}
LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 97
Environment.reset(): Trial set up with start = (1, 4), destination = (5, 5), deadline = 25
RoutePlanner.route_to(): destination = (5, 5)
{'forward': 0.5113515625, None: 1.6833456205818609, 'right': 0.44983443903991155, 'left': 7.529958301149926}
LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2
{'forward': -1.0, None: 6.666666609058875, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.666666617700043, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 7.025188838133856, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 22, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -1.0, None: 6.666666620148375, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.66666662189281, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.6666666232360265, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.666666624321793, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 7.160363363030988, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 17, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -1.0, None: 6.666666625115759, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.666666625808274, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 15, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.666666626421151, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 14, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 7.206226645121356, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 13, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -0.06666666666666667, None: 6.664567124744775, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 12, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.06666666666666667, None: 6.6645913502284895, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 11, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 98
Environment.reset(): Trial set up with start = (2, 2), destination = (8, 6), deadline = 50
RoutePlanner.route_to(): destination = (8, 6)
{'forward': -0.06666666666666667, None: 6.664613585761756, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 50, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.06666666666666667, None: 6.664635583057166, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 49, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.06666666666666667, None: 6.664940245598591, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 48, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.06666666666666667, None: 6.665069727178697, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 47, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 0.25, None: 0.5470011864196176, 'right': 7.803074861893354, 'left': 0.0}
LearningAgent.update(): deadline = 46, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': -0.06666666666666667, None: 6.665129612409496, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 45, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.06666666666666667, None: 6.665175724037211, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 44, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.06666666666666667, None: 6.665212997602947, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 43, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 0.25, None: 0.5470011864196176, 'right': 7.783587971974015, 'left': 0.0}
LearningAgent.update(): deadline = 42, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': 7.263781643538434, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 41, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -1.0, None: 6.666666627091909, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 40, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.66666662768553, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 39, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 7.300407551719731, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 38, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -1.0, None: 6.666666628172794, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 37, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.666666628616955, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 36, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.666666629024631, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 35, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 7.324824823916479, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 34, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -1.0, None: 6.6666666293775245, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 33, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.666666629706546, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 32, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.6666666300145465, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 31, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 7.3722604174118755, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 30, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 7.434449885350177, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 29, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 0.25, None: 0.5470011864196176, 'right': 7.778020289285364, 'left': 0.0}
LearningAgent.update(): deadline = 28, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
{'forward': -1.0, None: 6.666666630264447, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 27, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.666666630501853, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 26, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 7.444125583290861, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -1.0, None: 6.666666630718841, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.666666630926232, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.666666631124791, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.666666631315193, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 7.451799412715932, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -1.0, None: 6.6666666314919505, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 7.45873061349181, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 18, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -1.0, None: 6.666666631656832, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.030303030303030304, None: 0.0, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': 'left'}, action = forward, reward = -1
{'forward': -1.0, None: 6.666666631811287, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 15, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
Environment.act(): Primary agent has reached destination!
Simulator.run(): Trial 99
Environment.reset(): Trial set up with start = (5, 4), destination = (1, 2), deadline = 30
RoutePlanner.route_to(): destination = (1, 2)
{'forward': 7.4646716427360325, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 30, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -1.0, None: 6.666666631960667, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 29, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.666666637166567, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 28, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 7.90482126953083, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 27, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -1.0, None: 6.666666638641572, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 26, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -0.2, None: 0.3875, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 25, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': 'right'}, action = None, reward = 1
{'forward': -1.0, None: 6.666666639482325, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.666666640161933, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 8.021146528040884, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 22, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': -1.0, None: 6.666666640658897, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.666666641092359, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': -1.0, None: 6.666666641475974, 'right': 0.0, 'left': -0.043478260869565216}
LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 1
{'forward': 8.074798411481945, None: 1.8301850638323902, 'right': 0.0, 'left': 0.0}
LearningAgent.update(): deadline = 18, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2
{'forward': 0.25, None: 0.5470011864196176, 'right': 7.868483485991555, 'left': 0.0}
LearningAgent.update(): deadline = 17, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2
Environment.act(): Primary agent has reached destination!
